{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhDUFBxt9xZg"
   },
   "source": [
    "# Implement and train a LSTM for sentiment analysis\n",
    "\n",
    "(General Hint on Lab 1/2: Trust whatever you see from the training and report it on PDF. IDMB is far from ideal as it's more like a real-world dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gW6ymxu99xZk"
   },
   "source": [
    "## Step 0: set up the environment\n",
    "\n",
    "Make sure all packages are installed following setup.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1632424039407,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "Spc_UH4B9xZl",
    "outputId": "3989aa4b-d3ab-41a6-d2c9-8e046773b9f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/taylor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import os\n",
    "os.makedirs(\"resources\", exist_ok=True)\n",
    "\n",
    "import functorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters. Do not directly touch this to mess up settings.\n",
    "\n",
    "If you want to initalize new hyperparameter sets, use \"new_hparams = HyperParams()\" and change corresponding fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1632424039548,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "OxnFjs3f9xZn"
   },
   "outputs": [],
   "source": [
    "class HyperParams:\n",
    "    def __init__(self):\n",
    "        # Constance hyperparameters. They have been tested and don't need to be tuned.\n",
    "        self.PAD_INDEX = 0\n",
    "        self.UNK_INDEX = 1\n",
    "        self.PAD_TOKEN = '<pad>'\n",
    "        self.UNK_TOKEN = '<unk>'\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        self.MAX_LENGTH = 256\n",
    "        self.BATCH_SIZE = 96\n",
    "        self.EMBEDDING_DIM = 1\n",
    "        self.HIDDEN_DIM = 100\n",
    "        self.OUTPUT_DIM = 2\n",
    "        self.N_LAYERS = 1\n",
    "        self.DROPOUT_RATE = 0.0\n",
    "        self.LR = 0.01\n",
    "        self.N_EPOCHS = 5\n",
    "        self.WD = 0\n",
    "        self.OPTIM = \"sgd\"\n",
    "        self.BIDIRECTIONAL = False\n",
    "        self.SEED = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XODz_aDV9xZo"
   },
   "source": [
    "### Lab 1(a) Implement your own data loader function.  \n",
    "First, you need to read the data from the dataset file on the local disk. \n",
    "Then, split the dataset into three sets: train, validation and test by 7:1:2 ratio.\n",
    "Finally return x_train, x_valid, x_test, y_train, y_valid, y_test where x represents reviews and y represent labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1632424039548,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "AD7HSvM19xZp"
   },
   "outputs": [],
   "source": [
    "def load_imdb(base_csv:str = './IMDBDataset.csv'):\n",
    "    \"\"\"\n",
    "    Load the IMDB dataset\n",
    "    :param base_csv: the path of the dataset file.\n",
    "    :return: train, validation and test set.\n",
    "    \"\"\"\n",
    "    # Add your code here.\n",
    "    dfx = pd.read_csv(base_csv)\n",
    "    dfx_np = dfx.to_numpy()\n",
    "    num_obs = len(dfx_np)\n",
    "\n",
    "    train_index_start = 0\n",
    "    train_index_end = int(num_obs*0.7)\n",
    "    np_train = dfx_np[train_index_start:train_index_end, :]\n",
    "    #check that we have half neg, half positive\n",
    "    pd_train = pd.DataFrame(np_train, columns=['review', 'sentiment'])\n",
    "    pd_train.describe()\n",
    "\n",
    "    val_index_start = int(num_obs*0.7)\n",
    "    val_index_end = int(num_obs*0.8)\n",
    "    np_val = dfx_np[val_index_start:val_index_end, :]\n",
    "    #check that we have half neg, half positive\n",
    "    pd_val = pd.DataFrame(np_val, columns=['review', 'sentiment'])\n",
    "    pd_val.describe()\n",
    "\n",
    "    test_index_start = int(num_obs*0.8)\n",
    "    test_index_end = num_obs\n",
    "    np_test = dfx_np[test_index_start:test_index_end, :]\n",
    "    #check that we have half neg, half positive\n",
    "    pd_test = pd.DataFrame(np_test, columns=['review', 'sentiment'])\n",
    "    pd_test.describe()\n",
    "\n",
    "    x_train_outter = np_train[:, 0:1].tolist()\n",
    "    y_train_outter  = np_train[:, 1:2].tolist()\n",
    "\n",
    "    x_train = []\n",
    "    for i in x_train_outter:\n",
    "        x_train.append(i[0])\n",
    "\n",
    "    y_train = []\n",
    "    for i in y_train_outter:\n",
    "        y_train.append(i[0])\n",
    "\n",
    "    x_valid_outter  = np_val[:, 0:1].tolist()\n",
    "    y_valid_outter  = np_val[:, 1:2].tolist()\n",
    "\n",
    "    x_valid = []\n",
    "    for i in x_valid_outter:\n",
    "        x_valid.append(i[0])\n",
    "\n",
    "    y_valid = []\n",
    "    for i in y_valid_outter:\n",
    "        y_valid.append(i[0])\n",
    "\n",
    "    x_test_outter  = np_test[:, 0:1].tolist()\n",
    "    y_test_outter  = np_test[:, 1:2].tolist()\n",
    "\n",
    "    x_test = []\n",
    "    for i in x_test_outter:\n",
    "        x_test.append(i[0])\n",
    "\n",
    "    y_test = []\n",
    "    for i in y_test_outter:\n",
    "        y_test.append(i[0])\n",
    "\n",
    "    # print(f'shape of train data is {x_train.shape}')\n",
    "    # print(f'shape of test data is {x_test.shape}')\n",
    "    # print(f'shape of valid data is {x_valid.shape}')\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYVH6t--9xZq"
   },
   "source": [
    "### Lab 1(b): Implement your function to build a vocabulary based on the training corpus.\n",
    "You should first compute the frequency of all the words in the training corpus.\n",
    "Use the given preprocess_string() function to process each word by \"preprocess_string(word)\".\n",
    "Avoid the words that are in the STOP_WORDS. \n",
    "Filter the words by their frequency (>=min_freq).\n",
    "Generate a corpus variable which contains a list of words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1632424039686,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "sugI5VoJ9xZr"
   },
   "outputs": [],
   "source": [
    "def build_vocab(x_train:list, min_freq: int=5, hparams=None) -> dict:\n",
    "    \"\"\"\n",
    "    build a vocabulary based on the training corpus.\n",
    "    :param x_train:  List. The training corpus. Each sample in the list is a string of text.\n",
    "    :param min_freq: Int. The frequency threshold for selecting words.\n",
    "    :return: dictionary {word:index}\n",
    "    \"\"\"\n",
    "    # Add your code here. Your code should assign corpus with a list of words.\n",
    "\n",
    "    # 1 compute word freq in training corpus\n",
    "    word_dict = {}\n",
    "    for obs in x_train:\n",
    "        word_list = obs.split()\n",
    "        for word in word_list:\n",
    "            wd = word#nltk.stem.PorterStemmer().stem(word=word, to_lowercase=True) #stem the words and convert to lower case to increase match rate, and\n",
    "            if wd in word_dict:\n",
    "                word_dict[wd] = word_dict[wd] + 1\n",
    "            else:\n",
    "                word_dict[wd] = 1\n",
    "\n",
    "    # 2 remove stop words\n",
    "    STP_WORDS_SET = set(stopwords.words('english'))\n",
    "    for word in STP_WORDS_SET:\n",
    "        if word in word_dict.keys():\n",
    "            del word_dict[word]\n",
    "\n",
    "    # 3 filter words by freq (remove words with a freq < min freq)\n",
    "    word_dict_keys = list(word_dict.keys())\n",
    "    for word in word_dict_keys:\n",
    "        if word_dict[word] < min_freq:\n",
    "            del word_dict[word]\n",
    "\n",
    "    # 4 generate a corpus variable that contains a list of words\n",
    "    vocab = {}\n",
    "    index = 2\n",
    "    for word in word_dict:\n",
    "        vocab[word] = index\n",
    "        index = index + 1\n",
    "    vocab[hparams.PAD_TOKEN] = hparams.PAD_INDEX\n",
    "    vocab[hparams.UNK_TOKEN] = hparams.UNK_INDEX\n",
    "\n",
    "    corpus = []\n",
    "    # sorting on the basis of most common words\n",
    "    # corpus_ = sorted(corpus, key=corpus.get, reverse=True)[:1000]\n",
    "    # corpus_ = [word for word, freq in corpus.items() if freq >= min_freq]\n",
    "    # # creating a dict\n",
    "    # vocab = {w:i+2 for i, w in enumerate(corpus_)}\n",
    "    # vocab[hparams.PAD_TOKEN] = hparams.PAD_INDEX\n",
    "    # vocab[hparams.UNK_TOKEN] = hparams.UNK_INDEX\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ca71G17F9xZt"
   },
   "source": [
    "### Lab 1(c): Implement your tokenize function. \n",
    "You should leverage the given preprocess_string() function to process each word by \"preprocess_string(word)\".\n",
    "For each word, find its index in the vocabulary. \n",
    "Return a list of int that represents the indices of words in the example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1632424039686,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "c6kj_qT69xZt"
   },
   "outputs": [],
   "source": [
    "def tokenize(vocab: dict, example: str)-> list:\n",
    "    \"\"\"\n",
    "    Tokenize the give example string into a list of token indices.\n",
    "    :param vocab: dict, the vocabulary.\n",
    "    :param example: a string of text.\n",
    "    :return: a list of token indices.\n",
    "    \"\"\"\n",
    "    # Your code here.\n",
    "    example_index_list = []\n",
    "    example_words = example.split()\n",
    "    example_words_processed = []\n",
    "    for word in example_words:\n",
    "        wd = word#nltk.stem.PorterStemmer().stem(word=word, to_lowercase=True)\n",
    "        example_words_processed.append(wd)\n",
    "\n",
    "    for word in example_words_processed:\n",
    "        if word in vocab.keys():\n",
    "            example_index_list.append(vocab[word])\n",
    "        else:\n",
    "            # if the word is not part of the vocab dict, treat it as an unknown\n",
    "            example_index_list.append(1)\n",
    "\n",
    "    return example_index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9ntSo4k9xZu"
   },
   "source": [
    "### Lab 1 (d): Implement the __getitem__ function. Given an index i, you should return the i-th review and label. \n",
    "The review is originally a string. Please tokenize it into a sequence of token indices. \n",
    "Use the max_length parameter to truncate the sequence so that it contains at most max_length tokens. \n",
    "Convert the label string ('positive'/'negative') to a binary index. 'positive' is 1 and 'negative' is 0. \n",
    "Return a dictionary containing three keys: 'ids', 'length', 'label' which represent the list of token ids, the length of the sequence, the binary label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1632424039687,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "2TDgA4p79xZu"
   },
   "outputs": [],
   "source": [
    "class IMDB(Dataset):\n",
    "    def __init__(self, x, y, vocab, max_length=256):\n",
    "        \"\"\"\n",
    "        :param x: list of reviews\n",
    "        :param y: list of labels\n",
    "        :param vocab: vocabulary dictionary {word:index}.\n",
    "        :param max_length: the maximum sequence length.\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Return the tokenized review and label by the given index.\n",
    "        :param idx: index of the sample.\n",
    "        :return: a dictionary containing three keys: 'ids', 'length', 'label' which represent the list of token ids, the length of the sequence, the binary label.\n",
    "        \"\"\"\n",
    "        # Add your code here.\n",
    "        review_string = self.x[idx]\n",
    "        review_sentiment = self.y[idx]\n",
    "        review_tokens = tokenize(self.vocab, review_string)\n",
    "\n",
    "        final_tokens = []\n",
    "        if len(review_tokens)>self.max_length:\n",
    "            final_tokens = review_tokens[0:self.max_length]\n",
    "        else:\n",
    "            final_tokens = review_tokens\n",
    "\n",
    "        final_length = len(final_tokens)\n",
    "\n",
    "        final_label = 0\n",
    "        if review_sentiment == \"positive\":\n",
    "            final_label = 1\n",
    "\n",
    "        rtr_dict = {'ids': final_tokens,       # indexes of the review's words in the vocabulary dictionary\n",
    "                    'length': final_length,    # total number of words in the review (0 up to max_length)\n",
    "                    'label': final_label}      # label of the review (positive or negative)\n",
    "\n",
    "        return rtr_dict\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "\n",
    "def collate(batch, pad_index):\n",
    "    batch_ids = [torch.LongTensor(i['ids']) for i in batch]\n",
    "    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n",
    "    batch_length = torch.Tensor([i['length'] for i in batch])\n",
    "    batch_label = torch.LongTensor([i['label'] for i in batch])\n",
    "    batch = {'ids': batch_ids, 'length': batch_length, 'label': batch_label}\n",
    "    return batch\n",
    "\n",
    "collate_fn = collate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zgSPYmf9xZv"
   },
   "source": [
    "### Lab 1 (e): Implement the LSTM model for sentiment analysis.\n",
    "Q(a): Implement the \\_\\_init\\_\\_ function.\n",
    "Your task is to create the model by stacking several necessary layers including an embedding layer, a lstm cell, a linear layer, and a dropout layer.\n",
    "You can call functions from Pytorch's nn library. For example, nn.Embedding, nn.LSTM, nn.Linear.<br>\n",
    "Q(b): Implement the forward function.\n",
    "    Decide where to apply dropout. \n",
    "    The sequences in the batch have different lengths. Write/call a function to pad the sequences into the same length. \n",
    "    Apply a fully-connected (fc) layer to the output of the LSTM layer. \n",
    "    Return the output features which is of size [batch size, output dim]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1632424039687,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "b9ofQ5R29xZv"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.LSTM) or isinstance(m, nn.GRU):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "                \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size: int, \n",
    "        embedding_dim: int, \n",
    "        hidden_dim: int, \n",
    "        output_dim: int, \n",
    "        n_layers: int, \n",
    "        dropout_rate: float, \n",
    "        pad_index: int,\n",
    "        bidirectional: bool,\n",
    "        **kwargs):\n",
    "        \"\"\"\n",
    "        Create a LSTM model for classification.\n",
    "        :param vocab_size: size of the vocabulary\n",
    "        :param embedding_dim: dimension of embeddings\n",
    "        :param hidden_dim: dimension of hidden features\n",
    "        :param output_dim: dimension of the output layer which equals to the number of labels.\n",
    "        :param n_layers: number of layers.\n",
    "        :param dropout_rate: dropout rate.\n",
    "        :param pad_index: index of the padding token.we\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Add your code here. Initializing each layer by the given arguments.\n",
    "\n",
    "        # embedding layer\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim,)\n",
    "        # LSTM cell, dropout layer\n",
    "        self.lstm_layer = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional, batch_first=True, dropout=dropout_rate) # dropout may need to be applied here dropout=dropout_rate\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=dropout_rate)\n",
    "        # linear layer\n",
    "        fc_input_size = hidden_dim\n",
    "        # if bidirectional:\n",
    "        #     fc_input_size = hidden_dim * 2\n",
    "        #self.fc1 = nn.Linear(in_features=fc_input_size*256, out_features=output_dim)\n",
    "        self.fc1 = nn.Linear(in_features=fc_input_size, out_features=output_dim)\n",
    "\n",
    "        # Weight initialization. DO NOT CHANGE!\n",
    "        if \"weight_init_fn\" not in kwargs:\n",
    "            self.apply(init_weights)\n",
    "        else:\n",
    "            self.apply(kwargs[\"weight_init_fn\"])\n",
    "\n",
    "    def forward(self, ids:torch.Tensor, length:torch.Tensor):\n",
    "        \"\"\"\n",
    "        Feed the given token ids to the model.\n",
    "        :param ids: [batch size, seq len] batch of token ids.\n",
    "        :param length: [batch size] batch of length of the token ids.\n",
    "        :return: prediction of size [batch size, output dim].\n",
    "        \"\"\"\n",
    "        # Add your code here.\n",
    "\n",
    "        embeds_b = self.embed_layer(ids)\n",
    "        #lstm_out_b, (ht_b, ct_b) = self.lstm_layer(input=embeds_b) #h_0 and c_0 not provided, so the initial hidden state and cell state default to zero.\n",
    "        # functorch.vmap vectorizes a supplied function for faster computation.\n",
    "        # dropout_out_b = functorch.vmap(self.dropout_layer, randomness='same')(lstm_out_b)\n",
    "        # flatten_out_b = functorch.vmap(torch.flatten)(dropout_out_b)\n",
    "        # prediction_b = functorch.vmap(self.fc1)(flatten_out_b)\n",
    "\n",
    "        drop_out_b = self.dropout_layer(embeds_b)\n",
    "        lstm_out_b, (ht_b, ct_b) = self.lstm_layer(input=torch.nn.utils.rnn.pack_padded_sequence(input=drop_out_b, lengths=length, batch_first=True, enforce_sorted=False))\n",
    "        drop_out_b2 = self.dropout_layer(ht_b[-1])\n",
    "        prediction_b = self.fc1(drop_out_b2)\n",
    "\n",
    "        # lstm_out_b, (ht_b, ct_b) = self.lstm_layer(input=torch.nn.utils.rnn.pack_padded_sequence(input=embeds_b, lengths=length, batch_first=True, enforce_sorted=False))\n",
    "        # drop_out_b = self.dropout_layer(ht_b[-1])\n",
    "        # prediction_b = self.fc1(drop_out_b)\n",
    "\n",
    "        #prediction_b = self.fc1(ht_b[-1])\n",
    "\n",
    "        return prediction_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1632424039803,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "13Sdl7MV9xZv"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def train(dataloader, model, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    for batch in tqdm.tqdm(dataloader, desc='training...', file=sys.stdout):\n",
    "        ids = batch['ids'].to(device)\n",
    "        length = batch['length']\n",
    "        label = batch['label'].to(device)\n",
    "        prediction = model(ids, length)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "        scheduler.step()\n",
    "\n",
    "    return epoch_losses, epoch_accs\n",
    "\n",
    "def evaluate(dataloader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n",
    "            ids = batch['ids'].to(device)\n",
    "            length = batch['length']\n",
    "            label = batch['label'].to(device)\n",
    "            prediction = model(ids, length)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "\n",
    "    return epoch_losses, epoch_accs\n",
    "\n",
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy\n",
    "\n",
    "def predict_sentiment(text, model, vocab, device):\n",
    "    tokens = tokenize(vocab, text)\n",
    "    ids = [vocab[t] if t in vocab else UNK_INDEX for t in tokens]\n",
    "    length = torch.LongTensor([len(ids)])\n",
    "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
    "    prediction = model(tensor, length).squeeze(dim=0)\n",
    "    probability = torch.softmax(prediction, dim=-1)\n",
    "    predicted_class = prediction.argmax(dim=-1).item()\n",
    "    predicted_probability = probability[predicted_class].item()\n",
    "    return predicted_class, predicted_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 1 (g) Implement GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vocab_size: int, \n",
    "        embedding_dim: int, \n",
    "        hidden_dim: int, \n",
    "        output_dim: int, \n",
    "        n_layers: int, \n",
    "        dropout_rate: float, \n",
    "        pad_index: int,\n",
    "        bidirectional: bool,\n",
    "        **kwargs):\n",
    "        \"\"\"\n",
    "        Create a LSTM model for classification.\n",
    "        :param vocab_size: size of the vocabulary\n",
    "        :param embedding_dim: dimension of embeddings\n",
    "        :param hidden_dim: dimension of hidden features\n",
    "        :param output_dim: dimension of the output layer which equals to the number of labels.\n",
    "        :param n_layers: number of layers.\n",
    "        :param dropout_rate: dropout rate.\n",
    "        :param pad_index: index of the padding token.we\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Add your code here. Initializing each layer by the given arguments.\n",
    "\n",
    "        # embedding layer\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim,)\n",
    "        # GRU cell, dropout layer\n",
    "        self.gru_layer = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, bidirectional=bidirectional, batch_first=True, dropout=dropout_rate) # dropout may need to be applied here dropout=dropout_rate\n",
    "        self.dropout_layer = nn.Dropout(p=dropout_rate)\n",
    "        # linear layer\n",
    "        fc_input_size = hidden_dim\n",
    "        # if bidirectional:\n",
    "        #     fc_input_size = hidden_dim * 2\n",
    "        #self.fc1 = nn.Linear(in_features=fc_input_size*256, out_features=output_dim)\n",
    "        self.fc1 = nn.Linear(in_features=fc_input_size, out_features=output_dim)\n",
    "\n",
    "        # Weight initialization. DO NOT CHANGE!\n",
    "        if \"weight_init_fn\" not in kwargs:\n",
    "            self.apply(init_weights)\n",
    "        else:\n",
    "            self.apply(kwargs[\"weight_init_fn\"])\n",
    "\n",
    "\n",
    "    def forward(self, ids:torch.Tensor, length:torch.Tensor):\n",
    "        \"\"\"\n",
    "        Feed the given token ids to the model.\n",
    "        :param ids: [batch size, seq len] batch of token ids.\n",
    "        :param length: [batch size] batch of length of the token ids.\n",
    "        :return: prediction of size [batch size, output dim].\n",
    "        \"\"\"\n",
    "        # Add your code here.\n",
    "        embeds_b = self.embed_layer(ids)\n",
    "\n",
    "        # gru_out_b, ht_b= self.gru_layer(input=embeds_b) #h_0 and c_0 not provided, so the initial hidden state and cell state default to zero.\n",
    "        # # functorch.vmap vectorizes a supplied function for faster computation.\n",
    "        # dropout_out_b = functorch.vmap(self.dropout_layer)(gru_out_b)\n",
    "        # flatten_out_b = functorch.vmap(torch.flatten)(dropout_out_b)\n",
    "        # prediction_b = functorch.vmap(self.fc1)(flatten_out_b)\n",
    "\n",
    "        gru_out_b, ht_b= self.gru_layer(input=torch.nn.utils.rnn.pack_padded_sequence(input=embeds_b, lengths=length, batch_first=True, enforce_sorted=False))\n",
    "        dropout_out_b = self.dropout_layer(ht_b[-1])\n",
    "        prediction_b = self.fc1(dropout_out_b)\n",
    "\n",
    "        return prediction_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate warmup. DO NOT TOUCH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantWithWarmup(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer,\n",
    "        num_warmup_steps: int,\n",
    "    ):\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        super().__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self._step_count <= self.num_warmup_steps:\n",
    "            # warmup\n",
    "            scale = 1.0 - (self.num_warmup_steps - self._step_count) / self.num_warmup_steps\n",
    "            lr = [base_lr * scale for base_lr in self.base_lrs]\n",
    "            self.last_lr = lr\n",
    "        else:\n",
    "            lr = self.base_lrs\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the training / validation iteration here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "executionInfo": {
     "elapsed": 442161,
     "status": "error",
     "timestamp": 1632424481962,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "qXLkQSnS9xZw",
    "outputId": "3fc551e1-dabf-446d-f2cb-90e70f38d1e4"
   },
   "outputs": [],
   "source": [
    "def plot_training_validation_loss_and_accuracy(train_losses: list, train_accs: list, valid_losses: list, valid_accs: list, plt_title:str, file_name = \"test\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(train_losses, '-', label = \"Training Loss\", color = \"blue\")\n",
    "    ax.plot(train_accs, '--', label = \"Training Accuracy\", color = \"blue\")\n",
    "    ax.plot(valid_losses, '-', label = \"Validation Loss\", color = \"orange\")\n",
    "    ax.plot(valid_accs, '--', label = \"Validation Accuracy\", color = \"orange\")\n",
    "    plt.ylim([0,1.0])\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title(plt_title)\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel('epoch')\n",
    "\n",
    "    # PLT_FOLDER = \"./plots\"\n",
    "    # if not os.path.exists(PLT_FOLDER):\n",
    "    #     os.makedirs(PLT_FOLDER)\n",
    "    #\n",
    "    # fig_name = file_name + \".png\"\n",
    "    # plt.savefig(fig_name, bbox_inches='tight')\n",
    "    #\n",
    "    # plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def train_and_test_model_with_hparams(hparams, model_type=\"lstm\", **kwargs):\n",
    "    # Seeding. DO NOT TOUCH! DO NOT TOUCH hparams.SEED!\n",
    "    # Set the random seeds.\n",
    "    torch.manual_seed(hparams.SEED)\n",
    "    random.seed(hparams.SEED)\n",
    "    np.random.seed(hparams.SEED)\n",
    "\n",
    "    x_train, x_valid, x_test, y_train, y_valid, y_test = load_imdb()\n",
    "    vocab = build_vocab(x_train, hparams=hparams)\n",
    "    vocab_size = len(vocab)\n",
    "    print(f'Length of vocabulary is {vocab_size}')\n",
    "\n",
    "    train_data = IMDB(x_train, y_train, vocab, hparams.MAX_LENGTH)\n",
    "    valid_data = IMDB(x_valid, y_valid, vocab, hparams.MAX_LENGTH)\n",
    "    test_data = IMDB(x_test, y_test, vocab, hparams.MAX_LENGTH)\n",
    "\n",
    "    collate = functools.partial(collate_fn, pad_index=hparams.PAD_INDEX)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=hparams.BATCH_SIZE, collate_fn=collate, shuffle=True)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_data, batch_size=hparams.BATCH_SIZE, collate_fn=collate)\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=hparams.BATCH_SIZE, collate_fn=collate)\n",
    "\n",
    "    # Model\n",
    "    if \"override_models_with_gru\" in kwargs and kwargs[\"override_models_with_gru\"]:\n",
    "        model = GRU(\n",
    "            vocab_size,\n",
    "            hparams.EMBEDDING_DIM,\n",
    "            hparams.HIDDEN_DIM,\n",
    "            hparams.OUTPUT_DIM,\n",
    "            hparams.N_LAYERS,\n",
    "            hparams.DROPOUT_RATE,\n",
    "            hparams.PAD_INDEX,\n",
    "            hparams.BIDIRECTIONAL,\n",
    "            **kwargs)\n",
    "    else:\n",
    "        model = LSTM(\n",
    "            vocab_size,\n",
    "            hparams.EMBEDDING_DIM,\n",
    "            hparams.HIDDEN_DIM,\n",
    "            hparams.OUTPUT_DIM,\n",
    "            hparams.N_LAYERS,\n",
    "            hparams.DROPOUT_RATE,\n",
    "            hparams.PAD_INDEX,\n",
    "            hparams.BIDIRECTIONAL,\n",
    "            **kwargs)\n",
    "    num_params = count_parameters(model)\n",
    "    print(f'The model has {num_params:,} trainable parameters')\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Optimization. Lab 2 (a)(b) should choose one of them.\n",
    "    # DO NOT TOUCH optimizer-specific hyperparameters! (e.g., eps, momentum)\n",
    "    # DO NOT change optimizer implementations!\n",
    "    if hparams.OPTIM == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(), lr=hparams.LR, weight_decay=hparams.WD, momentum=.9)\n",
    "    elif hparams.OPTIM == \"adagrad\":\n",
    "        optimizer = optim.Adagrad(\n",
    "            model.parameters(), lr=hparams.LR, weight_decay=hparams.WD, eps=1e-6)\n",
    "    elif hparams.OPTIM == \"adam\":\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(), lr=hparams.LR, weight_decay=hparams.WD, eps=1e-6)\n",
    "    elif hparams.OPTIM == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(\n",
    "            model.parameters(), lr=hparams.LR, weight_decay=hparams.WD, eps=1e-6, momentum=.9)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Optimizer not implemented!\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # Start training\n",
    "    best_valid_loss = float('inf')\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Warmup Scheduler. DO NOT TOUCH!\n",
    "    WARMUP_STEPS = 200\n",
    "    lr_scheduler = ConstantWithWarmup(optimizer, WARMUP_STEPS)\n",
    "\n",
    "    # the folder where the trained model is saved\n",
    "    CHECKPOINT_FOLDER = \"./saved_model\"\n",
    "\n",
    "    for epoch in range(hparams.N_EPOCHS):\n",
    "\n",
    "        # Your code: implement the training process and save the best model.\n",
    "        train_loss, train_acc = train(train_dataloader, model, criterion, optimizer, lr_scheduler, device)\n",
    "        valid_loss, valid_acc = evaluate(valid_dataloader, model, criterion, device)\n",
    "\n",
    "        epoch_train_loss = np.mean(train_loss)\n",
    "        epoch_train_acc = np.mean(train_acc)\n",
    "        epoch_valid_loss = np.mean(valid_loss)\n",
    "        epoch_valid_acc = np.mean(valid_acc)\n",
    "\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        valid_losses.append(epoch_valid_loss)\n",
    "        valid_accs.append(epoch_valid_acc)\n",
    "\n",
    "        # Save the model that achieves the smallest validation loss.\n",
    "        if epoch_valid_loss < best_valid_loss:\n",
    "            # Your code: save the best model somewhere (no need to submit it to Sakai)\n",
    "            best_valid_loss = epoch_valid_loss\n",
    "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
    "                os.makedirs(CHECKPOINT_FOLDER)\n",
    "            print(\"Saving ...\")\n",
    "            state = {'state_dict': model.state_dict(),\n",
    "                     'epoch': epoch}\n",
    "            torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'model.pth'))\n",
    "\n",
    "        print(f'epoch: {epoch+1}')\n",
    "        print(f'train_loss: {epoch_train_loss:.3f}, train_acc: {epoch_train_acc:.3f}')\n",
    "        print(f'valid_loss: {epoch_valid_loss:.3f}, valid_acc: {epoch_valid_acc:.3f}')\n",
    "\n",
    "\n",
    "\n",
    "    # Your Code: Load the best model's weights.\n",
    "    checkpoint = torch.load('./saved_model/model.pth') # change the path to your own checkpoint file\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.cuda()\n",
    "\n",
    "    # Your Code: evaluate test loss on testing dataset (NOT Validation)\n",
    "    test_loss, test_acc = evaluate(test_dataloader, model, criterion, device)\n",
    "\n",
    "    epoch_test_loss = np.mean(test_loss)\n",
    "    epoch_test_acc = np.mean(test_acc)\n",
    "    print(f'test_loss: {epoch_test_loss:.3f}, test_acc: {epoch_test_acc:.3f}')\n",
    "\n",
    "    if \"output_plot\" in kwargs and kwargs[\"output_plot\"]:\n",
    "        plt_title = \"\"\n",
    "        if \"override_models_with_gru\" in kwargs and kwargs[\"override_models_with_gru\"]:\n",
    "            plt_title = plt_title + \" gru \"\n",
    "        else:\n",
    "            plt_title = plt_title + \" lstm \"\n",
    "\n",
    "        plt_title = plt_title + hparams.OPTIM + f' training vs validation losses and accuracy \\n with Layers: {hparams.N_LAYERS}, Hidden Dim: {hparams.HIDDEN_DIM}, Embed Dim: {hparams.EMBEDDING_DIM}'\n",
    "        plot_training_validation_loss_and_accuracy(train_losses, train_accs, valid_losses, valid_accs, plt_title=plt_title)\n",
    "\n",
    "    # Free memory for later usage.\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    return {\n",
    "        'num_params': num_params,\n",
    "        \"test_loss\": epoch_test_loss,\n",
    "        \"test_acc\": epoch_test_acc,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"train_accs\": train_accs,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"valid_accs\": valid_accs\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "aborted",
     "timestamp": 1632424481960,
     "user": {
      "displayName": "于安安",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13100696601280815207"
     },
     "user_tz": 240
    },
    "id": "VKCu4rPBA2Sp"
   },
   "source": [
    "### Lab 1 (f): Train model with original hyperparameters, for LSTM.\n",
    "\n",
    "Train the model with default hyperparameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.38it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.57it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.98it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.497\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.45it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.493\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.95it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.48it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.86it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.493\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 91.10it/s]\n",
      "test_loss: 0.693, test_acc: 0.499\n"
     ]
    }
   ],
   "source": [
    "org_hyperparams = HyperParams()\n",
    "_ = train_and_test_model_with_hparams(org_hyperparams, \"lstm_1layer_base_sgd_e32_h100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag 1 (h) Train GRU with vanilla hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 91,902 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.23it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.694, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 64.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.26it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.694, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 62.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.78it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.694, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.66it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.694, train_acc: 0.502\n",
      "valid_loss: 0.695, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.31it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.694, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 97.62it/s]\n",
      "test_loss: 0.693, test_acc: 0.501\n"
     ]
    }
   ],
   "source": [
    "org_hyperparams = HyperParams()\n",
    "_ = train_and_test_model_with_hparams(org_hyperparams, \"gru_1layer_base_sgd_e32_h100\", override_models_with_gru=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 (a) Study of LSTM Optimizers. Hint: For adaptive optimizers, we recommend using a learning rate of 0.001 (instead of 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.20it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.73it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.530\n",
      "valid_loss: 0.692, valid_acc: 0.619\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.92it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.652, train_acc: 0.648\n",
      "valid_loss: 0.652, valid_acc: 0.679\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.94it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.522, train_acc: 0.796\n",
      "valid_loss: 0.539, valid_acc: 0.778\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.69it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.470, train_acc: 0.830\n",
      "valid_loss: 0.499, valid_acc: 0.803\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 103.55it/s]\n",
      "test_loss: 0.492, test_acc: 0.813\n"
     ]
    }
   ],
   "source": [
    "adagrad_hparams = HyperParams()\n",
    "adagrad_hparams.OPTIM = \"adagrad\"\n",
    "adagrad_hparams.LR = 0.001\n",
    "_ = train_and_test_model_with_hparams(adagrad_hparams, \"lstm_1layer_base_adagrad_e32_h100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.34it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.534\n",
      "valid_loss: 0.673, valid_acc: 0.577\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.49it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.551, train_acc: 0.729\n",
      "valid_loss: 0.513, valid_acc: 0.752\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.70it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.378, train_acc: 0.837\n",
      "valid_loss: 0.421, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.98it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.242, train_acc: 0.907\n",
      "valid_loss: 0.421, valid_acc: 0.839\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.09it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.151, train_acc: 0.947\n",
      "valid_loss: 0.400, valid_acc: 0.846\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 94.43it/s]\n",
      "test_loss: 0.403, test_acc: 0.845\n"
     ]
    }
   ],
   "source": [
    "adam_hparams = HyperParams()\n",
    "adam_hparams.OPTIM = \"adam\"\n",
    "adam_hparams.LR = 0.001\n",
    "_ = train_and_test_model_with_hparams(adam_hparams, \"lstm_1layer_base_adam_e32_h100\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.20it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.547\n",
      "valid_loss: 0.687, valid_acc: 0.543\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.86it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.610, train_acc: 0.681\n",
      "valid_loss: 0.716, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.68it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.407, train_acc: 0.808\n",
      "valid_loss: 0.358, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.30it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.208, train_acc: 0.919\n",
      "valid_loss: 0.352, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.87it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.131, train_acc: 0.953\n",
      "valid_loss: 0.395, valid_acc: 0.833\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.39it/s]\n",
      "test_loss: 0.348, test_acc: 0.864\n"
     ]
    }
   ],
   "source": [
    "rmsprop_hparams = HyperParams()\n",
    "rmsprop_hparams.OPTIM = \"rmsprop\"\n",
    "rmsprop_hparams.LR = 0.001\n",
    "_ = train_and_test_model_with_hparams(rmsprop_hparams, \"lstm_1layer_base_adam_e32_h100\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 (b): Study of GRU Optimizers. Hint: For adaptive optimizers, we recommend using a learning rate of 0.001 (instead of 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 91,902 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 62.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.80it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.580\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 64.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.87it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.692, train_acc: 0.541\n",
      "valid_loss: 0.683, valid_acc: 0.683\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.14it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.643, train_acc: 0.722\n",
      "valid_loss: 0.538, valid_acc: 0.789\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.80it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.06it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.485, train_acc: 0.818\n",
      "valid_loss: 0.494, valid_acc: 0.809\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.22it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.426, train_acc: 0.852\n",
      "valid_loss: 0.459, valid_acc: 0.821\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 99.50it/s]\n",
      "test_loss: 0.454, test_acc: 0.829\n"
     ]
    }
   ],
   "source": [
    "adagrad_hparams = HyperParams()\n",
    "adagrad_hparams.OPTIM = \"adagrad\"\n",
    "adagrad_hparams.LR = 0.001\n",
    "_ = train_and_test_model_with_hparams(adagrad_hparams, \"gru_1layer_base_adagrad_e32_h100\", override_models_with_gru=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 91,902 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 60.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.99it/s] \n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.546\n",
      "valid_loss: 0.654, valid_acc: 0.646\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.90it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.448, train_acc: 0.801\n",
      "valid_loss: 0.343, valid_acc: 0.859\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 64.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.74it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.213, train_acc: 0.919\n",
      "valid_loss: 0.367, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.20it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.123, train_acc: 0.959\n",
      "valid_loss: 0.380, valid_acc: 0.864\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.80it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.079, train_acc: 0.975\n",
      "valid_loss: 0.445, valid_acc: 0.864\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 100.95it/s]\n",
      "test_loss: 0.353, test_acc: 0.856\n"
     ]
    }
   ],
   "source": [
    "adam_hparams = HyperParams()\n",
    "adam_hparams.OPTIM = \"adam\"\n",
    "adam_hparams.LR = 0.001\n",
    "_ = train_and_test_model_with_hparams(adam_hparams, \"gru_1layer_base_adam_e32_h100\", override_models_with_gru=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 91,902 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.37it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.621, train_acc: 0.631\n",
      "valid_loss: 0.347, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.34it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.251, train_acc: 0.896\n",
      "valid_loss: 0.421, valid_acc: 0.827\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 60.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.34it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.123, train_acc: 0.956\n",
      "valid_loss: 0.342, valid_acc: 0.873\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.69it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.056, train_acc: 0.980\n",
      "valid_loss: 0.413, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 62.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.84it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.030, train_acc: 0.990\n",
      "valid_loss: 0.546, valid_acc: 0.868\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 99.73it/s]\n",
      "test_loss: 0.338, test_acc: 0.873\n"
     ]
    }
   ],
   "source": [
    "rmsprop_hparams = HyperParams()\n",
    "rmsprop_hparams.OPTIM = \"rmsprop\"\n",
    "rmsprop_hparams.LR = 0.001\n",
    "_ = train_and_test_model_with_hparams(rmsprop_hparams, \"gru_1layer_base_adam_e32_h100\", override_models_with_gru=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Lab 2 (c) Deeper LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_loss_and_accuracy_over_parameter_change(test_loss_vect, test_acc_vect, parameter_setting_vect, parameter_name, plt_title):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(parameter_setting_vect, test_loss_vect, '-', label = \"Test Loss\", color = \"blue\")\n",
    "    ax.plot(parameter_setting_vect, test_acc_vect, '--', label = \"Test Accuracy\", color = \"blue\")\n",
    "    plt.ylim([0.8,1.0])\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title(plt_title)\n",
    "    ax.set_ylabel('%')\n",
    "    ax.set_xlabel(parameter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.05it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 60.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.87it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.530\n",
      "valid_loss: 0.692, valid_acc: 0.619\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 60.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.83it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.652, train_acc: 0.648\n",
      "valid_loss: 0.652, valid_acc: 0.679\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 60.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.19it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.522, train_acc: 0.796\n",
      "valid_loss: 0.539, valid_acc: 0.778\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.99it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.470, train_acc: 0.830\n",
      "valid_loss: 0.499, valid_acc: 0.803\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.63it/s]\n",
      "test_loss: 0.492, test_acc: 0.813\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_2layer_base_adagrad_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 183,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.77it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.67it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.521\n",
      "valid_loss: 0.686, valid_acc: 0.517\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.78it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.633, train_acc: 0.694\n",
      "valid_loss: 0.486, valid_acc: 0.792\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.80it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.435, train_acc: 0.805\n",
      "valid_loss: 0.403, valid_acc: 0.818\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.10it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.362, train_acc: 0.846\n",
      "valid_loss: 0.431, valid_acc: 0.805\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 87.41it/s]\n",
      "test_loss: 0.402, test_acc: 0.822\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_3layer_base_adagrad_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 263,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 39.75it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.73it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.505\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.44it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.555\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.05it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.671, train_acc: 0.578\n",
      "valid_loss: 0.658, valid_acc: 0.560\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 39.38it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.06it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.473, train_acc: 0.781\n",
      "valid_loss: 0.411, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.00it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.373, train_acc: 0.837\n",
      "valid_loss: 0.383, valid_acc: 0.826\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 70.85it/s]\n",
      "test_loss: 0.384, test_acc: 0.832\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_4layer_base_adagrad_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 344,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 31.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.73it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 32.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.37it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.498\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 31.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 63.12it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.684, train_acc: 0.546\n",
      "valid_loss: 0.593, valid_acc: 0.654\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 30.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.22it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.465, train_acc: 0.786\n",
      "valid_loss: 0.409, valid_acc: 0.819\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 31.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 62.89it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.355, train_acc: 0.849\n",
      "valid_loss: 0.367, valid_acc: 0.838\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 63.52it/s]\n",
      "test_loss: 0.364, test_acc: 0.840\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.01it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.534\n",
      "valid_loss: 0.673, valid_acc: 0.577\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.50it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.551, train_acc: 0.729\n",
      "valid_loss: 0.513, valid_acc: 0.752\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.50it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.378, train_acc: 0.837\n",
      "valid_loss: 0.421, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.00it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.242, train_acc: 0.907\n",
      "valid_loss: 0.421, valid_acc: 0.839\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.43it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.151, train_acc: 0.947\n",
      "valid_loss: 0.400, valid_acc: 0.846\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.74it/s]\n",
      "test_loss: 0.403, test_acc: 0.845\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_2layer_base_adam_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 183,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.25it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.542\n",
      "valid_loss: 0.588, valid_acc: 0.724\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.91it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.46it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.399, train_acc: 0.825\n",
      "valid_loss: 0.457, valid_acc: 0.787\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.35it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.218, train_acc: 0.919\n",
      "valid_loss: 0.384, valid_acc: 0.851\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 71.36it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.132, train_acc: 0.956\n",
      "valid_loss: 0.460, valid_acc: 0.832\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.76it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.23it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.096, train_acc: 0.967\n",
      "valid_loss: 0.475, valid_acc: 0.871\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 78.92it/s]\n",
      "test_loss: 0.383, test_acc: 0.853\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_3layer_base_adam_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 263,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 36.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.57it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.516\n",
      "valid_loss: 0.724, valid_acc: 0.723\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 36.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 71.67it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.584, train_acc: 0.695\n",
      "valid_loss: 0.508, valid_acc: 0.776\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.26it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.359, train_acc: 0.844\n",
      "valid_loss: 0.374, valid_acc: 0.833\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 70.92it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.200, train_acc: 0.925\n",
      "valid_loss: 0.377, valid_acc: 0.852\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.62it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.34it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.113, train_acc: 0.962\n",
      "valid_loss: 0.462, valid_acc: 0.817\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 71.51it/s]\n",
      "test_loss: 0.368, test_acc: 0.840\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_4layer_base_adam_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 344,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 63.09it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.497\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 29.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.43it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.498\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 62.97it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.498\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 62.11it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 29.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 56.49it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.497\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 58.88it/s]\n",
      "test_loss: 0.693, test_acc: 0.499\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.72it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.547\n",
      "valid_loss: 0.687, valid_acc: 0.543\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.21it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.610, train_acc: 0.681\n",
      "valid_loss: 0.716, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.75it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.15it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.407, train_acc: 0.808\n",
      "valid_loss: 0.358, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.83it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.208, train_acc: 0.919\n",
      "valid_loss: 0.352, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.29it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.131, train_acc: 0.953\n",
      "valid_loss: 0.395, valid_acc: 0.833\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.50it/s]\n",
      "test_loss: 0.348, test_acc: 0.864\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_2layer_base_rmsprop_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 183,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.29it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.694, train_acc: 0.553\n",
      "valid_loss: 0.643, valid_acc: 0.631\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.40it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.604, train_acc: 0.679\n",
      "valid_loss: 0.496, valid_acc: 0.779\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.07it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.298, train_acc: 0.876\n",
      "valid_loss: 0.338, valid_acc: 0.866\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.13it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.162, train_acc: 0.940\n",
      "valid_loss: 0.372, valid_acc: 0.854\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.12it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.090, train_acc: 0.969\n",
      "valid_loss: 0.428, valid_acc: 0.867\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 74.35it/s]\n",
      "test_loss: 0.328, test_acc: 0.866\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_3layer_base_rmsprop_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 263,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 70.27it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.700, train_acc: 0.509\n",
      "valid_loss: 0.694, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.83it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.696, train_acc: 0.501\n",
      "valid_loss: 0.698, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.50it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.696, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.64it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.696, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.99it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.697, train_acc: 0.499\n",
      "valid_loss: 0.709, valid_acc: 0.497\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 72.28it/s]\n",
      "test_loss: 0.693, test_acc: 0.501\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_4layer_base_rmsprop_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 344,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 31.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 59.07it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.696, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 28.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.60it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.695, train_acc: 0.504\n",
      "valid_loss: 0.694, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.60it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.695, train_acc: 0.500\n",
      "valid_loss: 0.696, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 29.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 59.15it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.694, train_acc: 0.498\n",
      "valid_loss: 0.695, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 28.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 59.60it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.694, train_acc: 0.498\n",
      "valid_loss: 0.695, valid_acc: 0.503\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 60.55it/s]\n",
      "test_loss: 0.693, test_acc: 0.499\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer_name = [\"adagrad\", \"adam\", \"rmsprop\"]\n",
    "layers = [1, 2,3,4]\n",
    "layer_table_dict = {}\n",
    "i = 0\n",
    "on = 0\n",
    "for opt_nm in optimizer_name:\n",
    "    if opt_nm == \"adagrad\":\n",
    "        on = 1\n",
    "    elif opt_nm == \"adam\":\n",
    "        on = 2\n",
    "    else:\n",
    "        on = 3\n",
    "\n",
    "    test_loss_vect = []\n",
    "    test_acc_vect = []\n",
    "\n",
    "    for lay in layers:\n",
    "        new_hp = HyperParams()\n",
    "        new_hp.OPTIM = opt_nm\n",
    "        new_hp.LR = 0.001\n",
    "        new_hp.N_LAYERS = lay\n",
    "        model_name_str = f'lstm_{lay}layer_base_{opt_nm}_e32_h{100}_{1}ed'\n",
    "        print(f'-----------------------------------------')\n",
    "        print(f'------ New Model: {model_name_str} ------')\n",
    "        rtr_vals = train_and_test_model_with_hparams(new_hp, model_name_str )\n",
    "        layer_table_dict[i] = [float(on),\n",
    "                                float(lay),   # number of layers\n",
    "                                float(100), # number of hidden dim\n",
    "                                float(1),\n",
    "                                float(rtr_vals['num_params']),\n",
    "                                rtr_vals[\"test_loss\"],\n",
    "                                rtr_vals[\"test_acc\"],\n",
    "                                rtr_vals[\"train_losses\"],\n",
    "                                rtr_vals[\"train_accs\"],\n",
    "                                rtr_vals[\"valid_losses\"],\n",
    "                                rtr_vals[\"valid_accs\"]]\n",
    "        print(f'-----------------------------------------')\n",
    "        test_loss_vect.append(rtr_vals[\"test_loss\"])\n",
    "        test_acc_vect.append(rtr_vals[\"test_acc\"])\n",
    "        i = i + 1\n",
    "\n",
    "    plt_title = opt_nm\n",
    "    parameter_name = 'num_layers'\n",
    "    parameter_setting_vect = layers\n",
    "    plot_test_loss_and_accuracy_over_parameter_change(test_loss_vect, test_acc_vect, parameter_setting_vect, parameter_name, plt_title)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "    OptimType  NumLayers  NumHiddenDim  NumEmbededDim  NumParams  Test_Loss  \\\n0         1.0        1.0         100.0            1.0   102202.0   0.492422   \n1         1.0        2.0         100.0            1.0   183002.0   0.402142   \n2         1.0        3.0         100.0            1.0   263802.0   0.383692   \n3         1.0        4.0         100.0            1.0   344602.0   0.363901   \n4         2.0        1.0         100.0            1.0   102202.0   0.402540   \n5         2.0        2.0         100.0            1.0   183002.0   0.383443   \n6         2.0        3.0         100.0            1.0   263802.0   0.368382   \n7         2.0        4.0         100.0            1.0   344602.0   0.693169   \n8         3.0        1.0         100.0            1.0   102202.0   0.348304   \n9         3.0        2.0         100.0            1.0   183002.0   0.327672   \n10        3.0        3.0         100.0            1.0   263802.0   0.693165   \n11        3.0        4.0         100.0            1.0   344602.0   0.693389   \n\n    Test_Acc                                         Train_Loss  \\\n0   0.812798  [0.6931541081977217, 0.6929038506664642, 0.651...   \n1   0.821627  [0.6931563993022867, 0.6927227165601025, 0.632...   \n2   0.831746  [0.6931308514451328, 0.6931339402721353, 0.671...   \n3   0.840278  [0.6931686014345247, 0.6931629370336663, 0.683...   \n4   0.845040  [0.6891940813358516, 0.5509744842575021, 0.377...   \n5   0.852579  [0.6904777922042429, 0.39927419991525887, 0.21...   \n6   0.839683  [0.6897021365492311, 0.5836437386192688, 0.358...   \n7   0.498710  [0.6932700211054659, 0.6932192047981367, 0.693...   \n8   0.864087  [0.6921269578476474, 0.6099212711804534, 0.406...   \n9   0.866369  [0.6938101748897605, 0.6040296984045472, 0.297...   \n10  0.501290  [0.7000981845267832, 0.6955934705799574, 0.696...   \n11  0.498810  [0.6958762062739019, 0.6945493965932767, 0.694...   \n\n                                            Train_Acc  \\\n0   [0.4996371643183983, 0.5299983859878696, 0.648...   \n1   [0.5009010241456228, 0.5210045819413172, 0.694...   \n2   [0.5049902300312095, 0.5007950244701072, 0.578...   \n3   [0.49945369909887444, 0.4978473718035711, 0.54...   \n4   [0.5339571260426142, 0.7291870715683454, 0.836...   \n5   [0.5421110723116627, 0.8254403324976359, 0.918...   \n6   [0.5164669103818397, 0.6954093487295386, 0.844...   \n7   [0.49722767161996395, 0.49787591091574057, 0.4...   \n8   [0.5473132922224803, 0.6813804824874826, 0.807...   \n9   [0.552857975600517, 0.6791707632476336, 0.8763...   \n10  [0.5088715093593075, 0.501002950292744, 0.5003...   \n11  [0.49945369901722425, 0.503954678365629, 0.500...   \n\n                                           Valid_Loss  \\\n0   [0.6931004940338854, 0.6921972992285242, 0.651...   \n1   [0.6930876419229327, 0.6855955528763106, 0.485...   \n2   [0.6931233248620663, 0.6930507680155197, 0.657...   \n3   [0.6931403526720011, 0.6931466314027894, 0.592...   \n4   [0.6731330662403466, 0.5128323503260342, 0.420...   \n5   [0.5883986140197178, 0.4573044051539223, 0.384...   \n6   [0.7244228641941862, 0.5076714686627658, 0.373...   \n7   [0.6931384307033611, 0.6931739269562487, 0.693...   \n8   [0.6873849416678807, 0.7163870975656329, 0.357...   \n9   [0.6434842876668246, 0.4955803521399228, 0.337...   \n10  [0.6939136408409983, 0.698224498415893, 0.6932...   \n11  [0.693235788705214, 0.6938436065080031, 0.6961...   \n\n                                            Valid_Acc  \n0   [0.5027515905083351, 0.6193003317095199, 0.678...  \n1   [0.5027515905083351, 0.5172956124791559, 0.792...  \n2   [0.5027515905083351, 0.5550314671588394, 0.559...  \n3   [0.5027515905083351, 0.49724844435475907, 0.65...  \n4   [0.5768475026454566, 0.7517688870429993, 0.811...  \n5   [0.7236635426305374, 0.7869497031535743, 0.850...  \n6   [0.72268083410443, 0.7761399543510293, 0.83333...  \n7   [0.5027515905083351, 0.49724844435475907, 0.50...  \n8   [0.5432390109548029, 0.5035377510313718, 0.848...  \n9   [0.6305031630228151, 0.7788915251785854, 0.865...  \n10  [0.5027515905083351, 0.5027515905083351, 0.497...  \n11  [0.5027515905083351, 0.49724844435475907, 0.50...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OptimType</th>\n      <th>NumLayers</th>\n      <th>NumHiddenDim</th>\n      <th>NumEmbededDim</th>\n      <th>NumParams</th>\n      <th>Test_Loss</th>\n      <th>Test_Acc</th>\n      <th>Train_Loss</th>\n      <th>Train_Acc</th>\n      <th>Valid_Loss</th>\n      <th>Valid_Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>102202.0</td>\n      <td>0.492422</td>\n      <td>0.812798</td>\n      <td>[0.6931541081977217, 0.6929038506664642, 0.651...</td>\n      <td>[0.4996371643183983, 0.5299983859878696, 0.648...</td>\n      <td>[0.6931004940338854, 0.6921972992285242, 0.651...</td>\n      <td>[0.5027515905083351, 0.6193003317095199, 0.678...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>183002.0</td>\n      <td>0.402142</td>\n      <td>0.821627</td>\n      <td>[0.6931563993022867, 0.6927227165601025, 0.632...</td>\n      <td>[0.5009010241456228, 0.5210045819413172, 0.694...</td>\n      <td>[0.6930876419229327, 0.6855955528763106, 0.485...</td>\n      <td>[0.5027515905083351, 0.5172956124791559, 0.792...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>263802.0</td>\n      <td>0.383692</td>\n      <td>0.831746</td>\n      <td>[0.6931308514451328, 0.6931339402721353, 0.671...</td>\n      <td>[0.5049902300312095, 0.5007950244701072, 0.578...</td>\n      <td>[0.6931233248620663, 0.6930507680155197, 0.657...</td>\n      <td>[0.5027515905083351, 0.5550314671588394, 0.559...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>344602.0</td>\n      <td>0.363901</td>\n      <td>0.840278</td>\n      <td>[0.6931686014345247, 0.6931629370336663, 0.683...</td>\n      <td>[0.49945369909887444, 0.4978473718035711, 0.54...</td>\n      <td>[0.6931403526720011, 0.6931466314027894, 0.592...</td>\n      <td>[0.5027515905083351, 0.49724844435475907, 0.65...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>102202.0</td>\n      <td>0.402540</td>\n      <td>0.845040</td>\n      <td>[0.6891940813358516, 0.5509744842575021, 0.377...</td>\n      <td>[0.5339571260426142, 0.7291870715683454, 0.836...</td>\n      <td>[0.6731330662403466, 0.5128323503260342, 0.420...</td>\n      <td>[0.5768475026454566, 0.7517688870429993, 0.811...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>183002.0</td>\n      <td>0.383443</td>\n      <td>0.852579</td>\n      <td>[0.6904777922042429, 0.39927419991525887, 0.21...</td>\n      <td>[0.5421110723116627, 0.8254403324976359, 0.918...</td>\n      <td>[0.5883986140197178, 0.4573044051539223, 0.384...</td>\n      <td>[0.7236635426305374, 0.7869497031535743, 0.850...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>263802.0</td>\n      <td>0.368382</td>\n      <td>0.839683</td>\n      <td>[0.6897021365492311, 0.5836437386192688, 0.358...</td>\n      <td>[0.5164669103818397, 0.6954093487295386, 0.844...</td>\n      <td>[0.7244228641941862, 0.5076714686627658, 0.373...</td>\n      <td>[0.72268083410443, 0.7761399543510293, 0.83333...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>344602.0</td>\n      <td>0.693169</td>\n      <td>0.498710</td>\n      <td>[0.6932700211054659, 0.6932192047981367, 0.693...</td>\n      <td>[0.49722767161996395, 0.49787591091574057, 0.4...</td>\n      <td>[0.6931384307033611, 0.6931739269562487, 0.693...</td>\n      <td>[0.5027515905083351, 0.49724844435475907, 0.50...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>102202.0</td>\n      <td>0.348304</td>\n      <td>0.864087</td>\n      <td>[0.6921269578476474, 0.6099212711804534, 0.406...</td>\n      <td>[0.5473132922224803, 0.6813804824874826, 0.807...</td>\n      <td>[0.6873849416678807, 0.7163870975656329, 0.357...</td>\n      <td>[0.5432390109548029, 0.5035377510313718, 0.848...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>183002.0</td>\n      <td>0.327672</td>\n      <td>0.866369</td>\n      <td>[0.6938101748897605, 0.6040296984045472, 0.297...</td>\n      <td>[0.552857975600517, 0.6791707632476336, 0.8763...</td>\n      <td>[0.6434842876668246, 0.4955803521399228, 0.337...</td>\n      <td>[0.6305031630228151, 0.7788915251785854, 0.865...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>263802.0</td>\n      <td>0.693165</td>\n      <td>0.501290</td>\n      <td>[0.7000981845267832, 0.6955934705799574, 0.696...</td>\n      <td>[0.5088715093593075, 0.501002950292744, 0.5003...</td>\n      <td>[0.6939136408409983, 0.698224498415893, 0.6932...</td>\n      <td>[0.5027515905083351, 0.5027515905083351, 0.497...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>344602.0</td>\n      <td>0.693389</td>\n      <td>0.498810</td>\n      <td>[0.6958762062739019, 0.6945493965932767, 0.694...</td>\n      <td>[0.49945369901722425, 0.503954678365629, 0.500...</td>\n      <td>[0.693235788705214, 0.6938436065080031, 0.6961...</td>\n      <td>[0.5027515905083351, 0.49724844435475907, 0.50...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data=layer_table_dict, orient=\"index\", columns = [\"OptimType\", \"NumLayers\", \"NumHiddenDim\", \"NumEmbededDim\", \"NumParams\",  \"\"\n",
    "  \"Test_Loss\", \"Test_Acc\",                                                                                                                                \"Train_Loss\",\n",
    "  \"Train_Acc\",\n",
    "  \"Valid_Loss\",\n",
    "  \"Valid_Acc\",  ])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 (d) Wider LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h1_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,820 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 68.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 107.44it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.503\n",
      "valid_loss: 0.693, valid_acc: 0.535\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 68.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 116.99it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.523\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.68it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.561\n",
      "valid_loss: 0.693, valid_acc: 0.551\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 115.80it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.607\n",
      "valid_loss: 0.693, valid_acc: 0.553\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 107.19it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.606\n",
      "valid_loss: 0.693, valid_acc: 0.558\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 109.83it/s]\n",
      "test_loss: 0.693, test_acc: 0.566\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h2_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,846 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 75.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.55it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.511\n",
      "valid_loss: 0.693, valid_acc: 0.534\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 115.50it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.538\n",
      "valid_loss: 0.693, valid_acc: 0.561\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.46it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.581\n",
      "valid_loss: 0.693, valid_acc: 0.581\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.17it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.574\n",
      "valid_loss: 0.693, valid_acc: 0.595\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 115.33it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.692, train_acc: 0.642\n",
      "valid_loss: 0.693, valid_acc: 0.603\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 114.70it/s]\n",
      "test_loss: 0.693, test_acc: 0.601\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h5_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,972 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 76.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 116.98it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 76.58it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.69it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.511\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 112.44it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.554\n",
      "valid_loss: 0.693, valid_acc: 0.532\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.15it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.556\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.45it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.592\n",
      "valid_loss: 0.693, valid_acc: 0.557\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 105.27it/s]\n",
      "test_loss: 0.693, test_acc: 0.557\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h10_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 61,342 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.46it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 117.08it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.511\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 75.98it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.26it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.570\n",
      "valid_loss: 0.693, valid_acc: 0.566\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 75.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 117.27it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.623\n",
      "valid_loss: 0.693, valid_acc: 0.604\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.95it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.628\n",
      "valid_loss: 0.693, valid_acc: 0.632\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 100.08it/s]\n",
      "test_loss: 0.693, test_acc: 0.619\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h20_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 62,682 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.63it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 115.71it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.532\n",
      "valid_loss: 0.693, valid_acc: 0.516\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.35it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.550\n",
      "valid_loss: 0.693, valid_acc: 0.512\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 69.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 117.28it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.692, train_acc: 0.587\n",
      "valid_loss: 0.687, valid_acc: 0.570\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.57it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.617, train_acc: 0.701\n",
      "valid_loss: 0.566, valid_acc: 0.758\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 105.41it/s]\n",
      "test_loss: 0.561, test_acc: 0.767\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h40_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 67,762 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.32it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.87it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.524\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 69.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.67it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.554\n",
      "valid_loss: 0.693, valid_acc: 0.577\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.67it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.692, train_acc: 0.565\n",
      "valid_loss: 0.690, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.63it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.603, train_acc: 0.707\n",
      "valid_loss: 0.556, valid_acc: 0.770\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 108.25it/s]\n",
      "test_loss: 0.554, test_acc: 0.768\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h60_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 76,042 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 68.48it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.97it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.14it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.513\n",
      "valid_loss: 0.693, valid_acc: 0.521\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.99it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.692, train_acc: 0.565\n",
      "valid_loss: 0.682, valid_acc: 0.760\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.99it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.37it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.612, train_acc: 0.694\n",
      "valid_loss: 0.562, valid_acc: 0.759\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.35it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.523, train_acc: 0.797\n",
      "valid_loss: 0.580, valid_acc: 0.735\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 101.43it/s]\n",
      "test_loss: 0.552, test_acc: 0.773\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h80_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 87,522 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.36it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.67it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.42it/s] \n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.518\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.43it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.678, train_acc: 0.589\n",
      "valid_loss: 0.591, valid_acc: 0.734\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 62.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.40it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.541, train_acc: 0.779\n",
      "valid_loss: 0.519, valid_acc: 0.792\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.83it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.477, train_acc: 0.822\n",
      "valid_loss: 0.513, valid_acc: 0.791\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 100.43it/s]\n",
      "test_loss: 0.506, test_acc: 0.800\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.75it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.14it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.530\n",
      "valid_loss: 0.692, valid_acc: 0.619\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.23it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.652, train_acc: 0.648\n",
      "valid_loss: 0.652, valid_acc: 0.679\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.18it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.522, train_acc: 0.796\n",
      "valid_loss: 0.539, valid_acc: 0.778\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.99it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.470, train_acc: 0.830\n",
      "valid_loss: 0.499, valid_acc: 0.803\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 91.35it/s]\n",
      "test_loss: 0.492, test_acc: 0.813\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h120_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 120,082 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.63it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.556\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.10it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.695, train_acc: 0.535\n",
      "valid_loss: 0.690, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.46it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.628, train_acc: 0.678\n",
      "valid_loss: 0.546, valid_acc: 0.769\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.94it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.62it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.502, train_acc: 0.807\n",
      "valid_loss: 0.499, valid_acc: 0.801\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.88it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.450, train_acc: 0.839\n",
      "valid_loss: 0.488, valid_acc: 0.809\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 81.39it/s]\n",
      "test_loss: 0.481, test_acc: 0.815\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h140_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 141,162 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.99it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.496\n",
      "valid_loss: 0.693, valid_acc: 0.564\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.40it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.692, train_acc: 0.527\n",
      "valid_loss: 0.672, valid_acc: 0.767\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.50it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.629, train_acc: 0.683\n",
      "valid_loss: 0.613, valid_acc: 0.706\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.92it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.510, train_acc: 0.802\n",
      "valid_loss: 0.512, valid_acc: 0.798\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.23it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.463, train_acc: 0.832\n",
      "valid_loss: 0.504, valid_acc: 0.801\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.74it/s]\n",
      "test_loss: 0.494, test_acc: 0.812\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 159,072 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.44it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.11it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.523\n",
      "valid_loss: 0.693, valid_acc: 0.523\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.55it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.691, train_acc: 0.570\n",
      "valid_loss: 0.678, valid_acc: 0.512\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.91it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.02it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.574, train_acc: 0.741\n",
      "valid_loss: 0.537, valid_acc: 0.777\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.38it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.67it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.485, train_acc: 0.817\n",
      "valid_loss: 0.528, valid_acc: 0.785\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.62it/s]\n",
      "test_loss: 0.518, test_acc: 0.790\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h160_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 165,442 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.98it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.503\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.85it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.80it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.498\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.12it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.526\n",
      "valid_loss: 0.693, valid_acc: 0.535\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.90it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.690, train_acc: 0.571\n",
      "valid_loss: 0.676, valid_acc: 0.668\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.83it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.593, train_acc: 0.722\n",
      "valid_loss: 0.541, valid_acc: 0.773\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 94.57it/s]\n",
      "test_loss: 0.532, test_acc: 0.781\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h180_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 192,922 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.01it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.90it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.519\n",
      "valid_loss: 0.703, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.65it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.691, train_acc: 0.500\n",
      "valid_loss: 0.690, valid_acc: 0.498\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.21it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.678, train_acc: 0.558\n",
      "valid_loss: 0.655, valid_acc: 0.566\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.92it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.540, train_acc: 0.782\n",
      "valid_loss: 0.530, valid_acc: 0.777\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.91it/s]\n",
      "test_loss: 0.527, test_acc: 0.781\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 223,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.10it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.06it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.521\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.12it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.686, train_acc: 0.559\n",
      "valid_loss: 0.660, valid_acc: 0.603\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.75it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.02it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.598, train_acc: 0.729\n",
      "valid_loss: 0.538, valid_acc: 0.782\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.44it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.61it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.509, train_acc: 0.802\n",
      "valid_loss: 0.514, valid_acc: 0.791\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 78.05it/s]\n",
      "test_loss: 0.508, test_acc: 0.799\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h220_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 257,482 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.98it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.21it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.697, train_acc: 0.544\n",
      "valid_loss: 0.683, valid_acc: 0.556\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.66it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.663, train_acc: 0.631\n",
      "valid_loss: 0.575, valid_acc: 0.753\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.06it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.544, train_acc: 0.776\n",
      "valid_loss: 0.535, valid_acc: 0.781\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.08it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.491, train_acc: 0.813\n",
      "valid_loss: 0.592, valid_acc: 0.758\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 75.42it/s]\n",
      "test_loss: 0.532, test_acc: 0.790\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h240_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 294,562 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 71.88it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.498\n",
      "valid_loss: 0.693, valid_acc: 0.521\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.63it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.514\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.05it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.691, train_acc: 0.551\n",
      "valid_loss: 0.687, valid_acc: 0.706\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.66it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.681, train_acc: 0.683\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 40.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.41it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.583, train_acc: 0.688\n",
      "valid_loss: 0.487, valid_acc: 0.798\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 71.94it/s]\n",
      "test_loss: 0.477, test_acc: 0.812\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h260_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 334,842 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.53it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.503\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 60.61it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.692, train_acc: 0.519\n",
      "valid_loss: 0.688, valid_acc: 0.698\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.32it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.686, train_acc: 0.565\n",
      "valid_loss: 0.684, valid_acc: 0.512\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 31.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.42it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.637, train_acc: 0.673\n",
      "valid_loss: 0.516, valid_acc: 0.806\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.86it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.476, train_acc: 0.819\n",
      "valid_loss: 0.465, valid_acc: 0.814\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 72.38it/s]\n",
      "test_loss: 0.460, test_acc: 0.822\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h280_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 378,322 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 36.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.64it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.498\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 36.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 70.84it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.691, train_acc: 0.525\n",
      "valid_loss: 0.688, valid_acc: 0.499\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 36.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 70.13it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.687, train_acc: 0.618\n",
      "valid_loss: 0.685, valid_acc: 0.692\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 36.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 71.14it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.672, train_acc: 0.663\n",
      "valid_loss: 0.662, valid_acc: 0.743\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 36.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.76it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.552, train_acc: 0.756\n",
      "valid_loss: 0.485, valid_acc: 0.812\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 68.15it/s]\n",
      "test_loss: 0.479, test_acc: 0.818\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h300_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 425,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.84it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.38it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.514\n",
      "valid_loss: 0.692, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 35.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.55it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.695, train_acc: 0.580\n",
      "valid_loss: 0.681, valid_acc: 0.750\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.91it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.641, train_acc: 0.642\n",
      "valid_loss: 0.541, valid_acc: 0.762\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.83it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.490, train_acc: 0.813\n",
      "valid_loss: 0.496, valid_acc: 0.803\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 69.09it/s]\n",
      "test_loss: 0.482, test_acc: 0.815\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h320_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 474,882 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.70it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.66it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.695, train_acc: 0.513\n",
      "valid_loss: 0.691, valid_acc: 0.500\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.46it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.688, train_acc: 0.614\n",
      "valid_loss: 0.691, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.90it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.682, train_acc: 0.540\n",
      "valid_loss: 0.685, valid_acc: 0.498\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.09it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.611, train_acc: 0.690\n",
      "valid_loss: 0.528, valid_acc: 0.781\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 65.79it/s]\n",
      "test_loss: 0.521, test_acc: 0.796\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h1_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,820 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.91it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.530\n",
      "valid_loss: 0.683, valid_acc: 0.563\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.85it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.535, train_acc: 0.745\n",
      "valid_loss: 0.473, valid_acc: 0.824\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.58it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.362, train_acc: 0.868\n",
      "valid_loss: 0.390, valid_acc: 0.840\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.87it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.270, train_acc: 0.908\n",
      "valid_loss: 0.369, valid_acc: 0.851\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.34it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.213, train_acc: 0.932\n",
      "valid_loss: 0.372, valid_acc: 0.853\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 113.52it/s]\n",
      "test_loss: 0.372, test_acc: 0.847\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h2_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,846 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.34it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.685, train_acc: 0.545\n",
      "valid_loss: 0.699, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 112.77it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.510, train_acc: 0.776\n",
      "valid_loss: 0.416, valid_acc: 0.840\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.44it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.81it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.377, train_acc: 0.848\n",
      "valid_loss: 0.534, valid_acc: 0.743\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.62it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.61it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.287, train_acc: 0.901\n",
      "valid_loss: 0.368, valid_acc: 0.852\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 108.38it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.202, train_acc: 0.934\n",
      "valid_loss: 0.390, valid_acc: 0.848\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 105.35it/s]\n",
      "test_loss: 0.361, test_acc: 0.854\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h5_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,972 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.55it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.676, train_acc: 0.543\n",
      "valid_loss: 0.507, valid_acc: 0.770\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.38it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.365, train_acc: 0.851\n",
      "valid_loss: 0.311, valid_acc: 0.870\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.36it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.199, train_acc: 0.930\n",
      "valid_loss: 0.314, valid_acc: 0.877\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.72it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.11it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.120, train_acc: 0.963\n",
      "valid_loss: 0.383, valid_acc: 0.846\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.52it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.077, train_acc: 0.979\n",
      "valid_loss: 0.367, valid_acc: 0.875\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 114.43it/s]\n",
      "test_loss: 0.309, test_acc: 0.873\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h10_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 61,342 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.15it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.672, train_acc: 0.556\n",
      "valid_loss: 0.510, valid_acc: 0.794\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.74it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.357, train_acc: 0.854\n",
      "valid_loss: 0.320, valid_acc: 0.870\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.05it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.198, train_acc: 0.930\n",
      "valid_loss: 0.310, valid_acc: 0.875\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 107.59it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.117, train_acc: 0.963\n",
      "valid_loss: 0.363, valid_acc: 0.868\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 107.06it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.069, train_acc: 0.981\n",
      "valid_loss: 0.402, valid_acc: 0.876\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 103.60it/s]\n",
      "test_loss: 0.308, test_acc: 0.877\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h20_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 62,682 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 115.12it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.687, train_acc: 0.538\n",
      "valid_loss: 0.641, valid_acc: 0.690\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 116.12it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.368, train_acc: 0.846\n",
      "valid_loss: 0.337, valid_acc: 0.861\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 75.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 116.22it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.199, train_acc: 0.928\n",
      "valid_loss: 0.342, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.57it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.119, train_acc: 0.961\n",
      "valid_loss: 0.373, valid_acc: 0.871\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.06it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.071, train_acc: 0.979\n",
      "valid_loss: 0.460, valid_acc: 0.856\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 113.27it/s]\n",
      "test_loss: 0.335, test_acc: 0.864\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h40_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 67,762 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.44it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.682, train_acc: 0.546\n",
      "valid_loss: 0.526, valid_acc: 0.749\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.48it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.94it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.404, train_acc: 0.821\n",
      "valid_loss: 0.325, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.57it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.198, train_acc: 0.927\n",
      "valid_loss: 0.343, valid_acc: 0.872\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.61it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.111, train_acc: 0.963\n",
      "valid_loss: 0.387, valid_acc: 0.875\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.81it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.066, train_acc: 0.980\n",
      "valid_loss: 0.446, valid_acc: 0.864\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 111.26it/s]\n",
      "test_loss: 0.323, test_acc: 0.865\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h60_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 76,042 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 66.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 107.21it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.687, train_acc: 0.534\n",
      "valid_loss: 0.649, valid_acc: 0.660\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 67.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.66it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.435, train_acc: 0.806\n",
      "valid_loss: 0.414, valid_acc: 0.827\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 66.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 107.10it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.229, train_acc: 0.912\n",
      "valid_loss: 0.351, valid_acc: 0.857\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 66.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.72it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.141, train_acc: 0.951\n",
      "valid_loss: 0.391, valid_acc: 0.859\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.80it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.38it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.087, train_acc: 0.972\n",
      "valid_loss: 0.487, valid_acc: 0.867\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 106.51it/s]\n",
      "test_loss: 0.347, test_acc: 0.858\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h80_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 87,522 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.25it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.687, train_acc: 0.542\n",
      "valid_loss: 0.655, valid_acc: 0.660\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.53it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.598, train_acc: 0.677\n",
      "valid_loss: 0.416, valid_acc: 0.821\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 62.91it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.39it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.346, train_acc: 0.855\n",
      "valid_loss: 0.362, valid_acc: 0.862\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 64.55it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.15it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.201, train_acc: 0.924\n",
      "valid_loss: 0.360, valid_acc: 0.850\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.92it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.131, train_acc: 0.956\n",
      "valid_loss: 0.461, valid_acc: 0.842\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 105.38it/s]\n",
      "test_loss: 0.358, test_acc: 0.855\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.94it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.00it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.534\n",
      "valid_loss: 0.673, valid_acc: 0.577\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 60.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.36it/s] \n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.551, train_acc: 0.729\n",
      "valid_loss: 0.513, valid_acc: 0.752\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.58it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.378, train_acc: 0.837\n",
      "valid_loss: 0.421, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.70it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.242, train_acc: 0.907\n",
      "valid_loss: 0.421, valid_acc: 0.839\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.04it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.151, train_acc: 0.947\n",
      "valid_loss: 0.400, valid_acc: 0.846\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.31it/s]\n",
      "test_loss: 0.403, test_acc: 0.845\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h120_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 120,082 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.00it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.537\n",
      "valid_loss: 0.723, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.65it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.37it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.633, train_acc: 0.657\n",
      "valid_loss: 0.517, valid_acc: 0.737\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.20it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.433, train_acc: 0.801\n",
      "valid_loss: 0.377, valid_acc: 0.838\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.91it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.240, train_acc: 0.906\n",
      "valid_loss: 0.424, valid_acc: 0.809\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.26it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.154, train_acc: 0.947\n",
      "valid_loss: 0.419, valid_acc: 0.840\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.44it/s]\n",
      "test_loss: 0.386, test_acc: 0.835\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h140_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 141,162 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.76it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.691, train_acc: 0.529\n",
      "valid_loss: 0.674, valid_acc: 0.635\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.72it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.511, train_acc: 0.759\n",
      "valid_loss: 0.382, valid_acc: 0.845\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.82it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.308, train_acc: 0.876\n",
      "valid_loss: 0.374, valid_acc: 0.852\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.21it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.188, train_acc: 0.930\n",
      "valid_loss: 0.389, valid_acc: 0.849\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.92it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.124, train_acc: 0.958\n",
      "valid_loss: 0.447, valid_acc: 0.847\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.70it/s]\n",
      "test_loss: 0.369, test_acc: 0.854\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 159,072 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.22it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.688, train_acc: 0.537\n",
      "valid_loss: 0.668, valid_acc: 0.622\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.32it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.610, train_acc: 0.687\n",
      "valid_loss: 0.434, valid_acc: 0.801\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.59it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.318, train_acc: 0.870\n",
      "valid_loss: 0.524, valid_acc: 0.736\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.80it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.209, train_acc: 0.922\n",
      "valid_loss: 0.425, valid_acc: 0.805\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.94it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.122, train_acc: 0.958\n",
      "valid_loss: 0.420, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.91it/s]\n",
      "test_loss: 0.417, test_acc: 0.859\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h160_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 165,442 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.85it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.686, train_acc: 0.531\n",
      "valid_loss: 0.657, valid_acc: 0.609\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.80it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.641, train_acc: 0.639\n",
      "valid_loss: 0.636, valid_acc: 0.619\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.95it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.561, train_acc: 0.722\n",
      "valid_loss: 0.563, valid_acc: 0.699\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.83it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.298, train_acc: 0.874\n",
      "valid_loss: 0.470, valid_acc: 0.770\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.49it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.178, train_acc: 0.935\n",
      "valid_loss: 0.404, valid_acc: 0.856\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 86.80it/s]\n",
      "test_loss: 0.401, test_acc: 0.856\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h180_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 192,922 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.54it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.697, train_acc: 0.544\n",
      "valid_loss: 0.678, valid_acc: 0.614\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.59it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.630, train_acc: 0.661\n",
      "valid_loss: 0.445, valid_acc: 0.801\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.26it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.359, train_acc: 0.848\n",
      "valid_loss: 0.452, valid_acc: 0.794\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.33it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.210, train_acc: 0.920\n",
      "valid_loss: 0.369, valid_acc: 0.855\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.62it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.129, train_acc: 0.955\n",
      "valid_loss: 0.412, valid_acc: 0.852\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 88.20it/s]\n",
      "test_loss: 0.367, test_acc: 0.856\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 223,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.82it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.695, train_acc: 0.527\n",
      "valid_loss: 0.682, valid_acc: 0.556\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.51it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.654, train_acc: 0.650\n",
      "valid_loss: 0.635, valid_acc: 0.613\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.64it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.580, train_acc: 0.706\n",
      "valid_loss: 0.617, valid_acc: 0.632\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.85it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.378, train_acc: 0.834\n",
      "valid_loss: 0.394, valid_acc: 0.835\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.43it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.211, train_acc: 0.919\n",
      "valid_loss: 0.408, valid_acc: 0.842\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.37it/s]\n",
      "test_loss: 0.387, test_acc: 0.834\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h220_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 257,482 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.61it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.531\n",
      "valid_loss: 0.675, valid_acc: 0.560\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.23it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.641, train_acc: 0.638\n",
      "valid_loss: 0.622, valid_acc: 0.635\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.19it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.573, train_acc: 0.708\n",
      "valid_loss: 0.500, valid_acc: 0.752\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.04it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.321, train_acc: 0.864\n",
      "valid_loss: 0.429, valid_acc: 0.816\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.83it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.212, train_acc: 0.920\n",
      "valid_loss: 0.476, valid_acc: 0.828\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 79.55it/s]\n",
      "test_loss: 0.428, test_acc: 0.815\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h240_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 294,562 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.46it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.694, train_acc: 0.524\n",
      "valid_loss: 0.669, valid_acc: 0.599\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.82it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.550, train_acc: 0.713\n",
      "valid_loss: 0.467, valid_acc: 0.779\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.37it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.372, train_acc: 0.844\n",
      "valid_loss: 0.441, valid_acc: 0.792\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.34it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.212, train_acc: 0.921\n",
      "valid_loss: 0.428, valid_acc: 0.829\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.71it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.134, train_acc: 0.955\n",
      "valid_loss: 0.468, valid_acc: 0.833\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.34it/s]\n",
      "test_loss: 0.408, test_acc: 0.835\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h260_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 334,842 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.11it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.550\n",
      "valid_loss: 0.662, valid_acc: 0.657\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.72it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.68it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.514, train_acc: 0.756\n",
      "valid_loss: 0.382, valid_acc: 0.831\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.68it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.273, train_acc: 0.891\n",
      "valid_loss: 0.458, valid_acc: 0.788\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.73it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.187, train_acc: 0.933\n",
      "valid_loss: 0.431, valid_acc: 0.864\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.65it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.117, train_acc: 0.961\n",
      "valid_loss: 0.467, valid_acc: 0.861\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 72.49it/s]\n",
      "test_loss: 0.378, test_acc: 0.834\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h280_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 378,322 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 36.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.79it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.691, train_acc: 0.525\n",
      "valid_loss: 0.684, valid_acc: 0.525\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.31it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.659, train_acc: 0.634\n",
      "valid_loss: 0.629, valid_acc: 0.631\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.81it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.581, train_acc: 0.704\n",
      "valid_loss: 0.474, valid_acc: 0.773\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.91it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.313, train_acc: 0.868\n",
      "valid_loss: 0.377, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 36.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.06it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.177, train_acc: 0.934\n",
      "valid_loss: 0.401, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 72.64it/s]\n",
      "test_loss: 0.372, test_acc: 0.847\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h300_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 425,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.34it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.697, train_acc: 0.528\n",
      "valid_loss: 0.677, valid_acc: 0.585\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.25it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.640, train_acc: 0.647\n",
      "valid_loss: 0.628, valid_acc: 0.616\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.36it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.17it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.445, train_acc: 0.796\n",
      "valid_loss: 0.417, valid_acc: 0.817\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.58it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.68it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.370, train_acc: 0.852\n",
      "valid_loss: 0.443, valid_acc: 0.829\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.71it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.208, train_acc: 0.922\n",
      "valid_loss: 0.435, valid_acc: 0.833\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 67.47it/s]\n",
      "test_loss: 0.412, test_acc: 0.821\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h320_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 474,882 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 33.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.11it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.522\n",
      "valid_loss: 0.672, valid_acc: 0.580\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.78it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.649, train_acc: 0.631\n",
      "valid_loss: 0.649, valid_acc: 0.591\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.67it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.575, train_acc: 0.703\n",
      "valid_loss: 0.648, valid_acc: 0.608\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 33.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.28it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.503, train_acc: 0.752\n",
      "valid_loss: 0.700, valid_acc: 0.602\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 33.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.91it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.441, train_acc: 0.790\n",
      "valid_loss: 0.744, valid_acc: 0.597\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 62.58it/s]\n",
      "test_loss: 0.662, test_acc: 0.598\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h1_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,820 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.18it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.654, train_acc: 0.602\n",
      "valid_loss: 0.617, valid_acc: 0.649\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.46it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.460, train_acc: 0.798\n",
      "valid_loss: 1.151, valid_acc: 0.566\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.69it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.663, train_acc: 0.625\n",
      "valid_loss: 0.449, valid_acc: 0.821\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.87it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.287, train_acc: 0.894\n",
      "valid_loss: 0.425, valid_acc: 0.833\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.59it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.175, train_acc: 0.939\n",
      "valid_loss: 0.487, valid_acc: 0.814\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 113.34it/s]\n",
      "test_loss: 0.430, test_acc: 0.827\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h2_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,846 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.68it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.699, train_acc: 0.544\n",
      "valid_loss: 0.691, valid_acc: 0.549\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 111.45it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.583, train_acc: 0.697\n",
      "valid_loss: 0.506, valid_acc: 0.767\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.30it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.389, train_acc: 0.843\n",
      "valid_loss: 0.471, valid_acc: 0.793\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.30it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.246, train_acc: 0.910\n",
      "valid_loss: 0.485, valid_acc: 0.802\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.99it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.167, train_acc: 0.943\n",
      "valid_loss: 0.495, valid_acc: 0.818\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 114.29it/s]\n",
      "test_loss: 0.459, test_acc: 0.798\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h5_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 60,972 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.85it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.683, train_acc: 0.579\n",
      "valid_loss: 0.658, valid_acc: 0.617\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 112.58it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.510, train_acc: 0.755\n",
      "valid_loss: 0.679, valid_acc: 0.632\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.83it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.373, train_acc: 0.847\n",
      "valid_loss: 0.452, valid_acc: 0.803\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.93it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.222, train_acc: 0.919\n",
      "valid_loss: 0.426, valid_acc: 0.826\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 115.15it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.144, train_acc: 0.951\n",
      "valid_loss: 0.461, valid_acc: 0.822\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 114.96it/s]\n",
      "test_loss: 0.425, test_acc: 0.826\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h10_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 61,342 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 112.37it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.623, train_acc: 0.633\n",
      "valid_loss: 0.469, valid_acc: 0.794\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.17it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.419, train_acc: 0.820\n",
      "valid_loss: 0.412, valid_acc: 0.808\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.44it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.225, train_acc: 0.914\n",
      "valid_loss: 0.363, valid_acc: 0.849\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.73it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.137, train_acc: 0.951\n",
      "valid_loss: 0.445, valid_acc: 0.841\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.32it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.090, train_acc: 0.969\n",
      "valid_loss: 0.509, valid_acc: 0.843\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.28it/s] \n",
      "test_loss: 0.368, test_acc: 0.856\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h20_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 62,682 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.70it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.646, train_acc: 0.599\n",
      "valid_loss: 0.553, valid_acc: 0.735\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.10it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.493, train_acc: 0.768\n",
      "valid_loss: 0.472, valid_acc: 0.787\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 74.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 114.14it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.286, train_acc: 0.884\n",
      "valid_loss: 0.378, valid_acc: 0.837\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 70.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.44it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.170, train_acc: 0.937\n",
      "valid_loss: 0.394, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:04<00:00, 73.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 113.23it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.112, train_acc: 0.962\n",
      "valid_loss: 0.432, valid_acc: 0.853\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 112.49it/s]\n",
      "test_loss: 0.379, test_acc: 0.838\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h40_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 67,762 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 67.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.97it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.661, train_acc: 0.594\n",
      "valid_loss: 0.662, valid_acc: 0.578\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 110.02it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.524, train_acc: 0.740\n",
      "valid_loss: 0.647, valid_acc: 0.603\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.76it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.439, train_acc: 0.803\n",
      "valid_loss: 0.470, valid_acc: 0.789\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 71.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.94it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.297, train_acc: 0.880\n",
      "valid_loss: 0.465, valid_acc: 0.807\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 72.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 109.50it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.260, train_acc: 0.896\n",
      "valid_loss: 0.450, valid_acc: 0.804\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 108.05it/s]\n",
      "test_loss: 0.439, test_acc: 0.811\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h60_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 76,042 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.04it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.662, train_acc: 0.591\n",
      "valid_loss: 0.627, valid_acc: 0.640\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 66.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 105.97it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.578, train_acc: 0.705\n",
      "valid_loss: 0.585, valid_acc: 0.678\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 66.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.89it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.372, train_acc: 0.840\n",
      "valid_loss: 0.503, valid_acc: 0.787\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 67.49it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 108.20it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.220, train_acc: 0.916\n",
      "valid_loss: 0.405, valid_acc: 0.820\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 66.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 106.80it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.141, train_acc: 0.950\n",
      "valid_loss: 0.468, valid_acc: 0.831\n",
      "evaluating...: 100%|██████████| 105/105 [00:00<00:00, 105.97it/s]\n",
      "test_loss: 0.388, test_acc: 0.835\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h80_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 87,522 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 64.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.99it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.697, train_acc: 0.564\n",
      "valid_loss: 0.595, valid_acc: 0.693\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 63.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.01it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.582, train_acc: 0.686\n",
      "valid_loss: 0.495, valid_acc: 0.768\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 64.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 102.66it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.334, train_acc: 0.861\n",
      "valid_loss: 0.398, valid_acc: 0.829\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 103.21it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.189, train_acc: 0.929\n",
      "valid_loss: 0.357, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 65.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 104.80it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.119, train_acc: 0.958\n",
      "valid_loss: 0.398, valid_acc: 0.858\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 101.59it/s]\n",
      "test_loss: 0.350, test_acc: 0.862\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.45it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.547\n",
      "valid_loss: 0.687, valid_acc: 0.543\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.81it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.31it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.610, train_acc: 0.681\n",
      "valid_loss: 0.716, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.28it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.407, train_acc: 0.808\n",
      "valid_loss: 0.358, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.49it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.208, train_acc: 0.919\n",
      "valid_loss: 0.352, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:05<00:00, 61.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.75it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.131, train_acc: 0.953\n",
      "valid_loss: 0.395, valid_acc: 0.833\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.56it/s]\n",
      "test_loss: 0.348, test_acc: 0.864\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h120_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 120,082 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.47it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.669, train_acc: 0.582\n",
      "valid_loss: 0.656, valid_acc: 0.727\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.81it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.498, train_acc: 0.762\n",
      "valid_loss: 0.490, valid_acc: 0.788\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.49it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.321, train_acc: 0.868\n",
      "valid_loss: 0.389, valid_acc: 0.831\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.57it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.194, train_acc: 0.927\n",
      "valid_loss: 0.382, valid_acc: 0.847\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 60.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.30it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.124, train_acc: 0.956\n",
      "valid_loss: 0.460, valid_acc: 0.848\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 99.32it/s] \n",
      "test_loss: 0.372, test_acc: 0.850\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h140_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 141,162 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.44it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.23it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.705, train_acc: 0.517\n",
      "valid_loss: 0.669, valid_acc: 0.560\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.36it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.87it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.639, train_acc: 0.622\n",
      "valid_loss: 0.626, valid_acc: 0.638\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.88it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.421, train_acc: 0.804\n",
      "valid_loss: 0.438, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.58it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.17it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.226, train_acc: 0.911\n",
      "valid_loss: 0.430, valid_acc: 0.820\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.42it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.142, train_acc: 0.948\n",
      "valid_loss: 0.387, valid_acc: 0.866\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 94.20it/s]\n",
      "test_loss: 0.385, test_acc: 0.863\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 159,072 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.86it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.702, train_acc: 0.543\n",
      "valid_loss: 0.661, valid_acc: 0.588\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.95it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.586, train_acc: 0.681\n",
      "valid_loss: 0.432, valid_acc: 0.822\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.06it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.304, train_acc: 0.872\n",
      "valid_loss: 0.368, valid_acc: 0.850\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.55it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.162, train_acc: 0.940\n",
      "valid_loss: 0.349, valid_acc: 0.872\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.45it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.089, train_acc: 0.970\n",
      "valid_loss: 0.452, valid_acc: 0.848\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.83it/s]\n",
      "test_loss: 0.339, test_acc: 0.870\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h160_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 165,442 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.55it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.673, train_acc: 0.572\n",
      "valid_loss: 0.648, valid_acc: 0.609\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.82it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.588, train_acc: 0.697\n",
      "valid_loss: 0.615, valid_acc: 0.656\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.85it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.331, train_acc: 0.859\n",
      "valid_loss: 0.382, valid_acc: 0.828\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.48it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.189, train_acc: 0.928\n",
      "valid_loss: 0.390, valid_acc: 0.830\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.79it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.111, train_acc: 0.960\n",
      "valid_loss: 0.454, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.88it/s]\n",
      "test_loss: 0.389, test_acc: 0.825\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h180_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 192,922 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.81it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.718, train_acc: 0.539\n",
      "valid_loss: 0.688, valid_acc: 0.525\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.85it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.643, train_acc: 0.618\n",
      "valid_loss: 0.600, valid_acc: 0.675\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.30it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.456, train_acc: 0.779\n",
      "valid_loss: 0.426, valid_acc: 0.806\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.71it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.258, train_acc: 0.898\n",
      "valid_loss: 0.359, valid_acc: 0.866\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.57it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.171, train_acc: 0.938\n",
      "valid_loss: 0.358, valid_acc: 0.858\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.00it/s]\n",
      "test_loss: 0.340, test_acc: 0.867\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 223,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.04it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.729, train_acc: 0.510\n",
      "valid_loss: 0.740, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.59it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.646, train_acc: 0.608\n",
      "valid_loss: 0.652, valid_acc: 0.609\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.48it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.357, train_acc: 0.840\n",
      "valid_loss: 0.345, valid_acc: 0.856\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.38it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.45it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.187, train_acc: 0.929\n",
      "valid_loss: 0.336, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.99it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.110, train_acc: 0.962\n",
      "valid_loss: 0.454, valid_acc: 0.849\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 81.41it/s]\n",
      "test_loss: 0.324, test_acc: 0.873\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h220_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 257,482 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.28it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.716, train_acc: 0.530\n",
      "valid_loss: 0.675, valid_acc: 0.576\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.35it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.633, train_acc: 0.624\n",
      "valid_loss: 0.528, valid_acc: 0.754\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.72it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.341, train_acc: 0.854\n",
      "valid_loss: 0.358, valid_acc: 0.851\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.85it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.193, train_acc: 0.925\n",
      "valid_loss: 0.332, valid_acc: 0.871\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.07it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.105, train_acc: 0.964\n",
      "valid_loss: 0.421, valid_acc: 0.862\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.49it/s]\n",
      "test_loss: 0.327, test_acc: 0.873\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h240_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 294,562 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.07it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.677, train_acc: 0.545\n",
      "valid_loss: 0.656, valid_acc: 0.580\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.16it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.617, train_acc: 0.646\n",
      "valid_loss: 0.663, valid_acc: 0.589\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.58it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.557, train_acc: 0.702\n",
      "valid_loss: 0.693, valid_acc: 0.585\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.81it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.507, train_acc: 0.742\n",
      "valid_loss: 0.742, valid_acc: 0.582\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.84it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.462, train_acc: 0.775\n",
      "valid_loss: 0.783, valid_acc: 0.602\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.62it/s]\n",
      "test_loss: 0.660, test_acc: 0.571\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h260_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 334,842 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.06it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.714, train_acc: 0.510\n",
      "valid_loss: 0.754, valid_acc: 0.515\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.59it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.652, train_acc: 0.603\n",
      "valid_loss: 0.659, valid_acc: 0.577\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.11it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.580, train_acc: 0.686\n",
      "valid_loss: 0.766, valid_acc: 0.563\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.75it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.520, train_acc: 0.734\n",
      "valid_loss: 0.730, valid_acc: 0.568\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.26it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.477, train_acc: 0.767\n",
      "valid_loss: 0.742, valid_acc: 0.566\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 73.36it/s]\n",
      "test_loss: 0.661, test_acc: 0.574\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h280_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 378,322 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.80it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.29it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.534\n",
      "valid_loss: 0.659, valid_acc: 0.578\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.39it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.623, train_acc: 0.637\n",
      "valid_loss: 0.659, valid_acc: 0.580\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.45it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.548, train_acc: 0.717\n",
      "valid_loss: 0.710, valid_acc: 0.572\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.31it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.478, train_acc: 0.771\n",
      "valid_loss: 0.769, valid_acc: 0.568\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 37.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.66it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.408, train_acc: 0.818\n",
      "valid_loss: 0.806, valid_acc: 0.590\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 73.69it/s]\n",
      "test_loss: 0.664, test_acc: 0.571\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h300_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 425,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 35.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.44it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.732, train_acc: 0.513\n",
      "valid_loss: 0.691, valid_acc: 0.523\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.44it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.689, train_acc: 0.536\n",
      "valid_loss: 0.690, valid_acc: 0.530\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 33.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.28it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.646, train_acc: 0.620\n",
      "valid_loss: 0.707, valid_acc: 0.536\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.84it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.592, train_acc: 0.679\n",
      "valid_loss: 0.728, valid_acc: 0.543\n",
      "training...: 100%|██████████| 365/365 [00:10<00:00, 34.40it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.72it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.546, train_acc: 0.714\n",
      "valid_loss: 0.767, valid_acc: 0.551\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 67.21it/s]\n",
      "test_loss: 0.690, test_acc: 0.539\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h320_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 474,882 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 32.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.17it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.708, train_acc: 0.525\n",
      "valid_loss: 0.682, valid_acc: 0.551\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 33.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 66.11it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.638, train_acc: 0.621\n",
      "valid_loss: 0.662, valid_acc: 0.579\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 32.55it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.92it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.574, train_acc: 0.696\n",
      "valid_loss: 0.706, valid_acc: 0.563\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 33.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.96it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.532, train_acc: 0.719\n",
      "valid_loss: 0.738, valid_acc: 0.570\n",
      "training...: 100%|██████████| 365/365 [00:11<00:00, 33.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.47it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.494, train_acc: 0.742\n",
      "valid_loss: 0.775, valid_acc: 0.568\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 65.17it/s]\n",
      "test_loss: 0.665, test_acc: 0.567\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer_name = [\"adagrad\", \"adam\", \"rmsprop\"]\n",
    "hd_dims = [1,2,5,10,20,40,60,80,100,120,140,155,160,180,200,220,240,260,280,300,320]\n",
    "hidden_table_dict = {}\n",
    "i = 0\n",
    "on = 0\n",
    "for opt_nm in optimizer_name:\n",
    "    if opt_nm == \"adagrad\":\n",
    "        on = 1\n",
    "    elif opt_nm == \"adam\":\n",
    "        on = 2\n",
    "    else:\n",
    "        on = 3\n",
    "\n",
    "    test_loss_vect = []\n",
    "    test_acc_vect = []\n",
    "\n",
    "    for hd in hd_dims:\n",
    "        new_hp = HyperParams()\n",
    "        new_hp.OPTIM = opt_nm\n",
    "        new_hp.LR = 0.001\n",
    "        new_hp.HIDDEN_DIM = hd\n",
    "        model_name_str = f'lstm_{1}layer_base_{opt_nm}_e32_h{hd}_{1}ed'\n",
    "        print(f'-----------------------------------------')\n",
    "        print(f'------ New Model: {model_name_str} ------')\n",
    "        rtr_vals = train_and_test_model_with_hparams(new_hp, model_name_str )\n",
    "        hidden_table_dict[i] = [float(on),\n",
    "                                   float(1),   # number of layers\n",
    "                                   float(hd), # number of hidden dim\n",
    "                                   float(1),\n",
    "                                   float(rtr_vals['num_params']),\n",
    "                                   rtr_vals[\"test_loss\"],\n",
    "                                   rtr_vals[\"test_acc\"],\n",
    "                                   rtr_vals[\"train_losses\"],\n",
    "                                   rtr_vals[\"train_accs\"],\n",
    "                                   rtr_vals[\"valid_losses\"],\n",
    "                                   rtr_vals[\"valid_accs\"]]\n",
    "        print(f'-----------------------------------------')\n",
    "        test_loss_vect.append(rtr_vals[\"test_loss\"])\n",
    "        test_acc_vect.append(rtr_vals[\"test_acc\"])\n",
    "        i = i + 1\n",
    "\n",
    "    plt_title = opt_nm\n",
    "    parameter_name = 'hidden size'\n",
    "    parameter_setting_vect = hd_dims\n",
    "    plot_test_loss_and_accuracy_over_parameter_change(test_loss_vect, test_acc_vect, parameter_setting_vect, parameter_name, plt_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    OptimType  NumLayers  NumHiddenDim  NumEmbededDim  NumParams  Test_Loss  \\\n0         1.0        1.0           1.0            1.0    60820.0   0.692968   \n1         1.0        1.0           2.0            1.0    60846.0   0.692617   \n2         1.0        1.0           5.0            1.0    60972.0   0.692818   \n3         1.0        1.0          10.0            1.0    61342.0   0.692648   \n4         1.0        1.0          20.0            1.0    62682.0   0.561145   \n..        ...        ...           ...            ...        ...        ...   \n58        3.0        1.0         240.0            1.0   294562.0   0.660490   \n59        3.0        1.0         260.0            1.0   334842.0   0.660660   \n60        3.0        1.0         280.0            1.0   378322.0   0.664107   \n61        3.0        1.0         300.0            1.0   425002.0   0.690024   \n62        3.0        1.0         320.0            1.0   474882.0   0.664965   \n\n    Test_Acc                                         Train_Loss  \\\n0   0.565873  [0.6931391500446894, 0.6930921422292109, 0.693...   \n1   0.601488  [0.6931258337138451, 0.693000954307922, 0.6928...   \n2   0.556548  [0.6931464263837631, 0.6931051190585307, 0.693...   \n3   0.618948  [0.693140804114407, 0.6930891585676637, 0.6929...   \n4   0.766667  [0.6931528635220985, 0.6930793907544385, 0.692...   \n..       ...                                                ...   \n58  0.571131  [0.6767613698358406, 0.6167217349352901, 0.557...   \n59  0.573810  [0.7140632181951444, 0.6523763238567195, 0.579...   \n60  0.570635  [0.6885336619533905, 0.6226312407075543, 0.547...   \n61  0.538790  [0.7317339761616433, 0.6890110548228434, 0.646...   \n62  0.567262  [0.7080002817389083, 0.6381347817917392, 0.573...   \n\n                                            Train_Acc  \\\n0   [0.5025766619264262, 0.5232224564029746, 0.560...   \n1   [0.5111790762372213, 0.5381808720222891, 0.581...   \n2   [0.5018754229153672, 0.5036040584518485, 0.554...   \n3   [0.5020996555890123, 0.5005870993823222, 0.569...   \n4   [0.499898090019618, 0.5317596382474246, 0.5501...   \n..                                                ...   \n58  [0.5445939505753452, 0.6459393540473833, 0.701...   \n59  [0.5099845221597854, 0.6028783615321329, 0.686...   \n60  [0.5335249681178837, 0.6369822435183068, 0.716...   \n61  [0.5127283250632352, 0.5363258497355735, 0.619...   \n62  [0.5254851751948056, 0.6214978996205003, 0.695...   \n\n                                           Valid_Loss  \\\n0   [0.6931269506238541, 0.6930950171542618, 0.693...   \n1   [0.6930848168876936, 0.6929909789337302, 0.692...   \n2   [0.6931287635047481, 0.6930848944861934, 0.693...   \n3   [0.6931079716052649, 0.6930524032070952, 0.692...   \n4   [0.6931322104526016, 0.693024051639269, 0.6927...   \n..                                                ...   \n58  [0.6557743448131489, 0.6628648964863904, 0.693...   \n59  [0.7543653081048209, 0.6585288992467916, 0.766...   \n60  [0.6586821382900454, 0.6585016408056583, 0.709...   \n61  [0.691391628868175, 0.6903342672114102, 0.7074...   \n62  [0.681862659049484, 0.6622992675259428, 0.7059...   \n\n                                            Valid_Acc  \n0   [0.5347877549675276, 0.5410770588326004, 0.551...  \n1   [0.533608505186045, 0.561124232017769, 0.58136...  \n2   [0.49724844435475907, 0.5113993843771377, 0.53...  \n3   [0.5027515905083351, 0.5110063029910034, 0.566...  \n4   [0.49724844435475907, 0.5161163660715211, 0.51...  \n..                                                ...  \n58  [0.5795990740353206, 0.5888364972933283, 0.585...  \n59  [0.5147405812200511, 0.5766509625146974, 0.562...  \n60  [0.5776336665423412, 0.5803852407437451, 0.572...  \n61  [0.5226022145658169, 0.5302673128415953, 0.536...  \n62  [0.551493726249011, 0.578812912387668, 0.56250...  \n\n[63 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OptimType</th>\n      <th>NumLayers</th>\n      <th>NumHiddenDim</th>\n      <th>NumEmbededDim</th>\n      <th>NumParams</th>\n      <th>Test_Loss</th>\n      <th>Test_Acc</th>\n      <th>Train_Loss</th>\n      <th>Train_Acc</th>\n      <th>Valid_Loss</th>\n      <th>Valid_Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>60820.0</td>\n      <td>0.692968</td>\n      <td>0.565873</td>\n      <td>[0.6931391500446894, 0.6930921422292109, 0.693...</td>\n      <td>[0.5025766619264262, 0.5232224564029746, 0.560...</td>\n      <td>[0.6931269506238541, 0.6930950171542618, 0.693...</td>\n      <td>[0.5347877549675276, 0.5410770588326004, 0.551...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>60846.0</td>\n      <td>0.692617</td>\n      <td>0.601488</td>\n      <td>[0.6931258337138451, 0.693000954307922, 0.6928...</td>\n      <td>[0.5111790762372213, 0.5381808720222891, 0.581...</td>\n      <td>[0.6930848168876936, 0.6929909789337302, 0.692...</td>\n      <td>[0.533608505186045, 0.561124232017769, 0.58136...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>60972.0</td>\n      <td>0.692818</td>\n      <td>0.556548</td>\n      <td>[0.6931464263837631, 0.6931051190585307, 0.693...</td>\n      <td>[0.5018754229153672, 0.5036040584518485, 0.554...</td>\n      <td>[0.6931287635047481, 0.6930848944861934, 0.693...</td>\n      <td>[0.49724844435475907, 0.5113993843771377, 0.53...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>61342.0</td>\n      <td>0.692648</td>\n      <td>0.618948</td>\n      <td>[0.693140804114407, 0.6930891585676637, 0.6929...</td>\n      <td>[0.5020996555890123, 0.5005870993823222, 0.569...</td>\n      <td>[0.6931079716052649, 0.6930524032070952, 0.692...</td>\n      <td>[0.5027515905083351, 0.5110063029910034, 0.566...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>62682.0</td>\n      <td>0.561145</td>\n      <td>0.766667</td>\n      <td>[0.6931528635220985, 0.6930793907544385, 0.692...</td>\n      <td>[0.499898090019618, 0.5317596382474246, 0.5501...</td>\n      <td>[0.6931322104526016, 0.693024051639269, 0.6927...</td>\n      <td>[0.49724844435475907, 0.5161163660715211, 0.51...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>240.0</td>\n      <td>1.0</td>\n      <td>294562.0</td>\n      <td>0.660490</td>\n      <td>0.571131</td>\n      <td>[0.6767613698358406, 0.6167217349352901, 0.557...</td>\n      <td>[0.5445939505753452, 0.6459393540473833, 0.701...</td>\n      <td>[0.6557743448131489, 0.6628648964863904, 0.693...</td>\n      <td>[0.5795990740353206, 0.5888364972933283, 0.585...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>260.0</td>\n      <td>1.0</td>\n      <td>334842.0</td>\n      <td>0.660660</td>\n      <td>0.573810</td>\n      <td>[0.7140632181951444, 0.6523763238567195, 0.579...</td>\n      <td>[0.5099845221597854, 0.6028783615321329, 0.686...</td>\n      <td>[0.7543653081048209, 0.6585288992467916, 0.766...</td>\n      <td>[0.5147405812200511, 0.5766509625146974, 0.562...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>280.0</td>\n      <td>1.0</td>\n      <td>378322.0</td>\n      <td>0.664107</td>\n      <td>0.570635</td>\n      <td>[0.6885336619533905, 0.6226312407075543, 0.547...</td>\n      <td>[0.5335249681178837, 0.6369822435183068, 0.716...</td>\n      <td>[0.6586821382900454, 0.6585016408056583, 0.709...</td>\n      <td>[0.5776336665423412, 0.5803852407437451, 0.572...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>300.0</td>\n      <td>1.0</td>\n      <td>425002.0</td>\n      <td>0.690024</td>\n      <td>0.538790</td>\n      <td>[0.7317339761616433, 0.6890110548228434, 0.646...</td>\n      <td>[0.5127283250632352, 0.5363258497355735, 0.619...</td>\n      <td>[0.691391628868175, 0.6903342672114102, 0.7074...</td>\n      <td>[0.5226022145658169, 0.5302673128415953, 0.536...</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>320.0</td>\n      <td>1.0</td>\n      <td>474882.0</td>\n      <td>0.664965</td>\n      <td>0.567262</td>\n      <td>[0.7080002817389083, 0.6381347817917392, 0.573...</td>\n      <td>[0.5254851751948056, 0.6214978996205003, 0.695...</td>\n      <td>[0.681862659049484, 0.6622992675259428, 0.7059...</td>\n      <td>[0.551493726249011, 0.578812912387668, 0.56250...</td>\n    </tr>\n  </tbody>\n</table>\n<p>63 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data=hidden_table_dict, orient=\"index\", columns = [\"OptimType\",\n",
    "                                                                               \"NumLayers\",\n",
    "                                                                               \"NumHiddenDim\",\n",
    "                                                                               \"NumEmbededDim\",\n",
    "                                                                               \"NumParams\",\n",
    "                                                                               \"Test_Loss\",\n",
    "                                                                               \"Test_Acc\",\n",
    "                                                                               \"Train_Loss\",\n",
    "                                                                               \"Train_Acc\",\n",
    "                                                                               \"Valid_Loss\",\n",
    "                                                                               \"Valid_Acc\",  ])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 (e) Larger Embedding Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.22it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.82it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.530\n",
      "valid_loss: 0.692, valid_acc: 0.619\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.17it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.652, train_acc: 0.648\n",
      "valid_loss: 0.652, valid_acc: 0.679\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.04it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.522, train_acc: 0.796\n",
      "valid_loss: 0.539, valid_acc: 0.778\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.27it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.470, train_acc: 0.830\n",
      "valid_loss: 0.499, valid_acc: 0.803\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.23it/s]\n",
      "test_loss: 0.492, test_acc: 0.813\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_2ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 163,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.38it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.28it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.27it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.541\n",
      "valid_loss: 0.685, valid_acc: 0.663\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.10it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.589, train_acc: 0.727\n",
      "valid_loss: 0.535, valid_acc: 0.790\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.37it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.478, train_acc: 0.822\n",
      "valid_loss: 0.487, valid_acc: 0.816\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.91it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.427, train_acc: 0.849\n",
      "valid_loss: 0.485, valid_acc: 0.812\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.44it/s]\n",
      "test_loss: 0.479, test_acc: 0.815\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_4ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 285,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.29it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.77it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.564\n",
      "valid_loss: 0.676, valid_acc: 0.750\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.13it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.595, train_acc: 0.707\n",
      "valid_loss: 0.520, valid_acc: 0.790\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.76it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.88it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.457, train_acc: 0.834\n",
      "valid_loss: 0.473, valid_acc: 0.818\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.10it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.404, train_acc: 0.861\n",
      "valid_loss: 0.474, valid_acc: 0.814\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.35it/s]\n",
      "test_loss: 0.473, test_acc: 0.818\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_8ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 530,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.13it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.566\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.76it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.627, train_acc: 0.655\n",
      "valid_loss: 0.486, valid_acc: 0.808\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.11it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.422, train_acc: 0.845\n",
      "valid_loss: 0.431, valid_acc: 0.830\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.68it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.347, train_acc: 0.882\n",
      "valid_loss: 0.397, valid_acc: 0.850\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.53it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.300, train_acc: 0.904\n",
      "valid_loss: 0.398, valid_acc: 0.845\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 101.59it/s]\n",
      "test_loss: 0.390, test_acc: 0.854\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_16ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,020,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.79it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.510\n",
      "valid_loss: 0.692, valid_acc: 0.557\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.75it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.89it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.586, train_acc: 0.707\n",
      "valid_loss: 0.464, valid_acc: 0.822\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.62it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.09it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.401, train_acc: 0.857\n",
      "valid_loss: 0.418, valid_acc: 0.837\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.42it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.329, train_acc: 0.893\n",
      "valid_loss: 0.410, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.87it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.283, train_acc: 0.912\n",
      "valid_loss: 0.381, valid_acc: 0.856\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.08it/s]\n",
      "test_loss: 0.375, test_acc: 0.861\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_24ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,509,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.05it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.526\n",
      "valid_loss: 0.691, valid_acc: 0.498\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.71it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.512, train_acc: 0.772\n",
      "valid_loss: 0.441, valid_acc: 0.826\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.99it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.357, train_acc: 0.876\n",
      "valid_loss: 0.405, valid_acc: 0.839\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.65it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.291, train_acc: 0.906\n",
      "valid_loss: 0.389, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.36it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.35it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.247, train_acc: 0.925\n",
      "valid_loss: 0.376, valid_acc: 0.851\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 98.23it/s]\n",
      "test_loss: 0.367, test_acc: 0.855\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,999,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.19it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.695, train_acc: 0.529\n",
      "valid_loss: 0.676, valid_acc: 0.576\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.86it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.507, train_acc: 0.790\n",
      "valid_loss: 0.431, valid_acc: 0.831\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.88it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.356, train_acc: 0.877\n",
      "valid_loss: 0.401, valid_acc: 0.842\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.69it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.289, train_acc: 0.907\n",
      "valid_loss: 0.395, valid_acc: 0.847\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.92it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.246, train_acc: 0.925\n",
      "valid_loss: 0.378, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.52it/s]\n",
      "test_loss: 0.369, test_acc: 0.855\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,978,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.83it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.697, train_acc: 0.538\n",
      "valid_loss: 0.673, valid_acc: 0.516\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.36it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.02it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.467, train_acc: 0.807\n",
      "valid_loss: 0.401, valid_acc: 0.844\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.88it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.324, train_acc: 0.889\n",
      "valid_loss: 0.367, valid_acc: 0.858\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.80it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.259, train_acc: 0.918\n",
      "valid_loss: 0.372, valid_acc: 0.853\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.01it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.216, train_acc: 0.937\n",
      "valid_loss: 0.377, valid_acc: 0.855\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 97.90it/s]\n",
      "test_loss: 0.366, test_acc: 0.859\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_64ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,957,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.11it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.532\n",
      "valid_loss: 0.677, valid_acc: 0.646\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.93it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.501, train_acc: 0.804\n",
      "valid_loss: 0.407, valid_acc: 0.846\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.24it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.317, train_acc: 0.887\n",
      "valid_loss: 0.353, valid_acc: 0.861\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.49it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.19it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.244, train_acc: 0.920\n",
      "valid_loss: 0.337, valid_acc: 0.862\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.09it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.199, train_acc: 0.940\n",
      "valid_loss: 0.338, valid_acc: 0.863\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.94it/s]\n",
      "test_loss: 0.331, test_acc: 0.866\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_80ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 4,937,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.04it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.683, train_acc: 0.559\n",
      "valid_loss: 0.500, valid_acc: 0.786\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.38it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.412, train_acc: 0.839\n",
      "valid_loss: 0.394, valid_acc: 0.853\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.00it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.284, train_acc: 0.904\n",
      "valid_loss: 0.384, valid_acc: 0.844\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.09it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.220, train_acc: 0.932\n",
      "valid_loss: 0.350, valid_acc: 0.861\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.12it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.180, train_acc: 0.949\n",
      "valid_loss: 0.369, valid_acc: 0.861\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.99it/s]\n",
      "test_loss: 0.335, test_acc: 0.868\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_96ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 5,916,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.39it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.549\n",
      "valid_loss: 0.630, valid_acc: 0.672\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.47it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.421, train_acc: 0.839\n",
      "valid_loss: 0.414, valid_acc: 0.832\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.98it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.41it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.291, train_acc: 0.901\n",
      "valid_loss: 0.347, valid_acc: 0.861\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.59it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.225, train_acc: 0.930\n",
      "valid_loss: 0.345, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.17it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.185, train_acc: 0.947\n",
      "valid_loss: 0.379, valid_acc: 0.858\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.89it/s]\n",
      "test_loss: 0.339, test_acc: 0.863\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_128ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 7,874,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.41it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.670, train_acc: 0.582\n",
      "valid_loss: 0.475, valid_acc: 0.832\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.97it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.379, train_acc: 0.855\n",
      "valid_loss: 0.360, valid_acc: 0.860\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.10it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.258, train_acc: 0.914\n",
      "valid_loss: 0.340, valid_acc: 0.860\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.46it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.196, train_acc: 0.940\n",
      "valid_loss: 0.329, valid_acc: 0.866\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.85it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.66it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.158, train_acc: 0.956\n",
      "valid_loss: 0.361, valid_acc: 0.853\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.88it/s]\n",
      "test_loss: 0.322, test_acc: 0.869\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_160ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 9,833,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.48it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.79it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.671, train_acc: 0.584\n",
      "valid_loss: 0.630, valid_acc: 0.772\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.99it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.73it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.374, train_acc: 0.855\n",
      "valid_loss: 0.381, valid_acc: 0.841\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.83it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.249, train_acc: 0.917\n",
      "valid_loss: 0.327, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.84it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.190, train_acc: 0.941\n",
      "valid_loss: 0.319, valid_acc: 0.872\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.01it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.152, train_acc: 0.957\n",
      "valid_loss: 0.328, valid_acc: 0.872\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 94.01it/s]\n",
      "test_loss: 0.312, test_acc: 0.874\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_192ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 11,791,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.56it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.661, train_acc: 0.589\n",
      "valid_loss: 0.430, valid_acc: 0.826\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.15it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.344, train_acc: 0.867\n",
      "valid_loss: 0.332, valid_acc: 0.876\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.58it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.59it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.221, train_acc: 0.926\n",
      "valid_loss: 0.328, valid_acc: 0.868\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.80it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.163, train_acc: 0.951\n",
      "valid_loss: 0.320, valid_acc: 0.871\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.72it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.126, train_acc: 0.965\n",
      "valid_loss: 0.364, valid_acc: 0.866\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.44it/s]\n",
      "test_loss: 0.319, test_acc: 0.871\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_228ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 13,994,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.63it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.685, train_acc: 0.577\n",
      "valid_loss: 0.494, valid_acc: 0.813\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.45it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.368, train_acc: 0.858\n",
      "valid_loss: 0.339, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.61it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.237, train_acc: 0.920\n",
      "valid_loss: 0.314, valid_acc: 0.875\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.43it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.178, train_acc: 0.944\n",
      "valid_loss: 0.322, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.55it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.141, train_acc: 0.959\n",
      "valid_loss: 0.343, valid_acc: 0.868\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.22it/s]\n",
      "test_loss: 0.310, test_acc: 0.877\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h100_256ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 15,708,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.71it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.647, train_acc: 0.608\n",
      "valid_loss: 0.418, valid_acc: 0.840\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.52it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.338, train_acc: 0.871\n",
      "valid_loss: 0.336, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.34it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.219, train_acc: 0.925\n",
      "valid_loss: 0.333, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.79it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.163, train_acc: 0.951\n",
      "valid_loss: 0.329, valid_acc: 0.875\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.76it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.11it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.127, train_acc: 0.965\n",
      "valid_loss: 0.331, valid_acc: 0.876\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 87.79it/s]\n",
      "test_loss: 0.317, test_acc: 0.875\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.35it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.534\n",
      "valid_loss: 0.673, valid_acc: 0.577\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.80it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.551, train_acc: 0.729\n",
      "valid_loss: 0.513, valid_acc: 0.752\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.48it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.378, train_acc: 0.837\n",
      "valid_loss: 0.421, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.36it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.242, train_acc: 0.907\n",
      "valid_loss: 0.421, valid_acc: 0.839\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.52it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.151, train_acc: 0.947\n",
      "valid_loss: 0.400, valid_acc: 0.846\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.40it/s]\n",
      "test_loss: 0.403, test_acc: 0.845\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_2ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 163,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.35it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.678, train_acc: 0.562\n",
      "valid_loss: 0.527, valid_acc: 0.747\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.04it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.431, train_acc: 0.812\n",
      "valid_loss: 0.369, valid_acc: 0.849\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.00it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.230, train_acc: 0.914\n",
      "valid_loss: 0.357, valid_acc: 0.847\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.60it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.143, train_acc: 0.952\n",
      "valid_loss: 0.430, valid_acc: 0.867\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.65it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.07it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.091, train_acc: 0.971\n",
      "valid_loss: 0.459, valid_acc: 0.822\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.88it/s]\n",
      "test_loss: 0.351, test_acc: 0.855\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_4ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 285,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.41it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.671, train_acc: 0.556\n",
      "valid_loss: 0.653, valid_acc: 0.600\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.68it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.394, train_acc: 0.825\n",
      "valid_loss: 0.379, valid_acc: 0.852\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.25it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.209, train_acc: 0.921\n",
      "valid_loss: 0.432, valid_acc: 0.819\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.12it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.118, train_acc: 0.961\n",
      "valid_loss: 0.550, valid_acc: 0.772\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.82it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.087, train_acc: 0.971\n",
      "valid_loss: 0.548, valid_acc: 0.845\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 91.15it/s]\n",
      "test_loss: 0.376, test_acc: 0.850\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_8ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 530,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.64it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.653, train_acc: 0.594\n",
      "valid_loss: 0.593, valid_acc: 0.682\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.76it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.90it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.445, train_acc: 0.801\n",
      "valid_loss: 0.406, valid_acc: 0.827\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.42it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.301, train_acc: 0.880\n",
      "valid_loss: 0.449, valid_acc: 0.816\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.11it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.180, train_acc: 0.935\n",
      "valid_loss: 0.457, valid_acc: 0.839\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.55it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.26it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.101, train_acc: 0.969\n",
      "valid_loss: 0.517, valid_acc: 0.819\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.72it/s]\n",
      "test_loss: 0.408, test_acc: 0.825\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_16ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,020,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.33it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.681, train_acc: 0.585\n",
      "valid_loss: 0.557, valid_acc: 0.733\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.69it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.429, train_acc: 0.808\n",
      "valid_loss: 0.602, valid_acc: 0.661\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.45it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.306, train_acc: 0.879\n",
      "valid_loss: 0.434, valid_acc: 0.823\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.20it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.159, train_acc: 0.944\n",
      "valid_loss: 0.453, valid_acc: 0.836\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 101.00it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.089, train_acc: 0.973\n",
      "valid_loss: 0.571, valid_acc: 0.814\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.55it/s]\n",
      "test_loss: 0.417, test_acc: 0.831\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_24ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,509,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.77it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.643, train_acc: 0.602\n",
      "valid_loss: 0.427, valid_acc: 0.817\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.97it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.351, train_acc: 0.853\n",
      "valid_loss: 0.400, valid_acc: 0.815\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.71it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.188, train_acc: 0.932\n",
      "valid_loss: 0.468, valid_acc: 0.830\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.08it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.107, train_acc: 0.965\n",
      "valid_loss: 0.530, valid_acc: 0.824\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.43it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.062, train_acc: 0.980\n",
      "valid_loss: 0.591, valid_acc: 0.830\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 97.17it/s]\n",
      "test_loss: 0.396, test_acc: 0.824\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,999,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.62it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.39it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.603, train_acc: 0.637\n",
      "valid_loss: 0.564, valid_acc: 0.697\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.45it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.315, train_acc: 0.872\n",
      "valid_loss: 0.363, valid_acc: 0.856\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.12it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.175, train_acc: 0.935\n",
      "valid_loss: 0.409, valid_acc: 0.832\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.51it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.141, train_acc: 0.951\n",
      "valid_loss: 0.559, valid_acc: 0.834\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.16it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.055, train_acc: 0.982\n",
      "valid_loss: 0.636, valid_acc: 0.816\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.76it/s]\n",
      "test_loss: 0.359, test_acc: 0.856\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,978,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.75it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.70it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.552, train_acc: 0.684\n",
      "valid_loss: 0.422, valid_acc: 0.812\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.58it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.716, train_acc: 0.642\n",
      "valid_loss: 0.603, valid_acc: 0.690\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.71it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.644, train_acc: 0.651\n",
      "valid_loss: 0.655, valid_acc: 0.598\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.79it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.594, train_acc: 0.680\n",
      "valid_loss: 0.635, valid_acc: 0.621\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.47it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.409, train_acc: 0.821\n",
      "valid_loss: 0.434, valid_acc: 0.827\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.07it/s]\n",
      "test_loss: 0.423, test_acc: 0.813\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_64ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,957,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.73it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.578, train_acc: 0.661\n",
      "valid_loss: 0.366, valid_acc: 0.844\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.61it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.288, train_acc: 0.888\n",
      "valid_loss: 0.417, valid_acc: 0.811\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.31it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.162, train_acc: 0.943\n",
      "valid_loss: 0.431, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.21it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.091, train_acc: 0.970\n",
      "valid_loss: 0.534, valid_acc: 0.841\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.82it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.133, train_acc: 0.944\n",
      "valid_loss: 0.536, valid_acc: 0.827\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.39it/s]\n",
      "test_loss: 0.370, test_acc: 0.842\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_80ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 4,937,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.82it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.576, train_acc: 0.665\n",
      "valid_loss: 0.404, valid_acc: 0.827\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.30it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.284, train_acc: 0.888\n",
      "valid_loss: 0.357, valid_acc: 0.858\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.00it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.160, train_acc: 0.944\n",
      "valid_loss: 0.429, valid_acc: 0.857\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.61it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.108, train_acc: 0.963\n",
      "valid_loss: 0.637, valid_acc: 0.814\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.31it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.056, train_acc: 0.982\n",
      "valid_loss: 0.610, valid_acc: 0.834\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 94.58it/s]\n",
      "test_loss: 0.355, test_acc: 0.860\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_96ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 5,916,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.65it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.543, train_acc: 0.702\n",
      "valid_loss: 0.416, valid_acc: 0.816\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.58it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.287, train_acc: 0.887\n",
      "valid_loss: 0.369, valid_acc: 0.850\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.98it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.25it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.142, train_acc: 0.951\n",
      "valid_loss: 0.408, valid_acc: 0.833\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.17it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.157, train_acc: 0.938\n",
      "valid_loss: 0.581, valid_acc: 0.827\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.80it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.070, train_acc: 0.975\n",
      "valid_loss: 0.564, valid_acc: 0.831\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 89.90it/s]\n",
      "test_loss: 0.372, test_acc: 0.849\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_128ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 7,874,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.49it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.642, train_acc: 0.640\n",
      "valid_loss: 0.668, valid_acc: 0.578\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.49it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.466, train_acc: 0.781\n",
      "valid_loss: 0.517, valid_acc: 0.778\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.59it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.248, train_acc: 0.904\n",
      "valid_loss: 0.429, valid_acc: 0.815\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.17it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.123, train_acc: 0.959\n",
      "valid_loss: 0.443, valid_acc: 0.856\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.29it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.058, train_acc: 0.983\n",
      "valid_loss: 0.522, valid_acc: 0.850\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.83it/s]\n",
      "test_loss: 0.426, test_acc: 0.814\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_160ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 9,833,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.44it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.500, train_acc: 0.736\n",
      "valid_loss: 0.391, valid_acc: 0.835\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.06it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.52it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.278, train_acc: 0.893\n",
      "valid_loss: 0.418, valid_acc: 0.838\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.72it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.241, train_acc: 0.903\n",
      "valid_loss: 0.487, valid_acc: 0.835\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.40it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.80it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.112, train_acc: 0.961\n",
      "valid_loss: 0.469, valid_acc: 0.820\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.53it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.069, train_acc: 0.977\n",
      "valid_loss: 0.737, valid_acc: 0.839\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.64it/s]\n",
      "test_loss: 0.393, test_acc: 0.835\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_192ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 11,791,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.71it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.582, train_acc: 0.667\n",
      "valid_loss: 0.395, valid_acc: 0.840\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.48it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.352, train_acc: 0.855\n",
      "valid_loss: 0.378, valid_acc: 0.834\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.51it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.176, train_acc: 0.934\n",
      "valid_loss: 0.422, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.09it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.109, train_acc: 0.959\n",
      "valid_loss: 0.548, valid_acc: 0.819\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.55it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.050, train_acc: 0.983\n",
      "valid_loss: 0.646, valid_acc: 0.813\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.24it/s]\n",
      "test_loss: 0.381, test_acc: 0.837\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_228ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 13,994,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.65it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.566, train_acc: 0.686\n",
      "valid_loss: 0.541, valid_acc: 0.730\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.95it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.292, train_acc: 0.884\n",
      "valid_loss: 0.371, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.22it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.156, train_acc: 0.945\n",
      "valid_loss: 0.438, valid_acc: 0.832\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.03it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.21it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.083, train_acc: 0.972\n",
      "valid_loss: 0.587, valid_acc: 0.809\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.30it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.049, train_acc: 0.985\n",
      "valid_loss: 0.640, valid_acc: 0.835\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 91.21it/s]\n",
      "test_loss: 0.369, test_acc: 0.844\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h100_256ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 15,708,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.04it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.590, train_acc: 0.673\n",
      "valid_loss: 0.634, valid_acc: 0.611\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.19it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.434, train_acc: 0.809\n",
      "valid_loss: 0.422, valid_acc: 0.816\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 39.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.27it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.220, train_acc: 0.917\n",
      "valid_loss: 0.419, valid_acc: 0.842\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.59it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.106, train_acc: 0.964\n",
      "valid_loss: 0.471, valid_acc: 0.845\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.44it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.047, train_acc: 0.986\n",
      "valid_loss: 0.743, valid_acc: 0.808\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 89.89it/s]\n",
      "test_loss: 0.436, test_acc: 0.843\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_1ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 102,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.17it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.692, train_acc: 0.547\n",
      "valid_loss: 0.687, valid_acc: 0.543\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.19it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.610, train_acc: 0.681\n",
      "valid_loss: 0.716, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.97it/s] \n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.407, train_acc: 0.808\n",
      "valid_loss: 0.358, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.48it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.208, train_acc: 0.919\n",
      "valid_loss: 0.352, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.09it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.131, train_acc: 0.953\n",
      "valid_loss: 0.395, valid_acc: 0.833\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 97.76it/s]\n",
      "test_loss: 0.348, test_acc: 0.864\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_2ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 163,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.37it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.673, train_acc: 0.584\n",
      "valid_loss: 0.525, valid_acc: 0.766\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.72it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.530, train_acc: 0.743\n",
      "valid_loss: 0.530, valid_acc: 0.742\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.10it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.297, train_acc: 0.878\n",
      "valid_loss: 0.497, valid_acc: 0.755\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.44it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.193, train_acc: 0.928\n",
      "valid_loss: 0.424, valid_acc: 0.842\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.70it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.116, train_acc: 0.959\n",
      "valid_loss: 0.449, valid_acc: 0.846\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 97.00it/s]\n",
      "test_loss: 0.412, test_acc: 0.843\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_4ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 285,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.06it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.644, train_acc: 0.628\n",
      "valid_loss: 0.721, valid_acc: 0.516\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.87it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.71it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.470, train_acc: 0.780\n",
      "valid_loss: 0.512, valid_acc: 0.778\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.58it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.288, train_acc: 0.886\n",
      "valid_loss: 0.375, valid_acc: 0.844\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.22it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.166, train_acc: 0.938\n",
      "valid_loss: 0.412, valid_acc: 0.849\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.67it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.101, train_acc: 0.966\n",
      "valid_loss: 0.485, valid_acc: 0.837\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.30it/s]\n",
      "test_loss: 0.358, test_acc: 0.852\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_8ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 530,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.80it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.628, train_acc: 0.641\n",
      "valid_loss: 0.533, valid_acc: 0.730\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.93it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.334, train_acc: 0.860\n",
      "valid_loss: 0.325, valid_acc: 0.864\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.09it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.169, train_acc: 0.937\n",
      "valid_loss: 0.363, valid_acc: 0.871\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.31it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.085, train_acc: 0.970\n",
      "valid_loss: 0.507, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.19it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.044, train_acc: 0.985\n",
      "valid_loss: 0.549, valid_acc: 0.859\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.66it/s]\n",
      "test_loss: 0.317, test_acc: 0.869\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_16ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,020,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 100.92it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.607, train_acc: 0.658\n",
      "valid_loss: 0.760, valid_acc: 0.528\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.32it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.337, train_acc: 0.854\n",
      "valid_loss: 0.326, valid_acc: 0.862\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.52it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.140, train_acc: 0.949\n",
      "valid_loss: 0.384, valid_acc: 0.868\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.58it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.050, train_acc: 0.984\n",
      "valid_loss: 0.509, valid_acc: 0.859\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.52it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.56it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.021, train_acc: 0.994\n",
      "valid_loss: 0.633, valid_acc: 0.853\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.42it/s]\n",
      "test_loss: 0.314, test_acc: 0.868\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_24ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,509,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.70it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.671, train_acc: 0.592\n",
      "valid_loss: 0.652, valid_acc: 0.597\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.76it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.34it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.337, train_acc: 0.853\n",
      "valid_loss: 0.313, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 59.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.32it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.148, train_acc: 0.946\n",
      "valid_loss: 0.363, valid_acc: 0.868\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.52it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.061, train_acc: 0.980\n",
      "valid_loss: 0.496, valid_acc: 0.859\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 58.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 99.56it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.026, train_acc: 0.992\n",
      "valid_loss: 0.560, valid_acc: 0.856\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 97.90it/s]\n",
      "test_loss: 0.308, test_acc: 0.873\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 1,999,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.27it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.74it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.677, train_acc: 0.609\n",
      "valid_loss: 0.445, valid_acc: 0.793\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.23it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.284, train_acc: 0.883\n",
      "valid_loss: 0.319, valid_acc: 0.866\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.31it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.105, train_acc: 0.963\n",
      "valid_loss: 0.387, valid_acc: 0.864\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.26it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.037, train_acc: 0.989\n",
      "valid_loss: 0.567, valid_acc: 0.863\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 57.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.97it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.015, train_acc: 0.996\n",
      "valid_loss: 0.758, valid_acc: 0.857\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.21it/s]\n",
      "test_loss: 0.311, test_acc: 0.870\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,978,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.94it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.610, train_acc: 0.666\n",
      "valid_loss: 0.468, valid_acc: 0.803\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.80it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.36it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.307, train_acc: 0.873\n",
      "valid_loss: 0.332, valid_acc: 0.872\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.27it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.134, train_acc: 0.952\n",
      "valid_loss: 0.384, valid_acc: 0.856\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.58it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.052, train_acc: 0.984\n",
      "valid_loss: 0.480, valid_acc: 0.857\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 56.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.94it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.020, train_acc: 0.994\n",
      "valid_loss: 0.687, valid_acc: 0.855\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.21it/s]\n",
      "test_loss: 0.325, test_acc: 0.871\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_64ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,957,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.60it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.646, train_acc: 0.626\n",
      "valid_loss: 0.554, valid_acc: 0.708\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.23it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.316, train_acc: 0.865\n",
      "valid_loss: 0.321, valid_acc: 0.861\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.15it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.125, train_acc: 0.955\n",
      "valid_loss: 0.397, valid_acc: 0.858\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 97.22it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.048, train_acc: 0.984\n",
      "valid_loss: 0.481, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 55.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.73it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.020, train_acc: 0.993\n",
      "valid_loss: 0.721, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.83it/s]\n",
      "test_loss: 0.317, test_acc: 0.861\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_80ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 4,937,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.06it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.671, train_acc: 0.604\n",
      "valid_loss: 0.547, valid_acc: 0.740\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.67it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.377, train_acc: 0.837\n",
      "valid_loss: 0.345, valid_acc: 0.852\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.38it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.199, train_acc: 0.925\n",
      "valid_loss: 0.386, valid_acc: 0.851\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.77it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.097, train_acc: 0.966\n",
      "valid_loss: 0.455, valid_acc: 0.847\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 98.10it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.044, train_acc: 0.985\n",
      "valid_loss: 0.542, valid_acc: 0.844\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 96.51it/s]\n",
      "test_loss: 0.352, test_acc: 0.850\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_96ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 5,916,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.41it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.606, train_acc: 0.665\n",
      "valid_loss: 0.557, valid_acc: 0.707\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.55it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.348, train_acc: 0.856\n",
      "valid_loss: 0.383, valid_acc: 0.841\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.18it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.173, train_acc: 0.936\n",
      "valid_loss: 0.368, valid_acc: 0.857\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.30it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.075, train_acc: 0.974\n",
      "valid_loss: 0.636, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.83it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.02it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.029, train_acc: 0.990\n",
      "valid_loss: 0.601, valid_acc: 0.845\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.23it/s]\n",
      "test_loss: 0.368, test_acc: 0.860\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_128ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 7,874,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.77it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.596, train_acc: 0.675\n",
      "valid_loss: 0.432, valid_acc: 0.813\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.58it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.68it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.279, train_acc: 0.889\n",
      "valid_loss: 0.365, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.72it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.46it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.142, train_acc: 0.949\n",
      "valid_loss: 0.409, valid_acc: 0.851\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.32it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.066, train_acc: 0.978\n",
      "valid_loss: 0.514, valid_acc: 0.847\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.92it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.029, train_acc: 0.990\n",
      "valid_loss: 0.672, valid_acc: 0.848\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.81it/s]\n",
      "test_loss: 0.354, test_acc: 0.845\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_160ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 9,833,002 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.13it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.606, train_acc: 0.669\n",
      "valid_loss: 0.386, valid_acc: 0.840\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.23it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.258, train_acc: 0.896\n",
      "valid_loss: 0.327, valid_acc: 0.856\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.20it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.125, train_acc: 0.956\n",
      "valid_loss: 0.415, valid_acc: 0.858\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.95it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.044, train_acc: 0.985\n",
      "valid_loss: 0.504, valid_acc: 0.849\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.47it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.019, train_acc: 0.994\n",
      "valid_loss: 0.702, valid_acc: 0.855\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 86.93it/s]\n",
      "test_loss: 0.323, test_acc: 0.856\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_192ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 11,791,402 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.49it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.75it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.576, train_acc: 0.690\n",
      "valid_loss: 0.384, valid_acc: 0.836\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.75it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.261, train_acc: 0.896\n",
      "valid_loss: 0.332, valid_acc: 0.861\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.77it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.114, train_acc: 0.959\n",
      "valid_loss: 0.393, valid_acc: 0.843\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.32it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.044, train_acc: 0.986\n",
      "valid_loss: 0.573, valid_acc: 0.862\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.98it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.13it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.022, train_acc: 0.992\n",
      "valid_loss: 0.650, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 92.62it/s]\n",
      "test_loss: 0.330, test_acc: 0.861\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_228ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 13,994,602 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.31it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.573, train_acc: 0.680\n",
      "valid_loss: 0.382, valid_acc: 0.835\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.48it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.38it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.260, train_acc: 0.895\n",
      "valid_loss: 0.352, valid_acc: 0.855\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.61it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.124, train_acc: 0.954\n",
      "valid_loss: 0.419, valid_acc: 0.853\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.71it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.054, train_acc: 0.981\n",
      "valid_loss: 0.602, valid_acc: 0.852\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.18it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.025, train_acc: 0.991\n",
      "valid_loss: 0.747, valid_acc: 0.843\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.09it/s]\n",
      "test_loss: 0.343, test_acc: 0.863\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h100_256ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 15,708,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.32it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.533, train_acc: 0.712\n",
      "valid_loss: 0.379, valid_acc: 0.830\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.98it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.260, train_acc: 0.893\n",
      "valid_loss: 0.350, valid_acc: 0.854\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.54it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.135, train_acc: 0.950\n",
      "valid_loss: 0.482, valid_acc: 0.830\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 40.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.37it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.068, train_acc: 0.976\n",
      "valid_loss: 0.558, valid_acc: 0.845\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.31it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.82it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.035, train_acc: 0.988\n",
      "valid_loss: 0.654, valid_acc: 0.845\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 89.65it/s]\n",
      "test_loss: 0.341, test_acc: 0.861\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer_name = [\"adagrad\", \"adam\", \"rmsprop\"]\n",
    "e_dims = [1,2,4,8,16,24,32,48,64,80,96,128,160,192,228,256]\n",
    "embedding_table_dict = {}\n",
    "i = 0\n",
    "on = 0\n",
    "for opt_nm in optimizer_name:\n",
    "    if opt_nm == \"adagrad\":\n",
    "        on = 1\n",
    "    elif opt_nm == \"adam\":\n",
    "        on = 2\n",
    "    else:\n",
    "        on = 3\n",
    "\n",
    "    test_loss_vect = []\n",
    "    test_acc_vect = []\n",
    "\n",
    "    for ed in e_dims:\n",
    "        new_hp = HyperParams()\n",
    "        new_hp.OPTIM = opt_nm\n",
    "        new_hp.LR = 0.001\n",
    "        new_hp.EMBEDDING_DIM = ed\n",
    "        model_name_str = f'lstm_{1}layer_base_{opt_nm}_e32_h{100}_{ed}ed'\n",
    "        print(f'-----------------------------------------')\n",
    "        print(f'------ New Model: {model_name_str} ------')\n",
    "        rtr_vals = train_and_test_model_with_hparams(new_hp, model_name_str )\n",
    "        embedding_table_dict[i] = [float(on),\n",
    "                                   float(1),   # number of layers\n",
    "                                   float(100), # number of hidden dim\n",
    "                                   float(ed),\n",
    "                                   float(rtr_vals['num_params']),\n",
    "                                   rtr_vals[\"test_loss\"],\n",
    "                                   rtr_vals[\"test_acc\"],\n",
    "                                   rtr_vals[\"train_losses\"],\n",
    "                                   rtr_vals[\"train_accs\"],\n",
    "                                   rtr_vals[\"valid_losses\"],\n",
    "                                   rtr_vals[\"valid_accs\"]]\n",
    "        print(f'-----------------------------------------')\n",
    "        test_loss_vect.append(rtr_vals[\"test_loss\"])\n",
    "        test_acc_vect.append(rtr_vals[\"test_acc\"])\n",
    "        i = i + 1\n",
    "\n",
    "    plt_title = opt_nm\n",
    "    parameter_name = 'num of embedding dim'\n",
    "    parameter_setting_vect = e_dims\n",
    "    plot_test_loss_and_accuracy_over_parameter_change(test_loss_vect, test_acc_vect, parameter_setting_vect, parameter_name, plt_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "    OptimType  NumLayers  NumHiddenDim  NumEmbededDim   NumParams  Test_Loss  \\\n0         1.0        1.0         100.0            1.0    102202.0   0.492422   \n1         1.0        1.0         100.0            2.0    163402.0   0.478856   \n2         1.0        1.0         100.0            4.0    285802.0   0.473220   \n3         1.0        1.0         100.0            8.0    530602.0   0.390204   \n4         1.0        1.0         100.0           16.0   1020202.0   0.375160   \n5         1.0        1.0         100.0           24.0   1509802.0   0.366760   \n6         1.0        1.0         100.0           32.0   1999402.0   0.368890   \n7         1.0        1.0         100.0           48.0   2978602.0   0.365573   \n8         1.0        1.0         100.0           64.0   3957802.0   0.330605   \n9         1.0        1.0         100.0           80.0   4937002.0   0.334897   \n10        1.0        1.0         100.0           96.0   5916202.0   0.339111   \n11        1.0        1.0         100.0          128.0   7874602.0   0.321789   \n12        1.0        1.0         100.0          160.0   9833002.0   0.311905   \n13        1.0        1.0         100.0          192.0  11791402.0   0.318790   \n14        1.0        1.0         100.0          228.0  13994602.0   0.309980   \n15        1.0        1.0         100.0          256.0  15708202.0   0.317393   \n16        2.0        1.0         100.0            1.0    102202.0   0.402540   \n17        2.0        1.0         100.0            2.0    163402.0   0.350857   \n18        2.0        1.0         100.0            4.0    285802.0   0.376127   \n19        2.0        1.0         100.0            8.0    530602.0   0.407517   \n20        2.0        1.0         100.0           16.0   1020202.0   0.416774   \n21        2.0        1.0         100.0           24.0   1509802.0   0.395821   \n22        2.0        1.0         100.0           32.0   1999402.0   0.358570   \n23        2.0        1.0         100.0           48.0   2978602.0   0.423119   \n24        2.0        1.0         100.0           64.0   3957802.0   0.370140   \n25        2.0        1.0         100.0           80.0   4937002.0   0.355262   \n26        2.0        1.0         100.0           96.0   5916202.0   0.371701   \n27        2.0        1.0         100.0          128.0   7874602.0   0.426462   \n28        2.0        1.0         100.0          160.0   9833002.0   0.392818   \n29        2.0        1.0         100.0          192.0  11791402.0   0.381137   \n30        2.0        1.0         100.0          228.0  13994602.0   0.368842   \n31        2.0        1.0         100.0          256.0  15708202.0   0.435841   \n32        3.0        1.0         100.0            1.0    102202.0   0.348304   \n33        3.0        1.0         100.0            2.0    163402.0   0.412410   \n34        3.0        1.0         100.0            4.0    285802.0   0.357861   \n35        3.0        1.0         100.0            8.0    530602.0   0.317032   \n36        3.0        1.0         100.0           16.0   1020202.0   0.313810   \n37        3.0        1.0         100.0           24.0   1509802.0   0.308124   \n38        3.0        1.0         100.0           32.0   1999402.0   0.311346   \n39        3.0        1.0         100.0           48.0   2978602.0   0.324921   \n40        3.0        1.0         100.0           64.0   3957802.0   0.316654   \n41        3.0        1.0         100.0           80.0   4937002.0   0.351865   \n42        3.0        1.0         100.0           96.0   5916202.0   0.367737   \n43        3.0        1.0         100.0          128.0   7874602.0   0.353965   \n44        3.0        1.0         100.0          160.0   9833002.0   0.323134   \n45        3.0        1.0         100.0          192.0  11791402.0   0.330461   \n46        3.0        1.0         100.0          228.0  13994602.0   0.343375   \n47        3.0        1.0         100.0          256.0  15708202.0   0.341447   \n\n    Test_Acc                                         Train_Loss  \\\n0   0.812798  [0.6931541081977217, 0.6929038506664642, 0.651...   \n1   0.814980  [0.6931445409173835, 0.6928415102501438, 0.588...   \n2   0.818452  [0.6931269356649216, 0.692604652332933, 0.5947...   \n3   0.854365  [0.6930987338497214, 0.6272332100835565, 0.421...   \n4   0.860516  [0.6930188020614728, 0.5859606024337142, 0.401...   \n5   0.855357  [0.6927967342611862, 0.5117703953834429, 0.356...   \n6   0.855060  [0.694692910207461, 0.5067696895501385, 0.3557...   \n7   0.859425  [0.6967454493862308, 0.46738927960395815, 0.32...   \n8   0.865774  [0.6924789299703624, 0.5005780207784208, 0.316...   \n9   0.867758  [0.6830516382439495, 0.41215036503256186, 0.28...   \n10  0.863194  [0.6899362092148768, 0.4213642620877044, 0.291...   \n11  0.868948  [0.669895490146663, 0.37856375064751874, 0.257...   \n12  0.874107  [0.6708046023976313, 0.37409820577053177, 0.24...   \n13  0.870734  [0.6610404340371694, 0.3439275697486041, 0.220...   \n14  0.876984  [0.6848356699290341, 0.36768609624202936, 0.23...   \n15  0.875397  [0.6473727152772146, 0.33769297983548413, 0.21...   \n16  0.845040  [0.6891940813358516, 0.5509744842575021, 0.377...   \n17  0.854762  [0.6778398266393845, 0.4305896083377812, 0.229...   \n18  0.850000  [0.6708934292401353, 0.3944140477131491, 0.209...   \n19  0.824603  [0.653002090241811, 0.4454861382915549, 0.3007...   \n20  0.831151  [0.68059907498425, 0.42904444275653525, 0.3057...   \n21  0.824206  [0.6427326127274395, 0.3510095393412734, 0.188...   \n22  0.856250  [0.602889923036915, 0.3145614863054393, 0.1752...   \n23  0.812897  [0.5521827263783102, 0.7159373581001204, 0.643...   \n24  0.842262  [0.5778470037734672, 0.2876714951575619, 0.162...   \n25  0.859524  [0.5756907040125703, 0.2836733652304297, 0.160...   \n26  0.848611  [0.5428397844099019, 0.28709624511738346, 0.14...   \n27  0.813790  [0.6422593820584963, 0.46606355468704275, 0.24...   \n28  0.835417  [0.5000658584784154, 0.2781942635162236, 0.240...   \n29  0.836905  [0.5820669404447896, 0.3519083792216157, 0.175...   \n30  0.843651  [0.5662773723063403, 0.29249417255186055, 0.15...   \n31  0.843353  [0.5904406160524447, 0.4344931422847591, 0.219...   \n32  0.864087  [0.6921269578476474, 0.6099212711804534, 0.406...   \n33  0.843353  [0.6727664309821717, 0.5299477578025975, 0.296...   \n34  0.851786  [0.6444536510395678, 0.4698400962842654, 0.288...   \n35  0.868849  [0.6276346622264548, 0.3339519692202137, 0.168...   \n36  0.867758  [0.6074011141306733, 0.3373215270777271, 0.140...   \n37  0.872520  [0.6711144527343854, 0.33742439505988603, 0.14...   \n38  0.870139  [0.6765626744048236, 0.2842075653680383, 0.105...   \n39  0.870635  [0.6101862517938222, 0.3070056398437448, 0.133...   \n40  0.861210  [0.6464532119770573, 0.3161672721986901, 0.125...   \n41  0.850000  [0.6709725959660255, 0.37677761814365646, 0.19...   \n42  0.860119  [0.6062288735827355, 0.34814040603703017, 0.17...   \n43  0.844643  [0.5961997497571658, 0.2787955488244148, 0.142...   \n44  0.855952  [0.6058286292095707, 0.2577876510889563, 0.125...   \n45  0.860516  [0.5764145377564104, 0.26094606237052237, 0.11...   \n46  0.863393  [0.5729518540509759, 0.2600000009961324, 0.123...   \n47  0.861111  [0.532896264121957, 0.2602015289541793, 0.1349...   \n\n                                            Train_Acc  \\\n0   [0.4996371643183983, 0.5299983859878696, 0.648...   \n1   [0.5024706603729562, 0.5414872965584062, 0.726...   \n2   [0.5015166481880292, 0.5639554974150984, 0.706...   \n3   [0.5044846852348276, 0.655438700522462, 0.8450...   \n4   [0.5102943719249882, 0.7073141093939951, 0.857...   \n5   [0.5255463307850982, 0.7721502147308767, 0.876...   \n6   [0.5294398404147527, 0.7898402039318868, 0.877...   \n7   [0.5378628675251791, 0.8066821786638808, 0.889...   \n8   [0.5323548774196677, 0.8042889954292611, 0.887...   \n9   [0.5585208906702799, 0.8394243514701112, 0.903...   \n10  [0.5493803177794365, 0.8385804173064558, 0.900...   \n11  [0.5816128681783806, 0.8552389316362877, 0.913...   \n12  [0.5836798943885385, 0.8553653165085675, 0.916...   \n13  [0.589395811214839, 0.866870535889717, 0.92569...   \n14  [0.5765370359975998, 0.8576321142993562, 0.919...   \n15  [0.608264042416664, 0.8710535118024643, 0.9252...   \n16  [0.5339571260426142, 0.7291870715683454, 0.836...   \n17  [0.5616397757236272, 0.8119781667239045, 0.913...   \n18  [0.556148093285626, 0.8251264072444341, 0.9207...   \n19  [0.5938519407625068, 0.8009540329240773, 0.879...   \n20  [0.5849152156751449, 0.8075464972077984, 0.878...   \n21  [0.6023565082517389, 0.8526622832637943, 0.931...   \n22  [0.6365378534140652, 0.8722154463807198, 0.935...   \n23  [0.6841365155291884, 0.6417400726716812, 0.650...   \n24  [0.6609670756614372, 0.887765023479723, 0.9427...   \n25  [0.6652845912600217, 0.8880422574200042, 0.943...   \n26  [0.7017205014620742, 0.8874592501823216, 0.950...   \n27  [0.6398972780737159, 0.7813030202094823, 0.904...   \n28  [0.736105693937981, 0.8928367774780482, 0.9032...   \n29  [0.6665729143848158, 0.8551696238452441, 0.934...   \n30  [0.6859507701984824, 0.8838592826503597, 0.944...   \n31  [0.6725579100928895, 0.8089122829371935, 0.916...   \n32  [0.5473132922224803, 0.6813804824874826, 0.807...   \n33  [0.5841283613688325, 0.7427430078591386, 0.878...   \n34  [0.6275644357073797, 0.7797130009899401, 0.886...   \n35  [0.6405659034644088, 0.8597643708529538, 0.937...   \n36  [0.6580398099879696, 0.8536162947955197, 0.949...   \n37  [0.5915117601825767, 0.8528009006421859, 0.946...   \n38  [0.6086513558479204, 0.8826035751055364, 0.963...   \n39  [0.665928754169647, 0.8726109147071839, 0.9518...   \n40  [0.625937723133662, 0.8647912792963525, 0.9554...   \n41  [0.603970990932151, 0.8370882445818757, 0.9251...   \n42  [0.6647627390410802, 0.8558382444185754, 0.936...   \n43  [0.6753057909338441, 0.8890125761293385, 0.948...   \n44  [0.6692392563983186, 0.8964734377926343, 0.955...   \n45  [0.6899380488754951, 0.8960942795831863, 0.958...   \n46  [0.6802756234391095, 0.8951117301640446, 0.954...   \n47  [0.712018935484429, 0.8931955518787854, 0.9503...   \n\n                                           Valid_Loss  \\\n0   [0.6931004940338854, 0.6921972992285242, 0.651...   \n1   [0.6930851171601493, 0.685137003097894, 0.5353...   \n2   [0.6930056056886349, 0.6755007572893826, 0.520...   \n3   [0.6928000090257177, 0.48578454469734766, 0.43...   \n4   [0.692475973435168, 0.4635376755921346, 0.4183...   \n5   [0.6909457681314001, 0.4407157445291303, 0.405...   \n6   [0.675755040825538, 0.4313070889351503, 0.4008...   \n7   [0.6731858365940597, 0.40142078163488853, 0.36...   \n8   [0.6772880756630087, 0.4065485610714499, 0.352...   \n9   [0.5002184448377142, 0.39376031002908385, 0.38...   \n10  [0.6298389209891265, 0.4136746919380044, 0.346...   \n11  [0.4746670925392295, 0.3601981002204823, 0.339...   \n12  [0.6297868006634262, 0.3806735136598911, 0.326...   \n13  [0.42968046440268465, 0.33169948014448275, 0.3...   \n14  [0.4939982621174938, 0.3385228097157658, 0.314...   \n15  [0.41819190810311513, 0.33612597944601524, 0.3...   \n16  [0.6731330662403466, 0.5128323503260342, 0.420...   \n17  [0.5269320095485112, 0.3688970129444914, 0.357...   \n18  [0.6528194321776336, 0.37883627864549746, 0.43...   \n19  [0.5927596317147309, 0.40643311446567754, 0.44...   \n20  [0.5573180351617202, 0.6024215997390028, 0.434...   \n21  [0.42714267716092885, 0.40008533788177203, 0.4...   \n22  [0.5636559781038536, 0.3630263071577504, 0.409...   \n23  [0.42171510969692805, 0.6034813995631236, 0.65...   \n24  [0.3661350205821811, 0.4169548378800446, 0.431...   \n25  [0.40369110680976006, 0.35710506225531957, 0.4...   \n26  [0.4159456379008743, 0.36948828792796945, 0.40...   \n27  [0.6680238944179607, 0.5171689908459501, 0.429...   \n28  [0.39068656147650954, 0.41822526083802275, 0.4...   \n29  [0.3950035833525208, 0.37822610111731403, 0.42...   \n30  [0.5409916476258692, 0.3706068703026142, 0.438...   \n31  [0.6336595393576712, 0.42179964061053293, 0.41...   \n32  [0.6873849416678807, 0.7163870975656329, 0.357...   \n33  [0.5245966883200519, 0.530366023756423, 0.4966...   \n34  [0.7210187237217741, 0.5119579805518096, 0.375...   \n35  [0.5330023928633276, 0.32543762028217316, 0.36...   \n36  [0.7598905214723551, 0.3256024673299969, 0.384...   \n37  [0.6517129641658855, 0.3127747656039472, 0.363...   \n38  [0.4452009915180926, 0.3186710707421573, 0.387...   \n39  [0.46771253251804495, 0.33199828300835954, 0.3...   \n40  [0.5541294503886744, 0.32069056691988457, 0.39...   \n41  [0.5472468756279856, 0.3450851690656734, 0.386...   \n42  [0.5570642762589004, 0.3829662279700333, 0.368...   \n43  [0.43244168246692083, 0.3647083523419668, 0.40...   \n44  [0.386150339583181, 0.3265663132352649, 0.4148...   \n45  [0.3841123119840082, 0.33157856551543724, 0.39...   \n46  [0.38163906195253694, 0.3516445286431403, 0.41...   \n47  [0.37883730317061803, 0.3499151015619062, 0.48...   \n\n                                            Valid_Acc  \n0   [0.5027515905083351, 0.6193003317095199, 0.678...  \n1   [0.49724844435475907, 0.6627358659258429, 0.78...  \n2   [0.49724844435475907, 0.7501965592492301, 0.78...  \n3   [0.5662342967852106, 0.8079795826156184, 0.830...  \n4   [0.5573899504148735, 0.8217374390026309, 0.836...  \n5   [0.4976415257408934, 0.8264544246331701, 0.839...  \n6   [0.5756682573624377, 0.8307783210052634, 0.841...  \n7   [0.5157232858100027, 0.843553475613864, 0.8579...  \n8   [0.6458333483282125, 0.8459119695537495, 0.861...  \n9   [0.7857704578705553, 0.8527908966226397, 0.843...  \n10  [0.6721698281899938, 0.8323506521728804, 0.861...  \n11  [0.8321541109175052, 0.8598663705699848, 0.859...  \n12  [0.7720125958604632, 0.8409984471662989, 0.868...  \n13  [0.826061338748572, 0.8763758045322491, 0.8683...  \n14  [0.8125000213677028, 0.8634041052944256, 0.874...  \n15  [0.8400157442632711, 0.8653695178481767, 0.869...  \n16  [0.5768475026454566, 0.7517688870429993, 0.811...  \n17  [0.7470519092847716, 0.8486635415059216, 0.847...  \n18  [0.6004324083058339, 0.8516116558380846, 0.819...  \n19  [0.6818003362079836, 0.8270440472746795, 0.815...  \n20  [0.7332940450254476, 0.6609670024997784, 0.822...  \n21  [0.8170204567459395, 0.8150550509398838, 0.829...  \n22  [0.6965408943734079, 0.856132095714785, 0.8315...  \n23  [0.8121069354831048, 0.6902515933198748, 0.597...  \n24  [0.8439465592492301, 0.8109276868262381, 0.848...  \n25  [0.8268475026454566, 0.8579009591408495, 0.856...  \n26  [0.8156446713321613, 0.8498427879135564, 0.832...  \n27  [0.5778302089223322, 0.778498446041683, 0.8152...  \n28  [0.8349056806204453, 0.8376572525726175, 0.834...  \n29  [0.8404088256494054, 0.8343160579789359, 0.842...  \n30  [0.7299528481825343, 0.8427673150908273, 0.832...  \n31  [0.6110456158530038, 0.8162343007213665, 0.841...  \n32  [0.5432390109548029, 0.5035377510313718, 0.848...  \n33  [0.7657232925576983, 0.7419418422680981, 0.754...  \n34  [0.5163129073268963, 0.7781053624063168, 0.843...  \n35  [0.7303459363163642, 0.864386814945149, 0.8710...  \n36  [0.5281053595947769, 0.8620283232544953, 0.867...  \n37  [0.5974842950982867, 0.8689072503233856, 0.867...  \n38  [0.7932390143286507, 0.8661556794958295, 0.863...  \n39  [0.8030660602281678, 0.8718553635309327, 0.855...  \n40  [0.707940271440542, 0.8614386949899062, 0.8577...  \n41  [0.7397798929574355, 0.8520047338503711, 0.850...  \n42  [0.7073506465498006, 0.8413915263032014, 0.856...  \n43  [0.8130896440092122, 0.8429638529723545, 0.850...  \n44  [0.8398192007586641, 0.856132096839401, 0.8579...  \n45  [0.8364780117880624, 0.8612421604822267, 0.842...  \n46  [0.8354953032619549, 0.8545597690456318, 0.852...  \n47  [0.8295990757222446, 0.8535770650179881, 0.830...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OptimType</th>\n      <th>NumLayers</th>\n      <th>NumHiddenDim</th>\n      <th>NumEmbededDim</th>\n      <th>NumParams</th>\n      <th>Test_Loss</th>\n      <th>Test_Acc</th>\n      <th>Train_Loss</th>\n      <th>Train_Acc</th>\n      <th>Valid_Loss</th>\n      <th>Valid_Acc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>102202.0</td>\n      <td>0.492422</td>\n      <td>0.812798</td>\n      <td>[0.6931541081977217, 0.6929038506664642, 0.651...</td>\n      <td>[0.4996371643183983, 0.5299983859878696, 0.648...</td>\n      <td>[0.6931004940338854, 0.6921972992285242, 0.651...</td>\n      <td>[0.5027515905083351, 0.6193003317095199, 0.678...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>2.0</td>\n      <td>163402.0</td>\n      <td>0.478856</td>\n      <td>0.814980</td>\n      <td>[0.6931445409173835, 0.6928415102501438, 0.588...</td>\n      <td>[0.5024706603729562, 0.5414872965584062, 0.726...</td>\n      <td>[0.6930851171601493, 0.685137003097894, 0.5353...</td>\n      <td>[0.49724844435475907, 0.6627358659258429, 0.78...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>4.0</td>\n      <td>285802.0</td>\n      <td>0.473220</td>\n      <td>0.818452</td>\n      <td>[0.6931269356649216, 0.692604652332933, 0.5947...</td>\n      <td>[0.5015166481880292, 0.5639554974150984, 0.706...</td>\n      <td>[0.6930056056886349, 0.6755007572893826, 0.520...</td>\n      <td>[0.49724844435475907, 0.7501965592492301, 0.78...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>8.0</td>\n      <td>530602.0</td>\n      <td>0.390204</td>\n      <td>0.854365</td>\n      <td>[0.6930987338497214, 0.6272332100835565, 0.421...</td>\n      <td>[0.5044846852348276, 0.655438700522462, 0.8450...</td>\n      <td>[0.6928000090257177, 0.48578454469734766, 0.43...</td>\n      <td>[0.5662342967852106, 0.8079795826156184, 0.830...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>16.0</td>\n      <td>1020202.0</td>\n      <td>0.375160</td>\n      <td>0.860516</td>\n      <td>[0.6930188020614728, 0.5859606024337142, 0.401...</td>\n      <td>[0.5102943719249882, 0.7073141093939951, 0.857...</td>\n      <td>[0.692475973435168, 0.4635376755921346, 0.4183...</td>\n      <td>[0.5573899504148735, 0.8217374390026309, 0.836...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>24.0</td>\n      <td>1509802.0</td>\n      <td>0.366760</td>\n      <td>0.855357</td>\n      <td>[0.6927967342611862, 0.5117703953834429, 0.356...</td>\n      <td>[0.5255463307850982, 0.7721502147308767, 0.876...</td>\n      <td>[0.6909457681314001, 0.4407157445291303, 0.405...</td>\n      <td>[0.4976415257408934, 0.8264544246331701, 0.839...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>32.0</td>\n      <td>1999402.0</td>\n      <td>0.368890</td>\n      <td>0.855060</td>\n      <td>[0.694692910207461, 0.5067696895501385, 0.3557...</td>\n      <td>[0.5294398404147527, 0.7898402039318868, 0.877...</td>\n      <td>[0.675755040825538, 0.4313070889351503, 0.4008...</td>\n      <td>[0.5756682573624377, 0.8307783210052634, 0.841...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>48.0</td>\n      <td>2978602.0</td>\n      <td>0.365573</td>\n      <td>0.859425</td>\n      <td>[0.6967454493862308, 0.46738927960395815, 0.32...</td>\n      <td>[0.5378628675251791, 0.8066821786638808, 0.889...</td>\n      <td>[0.6731858365940597, 0.40142078163488853, 0.36...</td>\n      <td>[0.5157232858100027, 0.843553475613864, 0.8579...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>64.0</td>\n      <td>3957802.0</td>\n      <td>0.330605</td>\n      <td>0.865774</td>\n      <td>[0.6924789299703624, 0.5005780207784208, 0.316...</td>\n      <td>[0.5323548774196677, 0.8042889954292611, 0.887...</td>\n      <td>[0.6772880756630087, 0.4065485610714499, 0.352...</td>\n      <td>[0.6458333483282125, 0.8459119695537495, 0.861...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>80.0</td>\n      <td>4937002.0</td>\n      <td>0.334897</td>\n      <td>0.867758</td>\n      <td>[0.6830516382439495, 0.41215036503256186, 0.28...</td>\n      <td>[0.5585208906702799, 0.8394243514701112, 0.903...</td>\n      <td>[0.5002184448377142, 0.39376031002908385, 0.38...</td>\n      <td>[0.7857704578705553, 0.8527908966226397, 0.843...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>96.0</td>\n      <td>5916202.0</td>\n      <td>0.339111</td>\n      <td>0.863194</td>\n      <td>[0.6899362092148768, 0.4213642620877044, 0.291...</td>\n      <td>[0.5493803177794365, 0.8385804173064558, 0.900...</td>\n      <td>[0.6298389209891265, 0.4136746919380044, 0.346...</td>\n      <td>[0.6721698281899938, 0.8323506521728804, 0.861...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>128.0</td>\n      <td>7874602.0</td>\n      <td>0.321789</td>\n      <td>0.868948</td>\n      <td>[0.669895490146663, 0.37856375064751874, 0.257...</td>\n      <td>[0.5816128681783806, 0.8552389316362877, 0.913...</td>\n      <td>[0.4746670925392295, 0.3601981002204823, 0.339...</td>\n      <td>[0.8321541109175052, 0.8598663705699848, 0.859...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>160.0</td>\n      <td>9833002.0</td>\n      <td>0.311905</td>\n      <td>0.874107</td>\n      <td>[0.6708046023976313, 0.37409820577053177, 0.24...</td>\n      <td>[0.5836798943885385, 0.8553653165085675, 0.916...</td>\n      <td>[0.6297868006634262, 0.3806735136598911, 0.326...</td>\n      <td>[0.7720125958604632, 0.8409984471662989, 0.868...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>192.0</td>\n      <td>11791402.0</td>\n      <td>0.318790</td>\n      <td>0.870734</td>\n      <td>[0.6610404340371694, 0.3439275697486041, 0.220...</td>\n      <td>[0.589395811214839, 0.866870535889717, 0.92569...</td>\n      <td>[0.42968046440268465, 0.33169948014448275, 0.3...</td>\n      <td>[0.826061338748572, 0.8763758045322491, 0.8683...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>228.0</td>\n      <td>13994602.0</td>\n      <td>0.309980</td>\n      <td>0.876984</td>\n      <td>[0.6848356699290341, 0.36768609624202936, 0.23...</td>\n      <td>[0.5765370359975998, 0.8576321142993562, 0.919...</td>\n      <td>[0.4939982621174938, 0.3385228097157658, 0.314...</td>\n      <td>[0.8125000213677028, 0.8634041052944256, 0.874...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>256.0</td>\n      <td>15708202.0</td>\n      <td>0.317393</td>\n      <td>0.875397</td>\n      <td>[0.6473727152772146, 0.33769297983548413, 0.21...</td>\n      <td>[0.608264042416664, 0.8710535118024643, 0.9252...</td>\n      <td>[0.41819190810311513, 0.33612597944601524, 0.3...</td>\n      <td>[0.8400157442632711, 0.8653695178481767, 0.869...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>102202.0</td>\n      <td>0.402540</td>\n      <td>0.845040</td>\n      <td>[0.6891940813358516, 0.5509744842575021, 0.377...</td>\n      <td>[0.5339571260426142, 0.7291870715683454, 0.836...</td>\n      <td>[0.6731330662403466, 0.5128323503260342, 0.420...</td>\n      <td>[0.5768475026454566, 0.7517688870429993, 0.811...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>2.0</td>\n      <td>163402.0</td>\n      <td>0.350857</td>\n      <td>0.854762</td>\n      <td>[0.6778398266393845, 0.4305896083377812, 0.229...</td>\n      <td>[0.5616397757236272, 0.8119781667239045, 0.913...</td>\n      <td>[0.5269320095485112, 0.3688970129444914, 0.357...</td>\n      <td>[0.7470519092847716, 0.8486635415059216, 0.847...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>4.0</td>\n      <td>285802.0</td>\n      <td>0.376127</td>\n      <td>0.850000</td>\n      <td>[0.6708934292401353, 0.3944140477131491, 0.209...</td>\n      <td>[0.556148093285626, 0.8251264072444341, 0.9207...</td>\n      <td>[0.6528194321776336, 0.37883627864549746, 0.43...</td>\n      <td>[0.6004324083058339, 0.8516116558380846, 0.819...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>8.0</td>\n      <td>530602.0</td>\n      <td>0.407517</td>\n      <td>0.824603</td>\n      <td>[0.653002090241811, 0.4454861382915549, 0.3007...</td>\n      <td>[0.5938519407625068, 0.8009540329240773, 0.879...</td>\n      <td>[0.5927596317147309, 0.40643311446567754, 0.44...</td>\n      <td>[0.6818003362079836, 0.8270440472746795, 0.815...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>16.0</td>\n      <td>1020202.0</td>\n      <td>0.416774</td>\n      <td>0.831151</td>\n      <td>[0.68059907498425, 0.42904444275653525, 0.3057...</td>\n      <td>[0.5849152156751449, 0.8075464972077984, 0.878...</td>\n      <td>[0.5573180351617202, 0.6024215997390028, 0.434...</td>\n      <td>[0.7332940450254476, 0.6609670024997784, 0.822...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>24.0</td>\n      <td>1509802.0</td>\n      <td>0.395821</td>\n      <td>0.824206</td>\n      <td>[0.6427326127274395, 0.3510095393412734, 0.188...</td>\n      <td>[0.6023565082517389, 0.8526622832637943, 0.931...</td>\n      <td>[0.42714267716092885, 0.40008533788177203, 0.4...</td>\n      <td>[0.8170204567459395, 0.8150550509398838, 0.829...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>32.0</td>\n      <td>1999402.0</td>\n      <td>0.358570</td>\n      <td>0.856250</td>\n      <td>[0.602889923036915, 0.3145614863054393, 0.1752...</td>\n      <td>[0.6365378534140652, 0.8722154463807198, 0.935...</td>\n      <td>[0.5636559781038536, 0.3630263071577504, 0.409...</td>\n      <td>[0.6965408943734079, 0.856132095714785, 0.8315...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>48.0</td>\n      <td>2978602.0</td>\n      <td>0.423119</td>\n      <td>0.812897</td>\n      <td>[0.5521827263783102, 0.7159373581001204, 0.643...</td>\n      <td>[0.6841365155291884, 0.6417400726716812, 0.650...</td>\n      <td>[0.42171510969692805, 0.6034813995631236, 0.65...</td>\n      <td>[0.8121069354831048, 0.6902515933198748, 0.597...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>64.0</td>\n      <td>3957802.0</td>\n      <td>0.370140</td>\n      <td>0.842262</td>\n      <td>[0.5778470037734672, 0.2876714951575619, 0.162...</td>\n      <td>[0.6609670756614372, 0.887765023479723, 0.9427...</td>\n      <td>[0.3661350205821811, 0.4169548378800446, 0.431...</td>\n      <td>[0.8439465592492301, 0.8109276868262381, 0.848...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>80.0</td>\n      <td>4937002.0</td>\n      <td>0.355262</td>\n      <td>0.859524</td>\n      <td>[0.5756907040125703, 0.2836733652304297, 0.160...</td>\n      <td>[0.6652845912600217, 0.8880422574200042, 0.943...</td>\n      <td>[0.40369110680976006, 0.35710506225531957, 0.4...</td>\n      <td>[0.8268475026454566, 0.8579009591408495, 0.856...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>96.0</td>\n      <td>5916202.0</td>\n      <td>0.371701</td>\n      <td>0.848611</td>\n      <td>[0.5428397844099019, 0.28709624511738346, 0.14...</td>\n      <td>[0.7017205014620742, 0.8874592501823216, 0.950...</td>\n      <td>[0.4159456379008743, 0.36948828792796945, 0.40...</td>\n      <td>[0.8156446713321613, 0.8498427879135564, 0.832...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>128.0</td>\n      <td>7874602.0</td>\n      <td>0.426462</td>\n      <td>0.813790</td>\n      <td>[0.6422593820584963, 0.46606355468704275, 0.24...</td>\n      <td>[0.6398972780737159, 0.7813030202094823, 0.904...</td>\n      <td>[0.6680238944179607, 0.5171689908459501, 0.429...</td>\n      <td>[0.5778302089223322, 0.778498446041683, 0.8152...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>160.0</td>\n      <td>9833002.0</td>\n      <td>0.392818</td>\n      <td>0.835417</td>\n      <td>[0.5000658584784154, 0.2781942635162236, 0.240...</td>\n      <td>[0.736105693937981, 0.8928367774780482, 0.9032...</td>\n      <td>[0.39068656147650954, 0.41822526083802275, 0.4...</td>\n      <td>[0.8349056806204453, 0.8376572525726175, 0.834...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>192.0</td>\n      <td>11791402.0</td>\n      <td>0.381137</td>\n      <td>0.836905</td>\n      <td>[0.5820669404447896, 0.3519083792216157, 0.175...</td>\n      <td>[0.6665729143848158, 0.8551696238452441, 0.934...</td>\n      <td>[0.3950035833525208, 0.37822610111731403, 0.42...</td>\n      <td>[0.8404088256494054, 0.8343160579789359, 0.842...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>228.0</td>\n      <td>13994602.0</td>\n      <td>0.368842</td>\n      <td>0.843651</td>\n      <td>[0.5662773723063403, 0.29249417255186055, 0.15...</td>\n      <td>[0.6859507701984824, 0.8838592826503597, 0.944...</td>\n      <td>[0.5409916476258692, 0.3706068703026142, 0.438...</td>\n      <td>[0.7299528481825343, 0.8427673150908273, 0.832...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>256.0</td>\n      <td>15708202.0</td>\n      <td>0.435841</td>\n      <td>0.843353</td>\n      <td>[0.5904406160524447, 0.4344931422847591, 0.219...</td>\n      <td>[0.6725579100928895, 0.8089122829371935, 0.916...</td>\n      <td>[0.6336595393576712, 0.42179964061053293, 0.41...</td>\n      <td>[0.6110456158530038, 0.8162343007213665, 0.841...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n      <td>102202.0</td>\n      <td>0.348304</td>\n      <td>0.864087</td>\n      <td>[0.6921269578476474, 0.6099212711804534, 0.406...</td>\n      <td>[0.5473132922224803, 0.6813804824874826, 0.807...</td>\n      <td>[0.6873849416678807, 0.7163870975656329, 0.357...</td>\n      <td>[0.5432390109548029, 0.5035377510313718, 0.848...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>2.0</td>\n      <td>163402.0</td>\n      <td>0.412410</td>\n      <td>0.843353</td>\n      <td>[0.6727664309821717, 0.5299477578025975, 0.296...</td>\n      <td>[0.5841283613688325, 0.7427430078591386, 0.878...</td>\n      <td>[0.5245966883200519, 0.530366023756423, 0.4966...</td>\n      <td>[0.7657232925576983, 0.7419418422680981, 0.754...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>4.0</td>\n      <td>285802.0</td>\n      <td>0.357861</td>\n      <td>0.851786</td>\n      <td>[0.6444536510395678, 0.4698400962842654, 0.288...</td>\n      <td>[0.6275644357073797, 0.7797130009899401, 0.886...</td>\n      <td>[0.7210187237217741, 0.5119579805518096, 0.375...</td>\n      <td>[0.5163129073268963, 0.7781053624063168, 0.843...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>8.0</td>\n      <td>530602.0</td>\n      <td>0.317032</td>\n      <td>0.868849</td>\n      <td>[0.6276346622264548, 0.3339519692202137, 0.168...</td>\n      <td>[0.6405659034644088, 0.8597643708529538, 0.937...</td>\n      <td>[0.5330023928633276, 0.32543762028217316, 0.36...</td>\n      <td>[0.7303459363163642, 0.864386814945149, 0.8710...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>16.0</td>\n      <td>1020202.0</td>\n      <td>0.313810</td>\n      <td>0.867758</td>\n      <td>[0.6074011141306733, 0.3373215270777271, 0.140...</td>\n      <td>[0.6580398099879696, 0.8536162947955197, 0.949...</td>\n      <td>[0.7598905214723551, 0.3256024673299969, 0.384...</td>\n      <td>[0.5281053595947769, 0.8620283232544953, 0.867...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>24.0</td>\n      <td>1509802.0</td>\n      <td>0.308124</td>\n      <td>0.872520</td>\n      <td>[0.6711144527343854, 0.33742439505988603, 0.14...</td>\n      <td>[0.5915117601825767, 0.8528009006421859, 0.946...</td>\n      <td>[0.6517129641658855, 0.3127747656039472, 0.363...</td>\n      <td>[0.5974842950982867, 0.8689072503233856, 0.867...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>32.0</td>\n      <td>1999402.0</td>\n      <td>0.311346</td>\n      <td>0.870139</td>\n      <td>[0.6765626744048236, 0.2842075653680383, 0.105...</td>\n      <td>[0.6086513558479204, 0.8826035751055364, 0.963...</td>\n      <td>[0.4452009915180926, 0.3186710707421573, 0.387...</td>\n      <td>[0.7932390143286507, 0.8661556794958295, 0.863...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>48.0</td>\n      <td>2978602.0</td>\n      <td>0.324921</td>\n      <td>0.870635</td>\n      <td>[0.6101862517938222, 0.3070056398437448, 0.133...</td>\n      <td>[0.665928754169647, 0.8726109147071839, 0.9518...</td>\n      <td>[0.46771253251804495, 0.33199828300835954, 0.3...</td>\n      <td>[0.8030660602281678, 0.8718553635309327, 0.855...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>64.0</td>\n      <td>3957802.0</td>\n      <td>0.316654</td>\n      <td>0.861210</td>\n      <td>[0.6464532119770573, 0.3161672721986901, 0.125...</td>\n      <td>[0.625937723133662, 0.8647912792963525, 0.9554...</td>\n      <td>[0.5541294503886744, 0.32069056691988457, 0.39...</td>\n      <td>[0.707940271440542, 0.8614386949899062, 0.8577...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>80.0</td>\n      <td>4937002.0</td>\n      <td>0.351865</td>\n      <td>0.850000</td>\n      <td>[0.6709725959660255, 0.37677761814365646, 0.19...</td>\n      <td>[0.603970990932151, 0.8370882445818757, 0.9251...</td>\n      <td>[0.5472468756279856, 0.3450851690656734, 0.386...</td>\n      <td>[0.7397798929574355, 0.8520047338503711, 0.850...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>96.0</td>\n      <td>5916202.0</td>\n      <td>0.367737</td>\n      <td>0.860119</td>\n      <td>[0.6062288735827355, 0.34814040603703017, 0.17...</td>\n      <td>[0.6647627390410802, 0.8558382444185754, 0.936...</td>\n      <td>[0.5570642762589004, 0.3829662279700333, 0.368...</td>\n      <td>[0.7073506465498006, 0.8413915263032014, 0.856...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>128.0</td>\n      <td>7874602.0</td>\n      <td>0.353965</td>\n      <td>0.844643</td>\n      <td>[0.5961997497571658, 0.2787955488244148, 0.142...</td>\n      <td>[0.6753057909338441, 0.8890125761293385, 0.948...</td>\n      <td>[0.43244168246692083, 0.3647083523419668, 0.40...</td>\n      <td>[0.8130896440092122, 0.8429638529723545, 0.850...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>160.0</td>\n      <td>9833002.0</td>\n      <td>0.323134</td>\n      <td>0.855952</td>\n      <td>[0.6058286292095707, 0.2577876510889563, 0.125...</td>\n      <td>[0.6692392563983186, 0.8964734377926343, 0.955...</td>\n      <td>[0.386150339583181, 0.3265663132352649, 0.4148...</td>\n      <td>[0.8398192007586641, 0.856132096839401, 0.8579...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>192.0</td>\n      <td>11791402.0</td>\n      <td>0.330461</td>\n      <td>0.860516</td>\n      <td>[0.5764145377564104, 0.26094606237052237, 0.11...</td>\n      <td>[0.6899380488754951, 0.8960942795831863, 0.958...</td>\n      <td>[0.3841123119840082, 0.33157856551543724, 0.39...</td>\n      <td>[0.8364780117880624, 0.8612421604822267, 0.842...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>228.0</td>\n      <td>13994602.0</td>\n      <td>0.343375</td>\n      <td>0.863393</td>\n      <td>[0.5729518540509759, 0.2600000009961324, 0.123...</td>\n      <td>[0.6802756234391095, 0.8951117301640446, 0.954...</td>\n      <td>[0.38163906195253694, 0.3516445286431403, 0.41...</td>\n      <td>[0.8354953032619549, 0.8545597690456318, 0.852...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>256.0</td>\n      <td>15708202.0</td>\n      <td>0.341447</td>\n      <td>0.861111</td>\n      <td>[0.532896264121957, 0.2602015289541793, 0.1349...</td>\n      <td>[0.712018935484429, 0.8931955518787854, 0.9503...</td>\n      <td>[0.37883730317061803, 0.3499151015619062, 0.48...</td>\n      <td>[0.8295990757222446, 0.8535770650179881, 0.830...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data=embedding_table_dict, orient=\"index\", columns = [\"OptimType\",\n",
    "                                                                                  \"NumLayers\",\n",
    "                                                                                  \"NumHiddenDim\",\n",
    "                                                                                  \"NumEmbededDim\",\n",
    "                                                                                  \"NumParams\",\n",
    "                                                                                  \"Test_Loss\",\n",
    "                                                                                  \"Test_Acc\",\n",
    "                                                                                  \"Train_Loss\",\n",
    "                                                                                  \"Train_Acc\",\n",
    "                                                                                  \"Valid_Loss\",\n",
    "                                                                                  \"Valid_Acc\",  ])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 (f) Compound scaling of embedding_dim, hidden_dim, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.37it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.79it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.522\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.95it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.529\n",
      "valid_loss: 0.693, valid_acc: 0.538\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.17it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.551\n",
      "valid_loss: 0.693, valid_acc: 0.545\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.68it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.554\n",
      "valid_loss: 0.693, valid_acc: 0.552\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.22it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.593\n",
      "valid_loss: 0.693, valid_acc: 0.559\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 81.82it/s]\n",
      "test_loss: 0.693, test_acc: 0.561\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.89it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.524\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.09it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.535\n",
      "valid_loss: 0.693, valid_acc: 0.531\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.88it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.543\n",
      "valid_loss: 0.693, valid_acc: 0.540\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.89it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.557\n",
      "valid_loss: 0.693, valid_acc: 0.547\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.80it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.564\n",
      "valid_loss: 0.693, valid_acc: 0.554\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 83.65it/s]\n",
      "test_loss: 0.693, test_acc: 0.549\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 39.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.02it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.500\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.96it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.519\n",
      "valid_loss: 0.693, valid_acc: 0.506\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.30it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.538\n",
      "valid_loss: 0.693, valid_acc: 0.509\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 39.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.67it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.527\n",
      "valid_loss: 0.693, valid_acc: 0.514\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.62it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.538\n",
      "valid_loss: 0.693, valid_acc: 0.526\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.84it/s]\n",
      "test_loss: 0.693, test_acc: 0.529\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.84it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.507\n",
      "valid_loss: 0.693, valid_acc: 0.507\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.16it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.528\n",
      "valid_loss: 0.693, valid_acc: 0.516\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.26it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.561\n",
      "valid_loss: 0.693, valid_acc: 0.528\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.22it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.572\n",
      "valid_loss: 0.693, valid_acc: 0.534\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.48it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.550\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 79.86it/s]\n",
      "test_loss: 0.693, test_acc: 0.545\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.94it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.512\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.50it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.516\n",
      "valid_loss: 0.693, valid_acc: 0.526\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.71it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.526\n",
      "valid_loss: 0.693, valid_acc: 0.546\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.70it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.94it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.537\n",
      "valid_loss: 0.693, valid_acc: 0.555\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.56it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.552\n",
      "valid_loss: 0.693, valid_acc: 0.564\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.28it/s]\n",
      "test_loss: 0.693, test_acc: 0.561\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.50it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.508\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.75it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.523\n",
      "valid_loss: 0.693, valid_acc: 0.524\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.34it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.537\n",
      "valid_loss: 0.693, valid_acc: 0.533\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.52it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.545\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.92it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.549\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 89.53it/s]\n",
      "test_loss: 0.693, test_acc: 0.537\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.65it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.95it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.498\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.12it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.512\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.49it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.07it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.520\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.29it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.521\n",
      "valid_loss: 0.693, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.63it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.523\n",
      "valid_loss: 0.693, valid_acc: 0.506\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.37it/s]\n",
      "test_loss: 0.693, test_acc: 0.513\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.09it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.68it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.505\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.75it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.523\n",
      "valid_loss: 0.693, valid_acc: 0.512\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.51it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.535\n",
      "valid_loss: 0.693, valid_acc: 0.521\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.55it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.543\n",
      "valid_loss: 0.693, valid_acc: 0.525\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.87it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.536\n",
      "valid_loss: 0.693, valid_acc: 0.531\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.06it/s]\n",
      "test_loss: 0.693, test_acc: 0.532\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.43it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.495\n",
      "valid_loss: 0.693, valid_acc: 0.501\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.03it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.497\n",
      "valid_loss: 0.693, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.08it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.20it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.99it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.77it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 89.45it/s]\n",
      "test_loss: 0.693, test_acc: 0.506\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.14it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.497\n",
      "valid_loss: 0.693, valid_acc: 0.494\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.76it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.503\n",
      "valid_loss: 0.693, valid_acc: 0.500\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.90it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.507\n",
      "valid_loss: 0.693, valid_acc: 0.500\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.39it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.509\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.32it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.92it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.511\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.75it/s]\n",
      "test_loss: 0.693, test_acc: 0.510\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.85it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.496\n",
      "valid_loss: 0.693, valid_acc: 0.487\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.59it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.488\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.46it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.491\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.59it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.506\n",
      "valid_loss: 0.693, valid_acc: 0.495\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.74it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.507\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.63it/s]\n",
      "test_loss: 0.693, test_acc: 0.504\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.22it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.506\n",
      "valid_loss: 0.693, valid_acc: 0.505\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.24it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.508\n",
      "valid_loss: 0.693, valid_acc: 0.507\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.78it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.512\n",
      "valid_loss: 0.693, valid_acc: 0.509\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.14it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.513\n",
      "valid_loss: 0.693, valid_acc: 0.511\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.10it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.515\n",
      "valid_loss: 0.693, valid_acc: 0.512\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 78.67it/s]\n",
      "test_loss: 0.693, test_acc: 0.507\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.32it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.494\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.90it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.497\n",
      "valid_loss: 0.693, valid_acc: 0.501\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.24it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.495\n",
      "valid_loss: 0.693, valid_acc: 0.502\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.82it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.498\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.47it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.24it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.505\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.81it/s]\n",
      "test_loss: 0.693, test_acc: 0.501\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h155_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.82it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.494\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.49it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.09it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.494\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.36it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.88it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.506\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.70it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.505\n",
      "valid_loss: 0.693, valid_acc: 0.500\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.22it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.78it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.505\n",
      "valid_loss: 0.693, valid_acc: 0.501\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.72it/s]\n",
      "test_loss: 0.693, test_acc: 0.512\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.32it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.488\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.29it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.500\n",
      "valid_loss: 0.693, valid_acc: 0.489\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.74it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.502\n",
      "valid_loss: 0.693, valid_acc: 0.489\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.64it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.00it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.505\n",
      "valid_loss: 0.693, valid_acc: 0.490\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.68it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.60it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.492\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 79.87it/s]\n",
      "test_loss: 0.693, test_acc: 0.502\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adagrad_e32_h200_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.12it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.90it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.505\n",
      "valid_loss: 0.693, valid_acc: 0.506\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.46it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.508\n",
      "valid_loss: 0.693, valid_acc: 0.507\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.74it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.504\n",
      "valid_loss: 0.693, valid_acc: 0.507\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.97it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.510\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 80.48it/s]\n",
      "test_loss: 0.693, test_acc: 0.506\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.02it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.96it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.513\n",
      "valid_loss: 0.687, valid_acc: 0.520\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 52.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.44it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.423, train_acc: 0.825\n",
      "valid_loss: 0.336, valid_acc: 0.871\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.29it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.221, train_acc: 0.923\n",
      "valid_loss: 0.305, valid_acc: 0.878\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.00it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.135, train_acc: 0.959\n",
      "valid_loss: 0.300, valid_acc: 0.879\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.88it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.085, train_acc: 0.977\n",
      "valid_loss: 0.410, valid_acc: 0.867\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 95.03it/s]\n",
      "test_loss: 0.293, test_acc: 0.881\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 95.35it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.688, train_acc: 0.534\n",
      "valid_loss: 0.566, valid_acc: 0.764\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.94it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.38it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.372, train_acc: 0.852\n",
      "valid_loss: 0.366, valid_acc: 0.853\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.41it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.199, train_acc: 0.930\n",
      "valid_loss: 0.301, valid_acc: 0.881\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.06it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.124, train_acc: 0.962\n",
      "valid_loss: 0.319, valid_acc: 0.877\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.95it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.076, train_acc: 0.979\n",
      "valid_loss: 0.420, valid_acc: 0.868\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.47it/s]\n",
      "test_loss: 0.291, test_acc: 0.882\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.35it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.688, train_acc: 0.528\n",
      "valid_loss: 0.534, valid_acc: 0.763\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 45.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.82it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.407, train_acc: 0.844\n",
      "valid_loss: 0.339, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.56it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.22it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.224, train_acc: 0.923\n",
      "valid_loss: 0.297, valid_acc: 0.882\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.45it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.71it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.142, train_acc: 0.956\n",
      "valid_loss: 0.309, valid_acc: 0.879\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.42it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.092, train_acc: 0.974\n",
      "valid_loss: 0.318, valid_acc: 0.876\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 81.55it/s]\n",
      "test_loss: 0.291, test_acc: 0.882\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.99it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.64it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.690, train_acc: 0.525\n",
      "valid_loss: 0.667, valid_acc: 0.526\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.81it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.396, train_acc: 0.825\n",
      "valid_loss: 0.310, valid_acc: 0.870\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.05it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.199, train_acc: 0.930\n",
      "valid_loss: 0.314, valid_acc: 0.877\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.75it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.122, train_acc: 0.962\n",
      "valid_loss: 0.342, valid_acc: 0.877\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.55it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.071, train_acc: 0.981\n",
      "valid_loss: 0.339, valid_acc: 0.880\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 82.09it/s]\n",
      "test_loss: 0.309, test_acc: 0.872\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.55it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.508\n",
      "valid_loss: 0.692, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.08it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.506, train_acc: 0.759\n",
      "valid_loss: 0.369, valid_acc: 0.857\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.95it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.40it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.260, train_acc: 0.910\n",
      "valid_loss: 0.313, valid_acc: 0.873\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 96.65it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.160, train_acc: 0.949\n",
      "valid_loss: 0.285, valid_acc: 0.886\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 54.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.71it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.099, train_acc: 0.972\n",
      "valid_loss: 0.350, valid_acc: 0.876\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 93.45it/s]\n",
      "test_loss: 0.284, test_acc: 0.884\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.40it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.88it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.521\n",
      "valid_loss: 0.691, valid_acc: 0.541\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.67it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.467, train_acc: 0.790\n",
      "valid_loss: 0.368, valid_acc: 0.858\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.47it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.227, train_acc: 0.920\n",
      "valid_loss: 0.295, valid_acc: 0.877\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.81it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.140, train_acc: 0.957\n",
      "valid_loss: 0.308, valid_acc: 0.880\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.70it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.089, train_acc: 0.975\n",
      "valid_loss: 0.383, valid_acc: 0.868\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 83.88it/s]\n",
      "test_loss: 0.291, test_acc: 0.879\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.54it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.512\n",
      "valid_loss: 0.692, valid_acc: 0.560\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 38.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 69.85it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.482, train_acc: 0.787\n",
      "valid_loss: 0.351, valid_acc: 0.865\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 68.12it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.249, train_acc: 0.914\n",
      "valid_loss: 0.313, valid_acc: 0.882\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.26it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.151, train_acc: 0.953\n",
      "valid_loss: 0.291, valid_acc: 0.882\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.44it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.103, train_acc: 0.972\n",
      "valid_loss: 0.369, valid_acc: 0.869\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 72.62it/s]\n",
      "test_loss: 0.285, test_acc: 0.881\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 39.30it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.66it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.507\n",
      "valid_loss: 0.691, valid_acc: 0.547\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.95it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.445, train_acc: 0.798\n",
      "valid_loss: 0.319, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 40.69it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.98it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.215, train_acc: 0.925\n",
      "valid_loss: 0.331, valid_acc: 0.875\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 65.78it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.130, train_acc: 0.960\n",
      "valid_loss: 0.337, valid_acc: 0.880\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 40.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.24it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.076, train_acc: 0.980\n",
      "valid_loss: 0.366, valid_acc: 0.878\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 71.33it/s]\n",
      "test_loss: 0.315, test_acc: 0.870\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.62it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.38it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.499\n",
      "valid_loss: 0.693, valid_acc: 0.520\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.40it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.533\n",
      "valid_loss: 0.693, valid_acc: 0.549\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.34it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.02it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.556\n",
      "valid_loss: 0.693, valid_acc: 0.544\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.55it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.572\n",
      "valid_loss: 0.693, valid_acc: 0.602\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.38it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.692, train_acc: 0.656\n",
      "valid_loss: 0.692, valid_acc: 0.611\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 84.07it/s]\n",
      "test_loss: 0.692, test_acc: 0.609\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.67it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.95it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.506\n",
      "valid_loss: 0.693, valid_acc: 0.511\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.49it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.55it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.535\n",
      "valid_loss: 0.693, valid_acc: 0.539\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 71.51it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.551\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.06it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.74it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.692, train_acc: 0.593\n",
      "valid_loss: 0.692, valid_acc: 0.580\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.82it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.12it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.691, train_acc: 0.641\n",
      "valid_loss: 0.690, valid_acc: 0.632\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 85.71it/s]\n",
      "test_loss: 0.690, test_acc: 0.630\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.62it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.90it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.15it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.524\n",
      "valid_loss: 0.693, valid_acc: 0.508\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.77it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.536\n",
      "valid_loss: 0.693, valid_acc: 0.555\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 61.88it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.563\n",
      "valid_loss: 0.693, valid_acc: 0.590\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.24it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.26it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.692, train_acc: 0.622\n",
      "valid_loss: 0.691, valid_acc: 0.618\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.52it/s]\n",
      "test_loss: 0.691, test_acc: 0.614\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.06it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.51it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.506\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.11it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.41it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.522\n",
      "valid_loss: 0.693, valid_acc: 0.508\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.48it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 73.59it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.567\n",
      "valid_loss: 0.693, valid_acc: 0.526\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.53it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.71it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.692, train_acc: 0.608\n",
      "valid_loss: 0.692, valid_acc: 0.552\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.25it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.38it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.688, train_acc: 0.604\n",
      "valid_loss: 0.642, valid_acc: 0.714\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 78.41it/s]\n",
      "test_loss: 0.641, test_acc: 0.706\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.97it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.523\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.07it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.62it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.526\n",
      "valid_loss: 0.693, valid_acc: 0.556\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.90it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.546\n",
      "valid_loss: 0.693, valid_acc: 0.539\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.53it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.564\n",
      "valid_loss: 0.693, valid_acc: 0.587\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.78it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.96it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.616\n",
      "valid_loss: 0.693, valid_acc: 0.606\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 85.52it/s]\n",
      "test_loss: 0.693, test_acc: 0.603\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h155_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.03it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.503\n",
      "valid_loss: 0.693, valid_acc: 0.521\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.89it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.530\n",
      "valid_loss: 0.693, valid_acc: 0.541\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.33it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 94.07it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.548\n",
      "valid_loss: 0.693, valid_acc: 0.532\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.58it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.45it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.564\n",
      "valid_loss: 0.693, valid_acc: 0.548\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 48.85it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.48it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.692, train_acc: 0.590\n",
      "valid_loss: 0.692, valid_acc: 0.585\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 83.26it/s]\n",
      "test_loss: 0.692, test_acc: 0.582\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.15it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.501\n",
      "valid_loss: 0.693, valid_acc: 0.498\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 74.80it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.514\n",
      "valid_loss: 0.693, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.96it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.99it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.531\n",
      "valid_loss: 0.693, valid_acc: 0.526\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.61it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.62it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.533\n",
      "valid_loss: 0.693, valid_acc: 0.544\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.55it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.693, train_acc: 0.562\n",
      "valid_loss: 0.693, valid_acc: 0.558\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 73.00it/s]\n",
      "test_loss: 0.693, test_acc: 0.558\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_adam_e32_h200_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.65it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.503\n",
      "valid_loss: 0.693, valid_acc: 0.497\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 67.41it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.693, train_acc: 0.521\n",
      "valid_loss: 0.693, valid_acc: 0.505\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.90it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.693, train_acc: 0.548\n",
      "valid_loss: 0.693, valid_acc: 0.516\n",
      "training...: 100%|██████████| 365/365 [00:09<00:00, 40.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.57it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.693, train_acc: 0.578\n",
      "valid_loss: 0.693, valid_acc: 0.530\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.75it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.692, train_acc: 0.566\n",
      "valid_loss: 0.692, valid_acc: 0.592\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 78.45it/s]\n",
      "test_loss: 0.692, test_acc: 0.583\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.15it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.671, train_acc: 0.602\n",
      "valid_loss: 0.553, valid_acc: 0.724\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.41it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.17it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.358, train_acc: 0.848\n",
      "valid_loss: 0.361, valid_acc: 0.859\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.80it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.231, train_acc: 0.914\n",
      "valid_loss: 0.365, valid_acc: 0.860\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.13it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 83.62it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.141, train_acc: 0.950\n",
      "valid_loss: 0.459, valid_acc: 0.842\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 46.66it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.79it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.087, train_acc: 0.972\n",
      "valid_loss: 0.470, valid_acc: 0.834\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 83.00it/s]\n",
      "test_loss: 0.360, test_acc: 0.859\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.31it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.664, train_acc: 0.611\n",
      "valid_loss: 0.558, valid_acc: 0.710\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.80it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.53it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.390, train_acc: 0.841\n",
      "valid_loss: 0.393, valid_acc: 0.831\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.08it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.212, train_acc: 0.922\n",
      "valid_loss: 0.380, valid_acc: 0.835\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.64it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.135, train_acc: 0.954\n",
      "valid_loss: 0.432, valid_acc: 0.837\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.77it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.084, train_acc: 0.973\n",
      "valid_loss: 0.460, valid_acc: 0.856\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 88.15it/s]\n",
      "test_loss: 0.367, test_acc: 0.847\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.26it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.695, train_acc: 0.565\n",
      "valid_loss: 0.656, valid_acc: 0.600\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.86it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.444, train_acc: 0.791\n",
      "valid_loss: 0.355, valid_acc: 0.855\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.79it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.237, train_acc: 0.909\n",
      "valid_loss: 0.346, valid_acc: 0.859\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.84it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.98it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.136, train_acc: 0.952\n",
      "valid_loss: 0.406, valid_acc: 0.855\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.14it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.33it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.083, train_acc: 0.973\n",
      "valid_loss: 0.462, valid_acc: 0.851\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.03it/s]\n",
      "test_loss: 0.343, test_acc: 0.862\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 41.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 75.75it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.622, train_acc: 0.628\n",
      "valid_loss: 0.428, valid_acc: 0.822\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 40.88it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.44it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.323, train_acc: 0.867\n",
      "valid_loss: 0.349, valid_acc: 0.864\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.17it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.186, train_acc: 0.932\n",
      "valid_loss: 0.371, valid_acc: 0.850\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.73it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.65it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.116, train_acc: 0.961\n",
      "valid_loss: 0.429, valid_acc: 0.857\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.71it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.061, train_acc: 0.981\n",
      "valid_loss: 0.540, valid_acc: 0.854\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 76.11it/s]\n",
      "test_loss: 0.347, test_acc: 0.859\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.84it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.732, train_acc: 0.534\n",
      "valid_loss: 0.670, valid_acc: 0.586\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.75it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.36it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.622, train_acc: 0.653\n",
      "valid_loss: 0.584, valid_acc: 0.687\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.28it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.38it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.445, train_acc: 0.807\n",
      "valid_loss: 0.407, valid_acc: 0.834\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.37it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.362, train_acc: 0.854\n",
      "valid_loss: 0.405, valid_acc: 0.830\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.36it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.226, train_acc: 0.915\n",
      "valid_loss: 0.442, valid_acc: 0.808\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 87.31it/s]\n",
      "test_loss: 0.403, test_acc: 0.826\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.98it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.18it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.716, train_acc: 0.578\n",
      "valid_loss: 0.587, valid_acc: 0.678\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 49.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.83it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.385, train_acc: 0.836\n",
      "valid_loss: 0.370, valid_acc: 0.846\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 82.51it/s]\n",
      "epoch: 3\n",
      "train_loss: 0.210, train_acc: 0.924\n",
      "valid_loss: 0.373, valid_acc: 0.858\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.39it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 88.54it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.142, train_acc: 0.951\n",
      "valid_loss: 0.416, valid_acc: 0.856\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.26it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.67it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.083, train_acc: 0.973\n",
      "valid_loss: 0.534, valid_acc: 0.861\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 90.86it/s]\n",
      "test_loss: 0.369, test_acc: 0.841\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.04it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.94it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.629, train_acc: 0.658\n",
      "valid_loss: 0.492, valid_acc: 0.755\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 45.10it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.96it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.502, train_acc: 0.781\n",
      "valid_loss: 0.473, valid_acc: 0.812\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.72it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.12it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.279, train_acc: 0.893\n",
      "valid_loss: 0.366, valid_acc: 0.855\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.65it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.98it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.192, train_acc: 0.930\n",
      "valid_loss: 0.414, valid_acc: 0.854\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.38it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.150, train_acc: 0.948\n",
      "valid_loss: 0.483, valid_acc: 0.852\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 78.47it/s]\n",
      "test_loss: 0.375, test_acc: 0.852\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.17it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.642, train_acc: 0.623\n",
      "valid_loss: 0.469, valid_acc: 0.805\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.42it/s]\n",
      "epoch: 2\n",
      "train_loss: 0.373, train_acc: 0.851\n",
      "valid_loss: 0.494, valid_acc: 0.764\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.23it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.67it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.238, train_acc: 0.912\n",
      "valid_loss: 0.393, valid_acc: 0.844\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.12it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.24it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.148, train_acc: 0.949\n",
      "valid_loss: 0.419, valid_acc: 0.838\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.72it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.04it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.091, train_acc: 0.971\n",
      "valid_loss: 0.481, valid_acc: 0.832\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.57it/s]\n",
      "test_loss: 0.394, test_acc: 0.844\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.98it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.55it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.514\n",
      "valid_loss: 0.687, valid_acc: 0.503\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.15it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.71it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.500, train_acc: 0.787\n",
      "valid_loss: 0.381, valid_acc: 0.850\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 87.08it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.289, train_acc: 0.896\n",
      "valid_loss: 0.319, valid_acc: 0.867\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.19it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 86.55it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.196, train_acc: 0.934\n",
      "valid_loss: 0.289, valid_acc: 0.882\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.89it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.25it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.138, train_acc: 0.957\n",
      "valid_loss: 0.373, valid_acc: 0.872\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 87.12it/s]\n",
      "test_loss: 0.282, test_acc: 0.883\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.00it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.21it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.682, train_acc: 0.547\n",
      "valid_loss: 0.532, valid_acc: 0.737\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.86it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 92.41it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.396, train_acc: 0.845\n",
      "valid_loss: 0.360, valid_acc: 0.855\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.43it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.72it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.240, train_acc: 0.915\n",
      "valid_loss: 0.308, valid_acc: 0.876\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 51.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 84.95it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.161, train_acc: 0.948\n",
      "valid_loss: 0.312, valid_acc: 0.881\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.17it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.32it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.111, train_acc: 0.966\n",
      "valid_loss: 0.371, valid_acc: 0.868\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 89.74it/s]\n",
      "test_loss: 0.300, test_acc: 0.877\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_32ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.01it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.699, train_acc: 0.530\n",
      "valid_loss: 0.675, valid_acc: 0.555\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.14it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.526, train_acc: 0.748\n",
      "valid_loss: 0.415, valid_acc: 0.848\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.37it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.325, train_acc: 0.888\n",
      "valid_loss: 0.336, valid_acc: 0.876\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.93it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.09it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.214, train_acc: 0.931\n",
      "valid_loss: 0.300, valid_acc: 0.881\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.01it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.61it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.149, train_acc: 0.955\n",
      "valid_loss: 0.321, valid_acc: 0.877\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.89it/s]\n",
      "test_loss: 0.293, test_acc: 0.881\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_48ed ------\n",
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.51it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.39it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.689, train_acc: 0.531\n",
      "valid_loss: 0.633, valid_acc: 0.765\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.21it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.06it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.405, train_acc: 0.836\n",
      "valid_loss: 0.345, valid_acc: 0.860\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.60it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.64it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.235, train_acc: 0.916\n",
      "valid_loss: 0.311, valid_acc: 0.876\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.44it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.158, train_acc: 0.949\n",
      "valid_loss: 0.329, valid_acc: 0.879\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.05it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.76it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.102, train_acc: 0.969\n",
      "valid_loss: 0.366, valid_acc: 0.871\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 79.50it/s]\n",
      "test_loss: 0.305, test_acc: 0.874\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,063,092 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.91it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.70it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.508\n",
      "valid_loss: 0.692, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.64it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.709, train_acc: 0.519\n",
      "valid_loss: 0.681, valid_acc: 0.511\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.54it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.65it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.602, train_acc: 0.623\n",
      "valid_loss: 0.410, valid_acc: 0.828\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 53.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 93.21it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.323, train_acc: 0.876\n",
      "valid_loss: 0.317, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:06<00:00, 52.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 85.62it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.221, train_acc: 0.919\n",
      "valid_loss: 0.295, valid_acc: 0.879\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 85.35it/s]\n",
      "test_loss: 0.294, test_acc: 0.880\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h155_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,045,812 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.46it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.53it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.522\n",
      "valid_loss: 0.691, valid_acc: 0.546\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 47.42it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 89.25it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.538, train_acc: 0.754\n",
      "valid_loss: 0.432, valid_acc: 0.825\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.63it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.01it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.317, train_acc: 0.891\n",
      "valid_loss: 0.331, valid_acc: 0.869\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.50it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 91.75it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.207, train_acc: 0.933\n",
      "valid_loss: 0.300, valid_acc: 0.881\n",
      "training...: 100%|██████████| 365/365 [00:07<00:00, 50.79it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 90.74it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.140, train_acc: 0.957\n",
      "valid_loss: 0.337, valid_acc: 0.873\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 91.40it/s]\n",
      "test_loss: 0.293, test_acc: 0.881\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_32ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 2,133,202 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.74it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 81.65it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.514\n",
      "valid_loss: 0.692, valid_acc: 0.567\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.57it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 78.21it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.718, train_acc: 0.561\n",
      "valid_loss: 0.667, valid_acc: 0.596\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 43.16it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.78it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.593, train_acc: 0.738\n",
      "valid_loss: 0.430, valid_acc: 0.815\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.97it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 80.29it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.342, train_acc: 0.867\n",
      "valid_loss: 0.337, valid_acc: 0.866\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 44.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.79it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.236, train_acc: 0.915\n",
      "valid_loss: 0.321, valid_acc: 0.876\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.53it/s]\n",
      "test_loss: 0.315, test_acc: 0.874\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "------ New Model: lstm_1layer_base_rmsprop_e32_h200_48ed ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,118,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.60it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.509\n",
      "valid_loss: 0.691, valid_acc: 0.545\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.18it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 72.64it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.687, train_acc: 0.592\n",
      "valid_loss: 0.481, valid_acc: 0.810\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.20it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 77.84it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.359, train_acc: 0.862\n",
      "valid_loss: 0.324, valid_acc: 0.868\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.59it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 76.75it/s]\n",
      "Saving ...\n",
      "epoch: 4\n",
      "train_loss: 0.224, train_acc: 0.920\n",
      "valid_loss: 0.307, valid_acc: 0.880\n",
      "training...: 100%|██████████| 365/365 [00:08<00:00, 42.71it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 79.05it/s]\n",
      "Saving ...\n",
      "epoch: 5\n",
      "train_loss: 0.152, train_acc: 0.950\n",
      "valid_loss: 0.286, valid_acc: 0.886\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 77.29it/s]\n",
      "test_loss: 0.281, test_acc: 0.886\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "optimizer_name = [\"adagrad\", \"adam\", \"rmsprop\"]\n",
    "n_layers = [1]\n",
    "hidden_dims = [155, 200]\n",
    "e_dims = [32, 48]\n",
    "lr = [0.0001, 0.00001]\n",
    "drp = [0.0, 0.5]\n",
    "table_dict = {}\n",
    "i = 0\n",
    "on = 0\n",
    "for opt_nm in optimizer_name:\n",
    "    if opt_nm == \"adagrad\":\n",
    "        on = 1\n",
    "    elif opt_nm == \"adam\":\n",
    "        on = 2\n",
    "    else:\n",
    "        on = 3\n",
    "\n",
    "    for learning_rate in lr:\n",
    "        for dropout_rate in drp:\n",
    "            for nl in n_layers:\n",
    "                for hd in hidden_dims:\n",
    "                    for ed in e_dims:\n",
    "                        new_hp = HyperParams()\n",
    "                        new_hp.OPTIM = opt_nm\n",
    "                        new_hp.LR = learning_rate\n",
    "                        new_hp.DROPOUT_RATE = dropout_rate\n",
    "                        new_hp.N_LAYER = nl\n",
    "                        new_hp.HIDDEN_DIM = hd\n",
    "                        new_hp.EMBEDDING_DIM = ed\n",
    "                        model_name_str = f'lstm_{nl}layer_base_{opt_nm}_e32_h{hd}_{ed}ed'\n",
    "                        print(f'-----------------------------------------')\n",
    "                        print(f'------ New Model: {model_name_str} ------')\n",
    "                        rtr_vals = train_and_test_model_with_hparams(new_hp, model_name_str)\n",
    "                        table_dict[i] = [float(on),\n",
    "                                         float(nl),\n",
    "                                         float(hd),\n",
    "                                         float(ed),\n",
    "                                         float(rtr_vals['num_params']),\n",
    "                                         rtr_vals[\"test_loss\"],\n",
    "                                         rtr_vals[\"test_acc\"],\n",
    "                                         float(dropout_rate),\n",
    "                                         float(learning_rate)]\n",
    "                        print(f'-----------------------------------------')\n",
    "                        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "    OptimType  NumLayers  NumHiddenDim  NumEmbededDim  NumParams  Test_Loss  \\\n0         1.0        1.0         155.0           32.0  2063092.0   0.693033   \n1         1.0        1.0         155.0           48.0  3045812.0   0.692962   \n2         1.0        1.0         200.0           32.0  2133202.0   0.693037   \n3         1.0        1.0         200.0           48.0  3118802.0   0.692973   \n4         1.0        1.0         155.0           32.0  2063092.0   0.693083   \n5         1.0        1.0         155.0           48.0  3045812.0   0.693040   \n6         1.0        1.0         200.0           32.0  2133202.0   0.693096   \n7         1.0        1.0         200.0           48.0  3118802.0   0.693055   \n8         1.0        1.0         155.0           32.0  2063092.0   0.693143   \n9         1.0        1.0         155.0           48.0  3045812.0   0.693132   \n10        1.0        1.0         200.0           32.0  2133202.0   0.693144   \n11        1.0        1.0         200.0           48.0  3118802.0   0.693136   \n12        1.0        1.0         155.0           32.0  2063092.0   0.693144   \n13        1.0        1.0         155.0           48.0  3045812.0   0.693135   \n14        1.0        1.0         200.0           32.0  2133202.0   0.693146   \n15        1.0        1.0         200.0           48.0  3118802.0   0.693138   \n16        2.0        1.0         155.0           32.0  2063092.0   0.292801   \n17        2.0        1.0         155.0           48.0  3045812.0   0.291201   \n18        2.0        1.0         200.0           32.0  2133202.0   0.291200   \n19        2.0        1.0         200.0           48.0  3118802.0   0.308691   \n20        2.0        1.0         155.0           32.0  2063092.0   0.283810   \n21        2.0        1.0         155.0           48.0  3045812.0   0.290888   \n22        2.0        1.0         200.0           32.0  2133202.0   0.285255   \n23        2.0        1.0         200.0           48.0  3118802.0   0.315115   \n24        2.0        1.0         155.0           32.0  2063092.0   0.691663   \n25        2.0        1.0         155.0           48.0  3045812.0   0.690239   \n26        2.0        1.0         200.0           32.0  2133202.0   0.691465   \n27        2.0        1.0         200.0           48.0  3118802.0   0.641215   \n28        2.0        1.0         155.0           32.0  2063092.0   0.692739   \n29        2.0        1.0         155.0           48.0  3045812.0   0.692446   \n30        2.0        1.0         200.0           32.0  2133202.0   0.692785   \n31        2.0        1.0         200.0           48.0  3118802.0   0.692374   \n32        3.0        1.0         155.0           32.0  2063092.0   0.360181   \n33        3.0        1.0         155.0           48.0  3045812.0   0.366611   \n34        3.0        1.0         200.0           32.0  2133202.0   0.342649   \n35        3.0        1.0         200.0           48.0  3118802.0   0.347035   \n36        3.0        1.0         155.0           32.0  2063092.0   0.403054   \n37        3.0        1.0         155.0           48.0  3045812.0   0.368852   \n38        3.0        1.0         200.0           32.0  2133202.0   0.374658   \n39        3.0        1.0         200.0           48.0  3118802.0   0.394272   \n40        3.0        1.0         155.0           32.0  2063092.0   0.281998   \n41        3.0        1.0         155.0           48.0  3045812.0   0.299813   \n42        3.0        1.0         200.0           32.0  2133202.0   0.293066   \n43        3.0        1.0         200.0           48.0  3118802.0   0.304978   \n44        3.0        1.0         155.0           32.0  2063092.0   0.293694   \n45        3.0        1.0         155.0           48.0  3045812.0   0.293033   \n46        3.0        1.0         200.0           32.0  2133202.0   0.315018   \n47        3.0        1.0         200.0           48.0  3118802.0   0.281131   \n\n    Test_Acc  dropout_rate  learning_rate  \n0   0.560913           0.0        0.00010  \n1   0.548710           0.0        0.00010  \n2   0.528671           0.0        0.00010  \n3   0.545437           0.0        0.00010  \n4   0.560814           0.5        0.00010  \n5   0.536905           0.5        0.00010  \n6   0.513492           0.5        0.00010  \n7   0.532242           0.5        0.00010  \n8   0.506052           0.0        0.00001  \n9   0.510020           0.0        0.00001  \n10  0.504365           0.0        0.00001  \n11  0.506944           0.0        0.00001  \n12  0.500794           0.5        0.00001  \n13  0.511806           0.5        0.00001  \n14  0.501885           0.5        0.00001  \n15  0.506448           0.5        0.00001  \n16  0.881250           0.0        0.00010  \n17  0.881746           0.0        0.00010  \n18  0.882341           0.0        0.00010  \n19  0.872421           0.0        0.00010  \n20  0.884226           0.5        0.00010  \n21  0.878869           0.5        0.00010  \n22  0.880853           0.5        0.00010  \n23  0.869643           0.5        0.00010  \n24  0.608829           0.0        0.00001  \n25  0.629861           0.0        0.00001  \n26  0.613591           0.0        0.00001  \n27  0.705853           0.0        0.00001  \n28  0.602679           0.5        0.00001  \n29  0.582143           0.5        0.00001  \n30  0.557937           0.5        0.00001  \n31  0.582738           0.5        0.00001  \n32  0.859425           0.0        0.00010  \n33  0.847421           0.0        0.00010  \n34  0.862103           0.0        0.00010  \n35  0.859325           0.0        0.00010  \n36  0.825794           0.5        0.00010  \n37  0.841468           0.5        0.00010  \n38  0.851687           0.5        0.00010  \n39  0.843651           0.5        0.00010  \n40  0.882738           0.0        0.00001  \n41  0.876587           0.0        0.00001  \n42  0.881448           0.0        0.00001  \n43  0.873810           0.0        0.00001  \n44  0.880258           0.5        0.00001  \n45  0.880952           0.5        0.00001  \n46  0.874405           0.5        0.00001  \n47  0.885814           0.5        0.00001  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OptimType</th>\n      <th>NumLayers</th>\n      <th>NumHiddenDim</th>\n      <th>NumEmbededDim</th>\n      <th>NumParams</th>\n      <th>Test_Loss</th>\n      <th>Test_Acc</th>\n      <th>dropout_rate</th>\n      <th>learning_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.693033</td>\n      <td>0.560913</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.692962</td>\n      <td>0.548710</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.693037</td>\n      <td>0.528671</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.692973</td>\n      <td>0.545437</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.693083</td>\n      <td>0.560814</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.693040</td>\n      <td>0.536905</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.693096</td>\n      <td>0.513492</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.693055</td>\n      <td>0.532242</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.693143</td>\n      <td>0.506052</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.693132</td>\n      <td>0.510020</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.693144</td>\n      <td>0.504365</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.693136</td>\n      <td>0.506944</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.693144</td>\n      <td>0.500794</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.693135</td>\n      <td>0.511806</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.693146</td>\n      <td>0.501885</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.693138</td>\n      <td>0.506448</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.292801</td>\n      <td>0.881250</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.291201</td>\n      <td>0.881746</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.291200</td>\n      <td>0.882341</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.308691</td>\n      <td>0.872421</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.283810</td>\n      <td>0.884226</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.290888</td>\n      <td>0.878869</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.285255</td>\n      <td>0.880853</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.315115</td>\n      <td>0.869643</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.691663</td>\n      <td>0.608829</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.690239</td>\n      <td>0.629861</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.691465</td>\n      <td>0.613591</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.641215</td>\n      <td>0.705853</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.692739</td>\n      <td>0.602679</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.692446</td>\n      <td>0.582143</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.692785</td>\n      <td>0.557937</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.692374</td>\n      <td>0.582738</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.360181</td>\n      <td>0.859425</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.366611</td>\n      <td>0.847421</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.342649</td>\n      <td>0.862103</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.347035</td>\n      <td>0.859325</td>\n      <td>0.0</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.403054</td>\n      <td>0.825794</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.368852</td>\n      <td>0.841468</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.374658</td>\n      <td>0.851687</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.394272</td>\n      <td>0.843651</td>\n      <td>0.5</td>\n      <td>0.00010</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.281998</td>\n      <td>0.882738</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.299813</td>\n      <td>0.876587</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.293066</td>\n      <td>0.881448</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.304978</td>\n      <td>0.873810</td>\n      <td>0.0</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>32.0</td>\n      <td>2063092.0</td>\n      <td>0.293694</td>\n      <td>0.880258</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>155.0</td>\n      <td>48.0</td>\n      <td>3045812.0</td>\n      <td>0.293033</td>\n      <td>0.880952</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>32.0</td>\n      <td>2133202.0</td>\n      <td>0.315018</td>\n      <td>0.874405</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>200.0</td>\n      <td>48.0</td>\n      <td>3118802.0</td>\n      <td>0.281131</td>\n      <td>0.885814</td>\n      <td>0.5</td>\n      <td>0.00001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(data=table_dict, orient=\"index\", columns = [\"OptimType\",\n",
    "                                                                        \"NumLayers\",\n",
    "                                                                        \"NumHiddenDim\",\n",
    "                                                                        \"NumEmbededDim\",\n",
    "                                                                        \"NumParams\",\n",
    "                                                                        \"Test_Loss\",\n",
    "                                                                        \"Test_Acc\",\n",
    "                                                                        \"dropout_rate\",\n",
    "                                                                        \"learning_rate\"])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2 (g) Bi-Directional LSTM, using best architecture from (f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taylor/Duke/ECE661/projects/untitled/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 60800\n",
      "The model has 3,318,802 trainable parameters\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.35it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.16it/s]\n",
      "Saving ...\n",
      "epoch: 1\n",
      "train_loss: 0.693, train_acc: 0.513\n",
      "valid_loss: 0.690, valid_acc: 0.504\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.29it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 63.52it/s]\n",
      "Saving ...\n",
      "epoch: 2\n",
      "train_loss: 0.450, train_acc: 0.800\n",
      "valid_loss: 0.342, valid_acc: 0.866\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 30.08it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.36it/s]\n",
      "Saving ...\n",
      "epoch: 3\n",
      "train_loss: 0.256, train_acc: 0.911\n",
      "valid_loss: 0.298, valid_acc: 0.879\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 29.92it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 64.21it/s]\n",
      "epoch: 4\n",
      "train_loss: 0.172, train_acc: 0.943\n",
      "valid_loss: 0.308, valid_acc: 0.874\n",
      "training...: 100%|██████████| 365/365 [00:12<00:00, 29.77it/s]\n",
      "evaluating...: 100%|██████████| 53/53 [00:00<00:00, 63.59it/s]\n",
      "epoch: 5\n",
      "train_loss: 0.116, train_acc: 0.964\n",
      "valid_loss: 0.349, valid_acc: 0.879\n",
      "evaluating...: 100%|██████████| 105/105 [00:01<00:00, 62.62it/s]\n",
      "test_loss: 0.298, test_acc: 0.880\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bi_hyperparams = HyperParams()\n",
    "bi_hyperparams.OPTIM = \"rmsprop\"\n",
    "bi_hyperparams.LR = 0.00001\n",
    "bi_hyperparams.DROPOUT_RATE = 0.5\n",
    "bi_hyperparams.N_LAYERS = 1\n",
    "bi_hyperparams.HIDDEN_DIM = 200\n",
    "bi_hyperparams.EMBEDDING_DIM = 48\n",
    "bi_hyperparams.BIDIRECTIONAL = True\n",
    "_ = train_and_test_model_with_hparams(bi_hyperparams , \"lstm_Xlayer_base_rmsprop_e32_hX_bidirectional\", output_plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lab1-answer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
